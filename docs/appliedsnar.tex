\PassOptionsToPackage{unicode=true}{hyperref} % options for packages loaded elsewhere
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[]{book}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provides euro and other symbols
\else % if luatex or xelatex
  \usepackage{unicode-math}
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage[]{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\usepackage{hyperref}
\hypersetup{
            pdftitle={Applied Network Science with R},
            pdfauthor={George G. Vega Yon},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs}
% Fix footnotes in tables (requires footnote package)
\IfFileExists{footnote.sty}{\usepackage{footnote}\makesavenoteenv{longtable}}{}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\usepackage[normalem]{ulem}
% avoid problems with \sout in headers with hyperref:
\pdfstringdefDisableCommands{\renewcommand{\sout}{}}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

% set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\usepackage{booktabs}
\usepackage{hyperref}
  \hypersetup{allcolors=blue, colorlinks=true}

\usepackage{apacite}
\usepackage{setspace}
\onehalfspacing

\usepackage{arev}
\usepackage[T1]{fontenc}

\usepackage[margin=1in]{geometry}

\allowdisplaybreaks

\title{Applied Network Science with R}
\author{George G. Vega Yon}
\date{2022-07-13}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{about}{%
\chapter{About}\label{about}}

\renewcommand{\Pr}[1]{\mbox{Pr}\left(#1\right)}
\renewcommand{\exp}[1]{\mbox{exp}\left\{#1\right\}}

\hypertarget{the-book}{%
\subsection{The Book}\label{the-book}}

Statistical methods for networked systems are present in most disciplines.
Nonetheless, the language differences between disciplines, many methods
developed to study specific types of problems can be helpful outside of their original context.

This project began as a part of a workshop that took place at USC's
\href{https://cana.usc.edu}{Center for Applied Network Analysis}. Now, it is a personal
project that I use to gather and study statistical methods to analyze networks, emphasizing social and biological systems.
Moreover, the book will use statistical computing methods as a core component
when developing these topics.

In general, we will, besides R itself, we will be using R studio and the following
R packages: dplyr for data management, stringr for data cleaning, and of course
igraph, netdiffuseR (a bit of a bias here), and statnet for our neat network
analysis.\footnote{Some of you may be wondering ``what about ggplot2 and friends? What about \href{https://www.tidyverse.org/}{\texttt{tidyverse}}'', well, my short answer is I jumped into R before all of that was that popular. When I started, plots were all about \href{https://CRAN.R-project.org/package=lattice}{\texttt{lattice}}, and after a couple of years on that, about base R graphics. What I'm saying is that so far, I have not found a compelling reason to leave my ``old practices'' and embrace all the \texttt{tidyverse} movement (religion?).}

You can access the book's source code at \url{https://github.com/gvegayon/appliedsnar}.

\hypertarget{the-author}{%
\subsection{The author}\label{the-author}}

I am a Research Assistant Professor at the University of Utah's Division of
Epidemiology, where I work on studying Complex Systems using Statistical Computing.
I have over ten years of experience developing scientific software focusing on
high-performance computing, data visualization, and social network analysis.
My training is in Public Policy (M.A.~UAI, 2011), Economics (M.Sc. Caltech,
2015), and Biostatistics (Ph.D.~USC, 2020).

I obtained my Ph.D.~in Biostatistics under the supervision of
\href{https://scholar.google.com/citations?user=Zj5ky5gAAAAJ\&hl=en}{Prof.~Paul Marjoram} and
\href{https://kayladelahaye.net/}{Prof.~Kayla de la Haye}, with my dissertation titled ``Essays on
Bioinformatics and Social Network Analysis: Statistical and Computational Methods
for Complex Systems.''

If you'd like to learn more about me, please visit my website at \url{https://ggvy.cl}.

\hypertarget{part-applications}{%
\part{Applications}\label{part-applications}}

\hypertarget{introduction}{%
\chapter{Introduction}\label{introduction}}

Social Network Analysis and Network Science, have a long scholarly tradition.
From social diffusion models to protein-interaction networks, these complex-systems
disciplines cover a wide range of problems across scientific fields. Yet, although
these could be seen as wildly different, the object under the microscope is the
same, networks.

With a long history (and insufficient levels of inter-discipline collaboration,
if you allow me to say) of scientific advances happing in a somewhat isolated
fashion, the potential of cross-pollination between disciplines within network
science is immense.

This book is an attempt to compile the many methods available in the realm of
complexity sciences, provide an in-depth mathematical examination--when possible--,
and provide a few examples illustrating their usage.

\hypertarget{r-basics}{%
\chapter{R Basics}\label{r-basics}}

\hypertarget{what-is-r}{%
\section{What is R}\label{what-is-r}}

A good reference book for both new and advanced user is \href{https://nostarch.com/artofr.htm}{``The Art of R programming''} (Matloff \protect\hyperlink{ref-Matloff2011}{2011})\footnote{\href{http://heather.cs.ucdavis.edu/~matloff/145/PLN/RMaterials/NSPpart.pdf}{Here} a free pdf version distributed by the author.}

\hypertarget{how-to-install-packages}{%
\section{How to install packages}\label{how-to-install-packages}}

Nowadays there are two ways of installing R packages (that I'm aware of), either using \texttt{install.packages}, which is a function shipped with R, or use the devtools R package to install a package from some remote repository other than CRAN, here is a couple of examples:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# This will install the igraph package from CRAN}
\OperatorTok{>}\StringTok{ }\KeywordTok{install.packages}\NormalTok{(}\StringTok{"netdiffuseR"}\NormalTok{)}

\CommentTok{# This will install the bleeding-edge version from the project's github repo!}
\OperatorTok{>}\StringTok{ }\NormalTok{devtools}\OperatorTok{::}\KeywordTok{install_github}\NormalTok{(}\StringTok{"USCCANA/netdiffuseR"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The first one, using \texttt{install.packages}, installs the CRAN version of \texttt{netdiffuseR}, whereas the second installs whatever version is plublished on \url{https://github.com/USCCANA/netdiffuseR}, which is usually called the development version.

In some cases users may want/need to install packages from command line as some packages need extra configuration to be installed. But we won't need to look at it now.

\hypertarget{prerequisits}{%
\section{Prerequisits}\label{prerequisits}}

To install R just follow the instructions available at \url{http://cran.r-project.org}

RStudio is the most popular Integrated Development Environment (IDE) for R that is developed by the company of the same name. While having RStudio is not a requirement for using netdiffuseR, it is highly recommended.

To get RStudio just visit \url{https://www.rstudio.com/products/rstudio/download/}.

\hypertarget{a-gentle-quick-n-dirty-introduction-to-r}{%
\section{\texorpdfstring{A \sout{gentle} Quick n' Dirty Introduction to R}{A gentle Quick n' Dirty Introduction to R}}\label{a-gentle-quick-n-dirty-introduction-to-r}}

Some common tasks in R

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{-1}
\item
  Getting help (and reading the manual) is \emph{THE MOST IMPORTANT} thing you should know about. For example, if you want to read the manual (help file) of the \texttt{read.csv} function, you can type either of these:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{?read.csv}
\NormalTok{?}\StringTok{"read.csv"}
\KeywordTok{help}\NormalTok{(read.csv)}
\KeywordTok{help}\NormalTok{(}\StringTok{"read.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

  If you are not fully aware of what is the name of the function, you can always use the \emph{fuzzy search}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{help.search}\NormalTok{(}\StringTok{"linear regression"}\NormalTok{)}
\NormalTok{??}\StringTok{"linear regression"}
\end{Highlighting}
\end{Shaded}
\item
  In R you can create new objects by either using the assign operator (\texttt{\textless{}-}) or the equal sign \texttt{=}, for example, the following 2 are equivalent:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a <-}\StringTok{ }\DecValTok{1}
\NormalTok{a =}\StringTok{  }\DecValTok{1}
\end{Highlighting}
\end{Shaded}

  Historically the assign operator is the most common used.
\item
  R has several type of objects, the most basic structures in R are \texttt{vectors}, \texttt{matrix}, \texttt{list}, \texttt{data.frame}. Here is an example creating several of these (each line is enclosed with parenthesis so that R prints the resulting element):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(a_vector     <-}\StringTok{ }\DecValTok{1}\OperatorTok{:}\DecValTok{9}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1 2 3 4 5 6 7 8 9
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(another_vect <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{9}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1 2 3 4 5 6 7 8 9
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(a_string_vec <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"I"}\NormalTok{, }\StringTok{"like"}\NormalTok{, }\StringTok{"netdiffuseR"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "I"           "like"        "netdiffuseR"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(a_matrix     <-}\StringTok{ }\KeywordTok{matrix}\NormalTok{(a_vector, }\DataTypeTok{ncol =} \DecValTok{3}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1] [,2] [,3]
## [1,]    1    4    7
## [2,]    2    5    8
## [3,]    3    6    9
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(a_string_mat <-}\StringTok{ }\KeywordTok{matrix}\NormalTok{(letters[}\DecValTok{1}\OperatorTok{:}\DecValTok{9}\NormalTok{], }\DataTypeTok{ncol=}\DecValTok{3}\NormalTok{)) }\CommentTok{# Matrices can be of strings too}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1] [,2] [,3]
## [1,] "a"  "d"  "g" 
## [2,] "b"  "e"  "h" 
## [3,] "c"  "f"  "i"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(another_mat  <-}\StringTok{ }\KeywordTok{cbind}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{4}\NormalTok{, }\DecValTok{11}\OperatorTok{:}\DecValTok{14}\NormalTok{)) }\CommentTok{# The `cbind` operator does "column bind"}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1] [,2]
## [1,]    1   11
## [2,]    2   12
## [3,]    3   13
## [4,]    4   14
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(another_mat2 <-}\StringTok{ }\KeywordTok{rbind}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{4}\NormalTok{, }\DecValTok{11}\OperatorTok{:}\DecValTok{14}\NormalTok{)) }\CommentTok{# The `rbind` operator does "row bind"}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1] [,2] [,3] [,4]
## [1,]    1    2    3    4
## [2,]   11   12   13   14
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(a_string_mat <-}\StringTok{ }\KeywordTok{matrix}\NormalTok{(letters[}\DecValTok{1}\OperatorTok{:}\DecValTok{9}\NormalTok{], }\DataTypeTok{ncol =} \DecValTok{3}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1] [,2] [,3]
## [1,] "a"  "d"  "g" 
## [2,] "b"  "e"  "h" 
## [3,] "c"  "f"  "i"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(a_list       <-}\StringTok{ }\KeywordTok{list}\NormalTok{(a_vector, a_matrix))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [[1]]
## [1] 1 2 3 4 5 6 7 8 9
## 
## [[2]]
##      [,1] [,2] [,3]
## [1,]    1    4    7
## [2,]    2    5    8
## [3,]    3    6    9
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(another_list <-}\StringTok{ }\KeywordTok{list}\NormalTok{(}\DataTypeTok{my_vec =}\NormalTok{ a_vector, }\DataTypeTok{my_mat =}\NormalTok{ a_matrix)) }\CommentTok{# same but with names!}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $my_vec
## [1] 1 2 3 4 5 6 7 8 9
## 
## $my_mat
##      [,1] [,2] [,3]
## [1,]    1    4    7
## [2,]    2    5    8
## [3,]    3    6    9
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Data frames can have multiple types of elements, it is a collection of lists}
\NormalTok{(a_data_frame <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{x =} \DecValTok{1}\OperatorTok{:}\DecValTok{10}\NormalTok{, }\DataTypeTok{y =}\NormalTok{ letters[}\DecValTok{1}\OperatorTok{:}\DecValTok{10}\NormalTok{]))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##     x y
## 1   1 a
## 2   2 b
## 3   3 c
## 4   4 d
## 5   5 e
## 6   6 f
## 7   7 g
## 8   8 h
## 9   9 i
## 10 10 j
\end{verbatim}
\item
  Depending on the type of object, we can access to its components using indexing:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a_vector[}\DecValTok{1}\OperatorTok{:}\DecValTok{3}\NormalTok{] }\CommentTok{# First 3 elements}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1 2 3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a_string_vec[}\DecValTok{3}\NormalTok{] }\CommentTok{# Third element}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "netdiffuseR"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a_matrix[}\DecValTok{1}\OperatorTok{:}\DecValTok{2}\NormalTok{, }\DecValTok{1}\OperatorTok{:}\DecValTok{2}\NormalTok{] }\CommentTok{# A sub matrix}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1] [,2]
## [1,]    1    4
## [2,]    2    5
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a_matrix[,}\DecValTok{3}\NormalTok{] }\CommentTok{# Third column}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 7 8 9
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a_matrix[}\DecValTok{3}\NormalTok{,] }\CommentTok{# Third row}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3 6 9
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a_string_mat[}\DecValTok{1}\OperatorTok{:}\DecValTok{6}\NormalTok{] }\CommentTok{# First 6 elements of the matrix. R stores matrices by column.}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "a" "b" "c" "d" "e" "f"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# These three are equivalent}
\NormalTok{another_list[[}\DecValTok{1}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1 2 3 4 5 6 7 8 9
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{another_list}\OperatorTok{$}\NormalTok{my_vec}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1 2 3 4 5 6 7 8 9
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{another_list[[}\StringTok{"my_vec"}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1 2 3 4 5 6 7 8 9
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Data frames are just like lists}
\NormalTok{a_data_frame[[}\DecValTok{1}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1]  1  2  3  4  5  6  7  8  9 10
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a_data_frame[,}\DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1]  1  2  3  4  5  6  7  8  9 10
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a_data_frame[[}\StringTok{"x"}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1]  1  2  3  4  5  6  7  8  9 10
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a_data_frame}\OperatorTok{$}\NormalTok{x}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1]  1  2  3  4  5  6  7  8  9 10
\end{verbatim}
\item
  Control-flow statements

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# The oldfashion forloop}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\DecValTok{10}\NormalTok{) \{}
  \KeywordTok{print}\NormalTok{(}\KeywordTok{paste}\NormalTok{(}\StringTok{"I'm step"}\NormalTok{, i, }\StringTok{"/"}\NormalTok{, }\DecValTok{10}\NormalTok{))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "I'm step 1 / 10"
## [1] "I'm step 2 / 10"
## [1] "I'm step 3 / 10"
## [1] "I'm step 4 / 10"
## [1] "I'm step 5 / 10"
## [1] "I'm step 6 / 10"
## [1] "I'm step 7 / 10"
## [1] "I'm step 8 / 10"
## [1] "I'm step 9 / 10"
## [1] "I'm step 10 / 10"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# A nice ifelse}

\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\DecValTok{10}\NormalTok{) \{}

  \ControlFlowTok{if}\NormalTok{ (i }\OperatorTok{%%}\StringTok{ }\DecValTok{2}\NormalTok{) }\CommentTok{# Modulus operand}
    \KeywordTok{print}\NormalTok{(}\KeywordTok{paste}\NormalTok{(}\StringTok{"I'm step"}\NormalTok{, i, }\StringTok{"/"}\NormalTok{, }\DecValTok{10}\NormalTok{, }\StringTok{"(and I'm odd)"}\NormalTok{))}
  \ControlFlowTok{else}
    \KeywordTok{print}\NormalTok{(}\KeywordTok{paste}\NormalTok{(}\StringTok{"I'm step"}\NormalTok{, i, }\StringTok{"/"}\NormalTok{, }\DecValTok{10}\NormalTok{, }\StringTok{"(and I'm even)"}\NormalTok{))}

\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "I'm step 1 / 10 (and I'm odd)"
## [1] "I'm step 2 / 10 (and I'm even)"
## [1] "I'm step 3 / 10 (and I'm odd)"
## [1] "I'm step 4 / 10 (and I'm even)"
## [1] "I'm step 5 / 10 (and I'm odd)"
## [1] "I'm step 6 / 10 (and I'm even)"
## [1] "I'm step 7 / 10 (and I'm odd)"
## [1] "I'm step 8 / 10 (and I'm even)"
## [1] "I'm step 9 / 10 (and I'm odd)"
## [1] "I'm step 10 / 10 (and I'm even)"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# A while}
\NormalTok{i <-}\StringTok{ }\DecValTok{10}
\ControlFlowTok{while}\NormalTok{ (i }\OperatorTok{>}\StringTok{ }\DecValTok{0}\NormalTok{) \{}
  \KeywordTok{print}\NormalTok{(}\KeywordTok{paste}\NormalTok{(}\StringTok{"I'm step"}\NormalTok{, i, }\StringTok{"/"}\NormalTok{, }\DecValTok{10}\NormalTok{))}
\NormalTok{  i <-}\StringTok{ }\NormalTok{i }\OperatorTok{-}\StringTok{ }\DecValTok{1}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "I'm step 10 / 10"
## [1] "I'm step 9 / 10"
## [1] "I'm step 8 / 10"
## [1] "I'm step 7 / 10"
## [1] "I'm step 6 / 10"
## [1] "I'm step 5 / 10"
## [1] "I'm step 4 / 10"
## [1] "I'm step 3 / 10"
## [1] "I'm step 2 / 10"
## [1] "I'm step 1 / 10"
\end{verbatim}
\item
  R has a very nice set of pseudo random number generation functions. In general, distribution functions have the following name structure:

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    Random Number Generation: \texttt{r{[}name-of-the-distribution{]}}, e.g.~\texttt{rnorm} for normal, \texttt{runif} for uniform.
  \item
    Density function: \texttt{d{[}name-of-the-distribution{]}}, e.g.~\texttt{dnorm} for normal, \texttt{dunif} for uniform.
  \item
    Cumulative Distribution Function (CDF): \texttt{p{[}name-of-the-distribution{]}}, e.g.~\texttt{pnorm} for normal, \texttt{punif} for uniform.
  \item
    Inverse (quantile) function: \texttt{q{[}name-of-the-distribution{]}}, e.g.~\texttt{qnorm} for the normal, \texttt{qunif} for the uniform.
  \end{enumerate}

  Here are some examples:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# To ensure reproducibility}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{1231}\NormalTok{)}

\CommentTok{# 100,000 Unif(0,1) numbers}
\NormalTok{x <-}\StringTok{ }\KeywordTok{runif}\NormalTok{(}\FloatTok{1e5}\NormalTok{)}
\KeywordTok{hist}\NormalTok{(x)}
\end{Highlighting}
\end{Shaded}

  \includegraphics{02-the-basics_files/figure-latex/random-numbers-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# 100,000 N(0,1) numbers}
\NormalTok{x <-}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(}\FloatTok{1e5}\NormalTok{)}
\KeywordTok{hist}\NormalTok{(x)}
\end{Highlighting}
\end{Shaded}

  \includegraphics{02-the-basics_files/figure-latex/random-numbers-2.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# 100,000 N(10,25) numbers}
\NormalTok{x <-}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(}\FloatTok{1e5}\NormalTok{, }\DataTypeTok{mean =} \DecValTok{10}\NormalTok{, }\DataTypeTok{sd =} \DecValTok{5}\NormalTok{)}
\KeywordTok{hist}\NormalTok{(x)}
\end{Highlighting}
\end{Shaded}

  \includegraphics{02-the-basics_files/figure-latex/random-numbers-3.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# 100,000 Poisson(5) numbers}
\NormalTok{x <-}\StringTok{ }\KeywordTok{rpois}\NormalTok{(}\FloatTok{1e5}\NormalTok{, }\DataTypeTok{lambda =} \DecValTok{5}\NormalTok{)}
\KeywordTok{hist}\NormalTok{(x)}
\end{Highlighting}
\end{Shaded}

  \includegraphics{02-the-basics_files/figure-latex/random-numbers-4.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# 100,000 rexp(5) numbers}
\NormalTok{x <-}\StringTok{ }\KeywordTok{rexp}\NormalTok{(}\FloatTok{1e5}\NormalTok{, }\DecValTok{5}\NormalTok{)}
\KeywordTok{hist}\NormalTok{(x)}
\end{Highlighting}
\end{Shaded}

  \includegraphics{02-the-basics_files/figure-latex/random-numbers-5.pdf}

  More distributions available at \texttt{??Distributions}.
\end{enumerate}

For a nice intro to R, take a look at \href{https://nostarch.com/artofr.htm}{``The Art of R Programming'' by Norman Matloff}. For more advanced users, take a look at \href{http://adv-r.had.co.nz/}{``Advanced R'' by Hadley Wickham}.

For this book, we need the following

R Core Team (\protect\hyperlink{ref-R}{2017}\protect\hyperlink{ref-R}{b})

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Install R from CRAN: \url{https://www.r-project.org/}
\item
  (optional) Install Rstudio: \url{https://rstudio.org}
\end{enumerate}

While I find RStudio extremely useful, it is not necessary to use it with R.

\hypertarget{network-nomination-data}{%
\chapter{Network Nomination Data}\label{network-nomination-data}}

You can download the data for this chapter \href{https://cdn.rawgit.com/gvegayon/appliedsnar/fdc0d26f/03-sns.dta}{here}.

The codebook for the data provided here is in \protect\hyperlink{sns-data}{the appendix}.

The goals for this chapter are:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Read the data into R,
\item
  Create a network with it,
\item
  Compute descriptive statistics
\item
  Visualize the network
\end{enumerate}

\hypertarget{data-preprocessing}{%
\section{Data preprocessing}\label{data-preprocessing}}

\hypertarget{reading-the-data-into-r}{%
\subsection{Reading the data into R}\label{reading-the-data-into-r}}

R has several ways of reading data. Your data can be Raw plain files like CSV, tab-delimited, or specified by column width. To read plain-text data, you can use the \href{https://cran.r-project.org/package=readr}{\texttt{readr}} package (Wickham, Hester, and Francois \protect\hyperlink{ref-R-readr}{2017}). In the case of binary files, like Stata, Octave, or SPSS files, you can use the R package \href{https://cran.r-project.org/package=readr}{\texttt{foreign}} (R Core Team \protect\hyperlink{ref-R-foreign}{2017}\protect\hyperlink{ref-R-foreign}{a}). If your data is formatted as Microsoft spreadsheets, the \href{https://cran.r-project.org/package=readxl}{\texttt{readxl}} R package (Wickham and Bryan \protect\hyperlink{ref-R-readxl}{2017}) is the alternative to use. In our case, the data for this session is in Stata format:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(foreign)}

\CommentTok{# Reading the data}
\NormalTok{dat <-}\StringTok{ }\NormalTok{foreign}\OperatorTok{::}\KeywordTok{read.dta}\NormalTok{(}\StringTok{"03-sns.dta"}\NormalTok{)}

\CommentTok{# Taking a look at the data's first 5 columns and 5 rows}
\NormalTok{dat[}\DecValTok{1}\OperatorTok{:}\DecValTok{5}\NormalTok{, }\DecValTok{1}\OperatorTok{:}\DecValTok{10}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   photoid school hispanic female1 female2 female3 female4 grades1 grades2
## 1       1    111        1      NA      NA       0       0      NA      NA
## 2       2    111        1       0      NA      NA       0     3.0      NA
## 3       7    111        0       1       1       1       1     5.0     4.5
## 4      13    111        1       1       1       1       1     2.5     2.5
## 5      14    111        1       1       1       1      NA     3.0     3.5
##   grades3
## 1     3.5
## 2      NA
## 3     4.0
## 4     2.5
## 5     3.5
\end{verbatim}

\hypertarget{creating-a-unique-id-for-each-participant}{%
\subsection{Creating a unique id for each participant}\label{creating-a-unique-id-for-each-participant}}

Now suppose that we want to create a unique id using the school and photo id. In this case, since both variables are numeric, a good way of doing it is to encode the id. For example, the last three numbers are the photoid and the first ones are the school id. To do this, we need to take into account the range of the variables:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(photo_id_ran <-}\StringTok{ }\KeywordTok{range}\NormalTok{(dat}\OperatorTok{$}\NormalTok{photoid))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]    1 2074
\end{verbatim}

As the variable spans up to 2074, we need to set the last 4 units of the variable to store the \texttt{photoid}. We will use \texttt{dplyr} (Wickham et al. \protect\hyperlink{ref-R-dplyr}{2017}) and \texttt{magrittr} (Bache and Wickham \protect\hyperlink{ref-R-magrittr}{2014}){]} (the pipe operator, \texttt{\%\textgreater{}\%}) to create this variable, and we will call it\ldots{} \texttt{id} (mind blowing, right?):

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(dplyr)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Attaching package: 'dplyr'
\end{verbatim}

\begin{verbatim}
## The following objects are masked from 'package:stats':
## 
##     filter, lag
\end{verbatim}

\begin{verbatim}
## The following objects are masked from 'package:base':
## 
##     intersect, setdiff, setequal, union
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(magrittr)}

\NormalTok{(dat }\OperatorTok{%<>%}\StringTok{ }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{id =}\NormalTok{ school}\OperatorTok{*}\DecValTok{10000} \OperatorTok{+}\StringTok{ }\NormalTok{photoid)) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{head }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(school, photoid, id)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   school photoid      id
## 1    111       1 1110001
## 2    111       2 1110002
## 3    111       7 1110007
## 4    111      13 1110013
## 5    111      14 1110014
## 6    111      15 1110015
\end{verbatim}

Wow, what happened in the last three lines of code! What is that \texttt{\%\textgreater{}\%}? Well, that's the \href{http://r4ds.had.co.nz/pipes.html}{pipe operator}, and it is an appealing way of writing nested function calls. In this case, instead of writing something like:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dat_filtered}\OperatorTok{$}\NormalTok{id <-}\StringTok{ }\NormalTok{dat_filtered}\OperatorTok{$}\NormalTok{school}\OperatorTok{*}\DecValTok{10000} \OperatorTok{+}\StringTok{ }\NormalTok{dat_filtered}\OperatorTok{$}\NormalTok{photoid}
\KeywordTok{subset}\NormalTok{(}\KeywordTok{head}\NormalTok{(dat_filtered), }\DataTypeTok{select =} \KeywordTok{c}\NormalTok{(school, photoid, id))}
\end{Highlighting}
\end{Shaded}

\hypertarget{creating-a-network}{%
\section{Creating a network}\label{creating-a-network}}

\begin{itemize}
\item
  We want to build a social network. For that, we either use an adjacency matrix or an edgelist.
\item
  Each individual of the SNS data nominated 19 friends from school. We will use those nominations to create the social network.
\item
  In this case, we will create the network by coercing the dataset into an edgelist.
\end{itemize}

\hypertarget{from-survey-to-edgelist}{%
\subsection{From survey to edgelist}\label{from-survey-to-edgelist}}

Let's start by loading a couple of handy R packages. We will load \texttt{tidyr} (Wickham and Henry \protect\hyperlink{ref-R-tidyr}{2017}) and \texttt{stringr} (Wickham \protect\hyperlink{ref-R-stringr}{2017}). We will use the first, \texttt{tidyr}, to reshape the data. The second, \texttt{stringr}, will help us processing strings using \emph{regular expressions}\footnote{Please refer to the help file \texttt{?\textquotesingle{}regular\ expression\textquotesingle{}} in R. The R package \texttt{rex} (Ushey, Hester, and Krzyzanowski \protect\hyperlink{ref-R-rex}{2017}) is a very nice companion for writing regular expressions. There's also a neat (but experimental) RStudio add-in that can be very helpful for understanding how regular expressions work, the \href{https://github.com/gadenbuie/regexplain}{regexplain} add-in.}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyr)}
\KeywordTok{library}\NormalTok{(stringr)}
\end{Highlighting}
\end{Shaded}

Optionally, we can use the \texttt{tibble} type of object, which is an alternative to the actual \texttt{data.frame}. This object is said to provide \emph{more efficient methods for matrices and data frames}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dat <-}\StringTok{ }\KeywordTok{as_tibble}\NormalTok{(dat)}
\end{Highlighting}
\end{Shaded}

What I like from \texttt{tibbles} is that when you print them on the console, these actually look nice:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dat}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2,164 x 100
##    photoid school hispanic female1 female2 female3 female4 grades1 grades2
##      <int>  <int>    <dbl>   <int>   <int>   <int>   <int>   <dbl>   <dbl>
##  1       1    111        1      NA      NA       0       0    NA      NA  
##  2       2    111        1       0      NA      NA       0     3      NA  
##  3       7    111        0       1       1       1       1     5       4.5
##  4      13    111        1       1       1       1       1     2.5     2.5
##  5      14    111        1       1       1       1      NA     3       3.5
##  6      15    111        1       0       0       0       0     2.5     2.5
##  7      20    111        1       1       1       1       1     2.5     2.5
##  8      22    111        1      NA      NA       0       0    NA      NA  
##  9      25    111        0       1       1      NA       1     4.5     3.5
## 10      27    111        1       0      NA       0       0     3.5    NA  
## # ... with 2,154 more rows, and 91 more variables: grades3 <dbl>,
## #   grades4 <dbl>, eversmk1 <int>, eversmk2 <int>, eversmk3 <int>,
## #   eversmk4 <int>, everdrk1 <int>, everdrk2 <int>, everdrk3 <int>,
## #   everdrk4 <int>, home1 <int>, home2 <int>, home3 <int>, home4 <int>,
## #   sch_friend11 <int>, sch_friend12 <int>, sch_friend13 <int>,
## #   sch_friend14 <int>, sch_friend15 <int>, sch_friend16 <int>,
## #   sch_friend17 <int>, sch_friend18 <int>, sch_friend19 <int>, ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Maybe too much piping... but its cool!}
\NormalTok{net <-}\StringTok{ }\NormalTok{dat }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{select}\NormalTok{(id, school, }\KeywordTok{starts_with}\NormalTok{(}\StringTok{"sch_friend"}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gather}\NormalTok{(}\DataTypeTok{key =} \StringTok{"varname"}\NormalTok{, }\DataTypeTok{value =} \StringTok{"content"}\NormalTok{, }\OperatorTok{-}\NormalTok{id, }\OperatorTok{-}\NormalTok{school) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(}\OperatorTok{!}\KeywordTok{is.na}\NormalTok{(content)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{friendid =}\NormalTok{ school}\OperatorTok{*}\DecValTok{10000} \OperatorTok{+}\StringTok{ }\NormalTok{content,}
    \DataTypeTok{year     =} \KeywordTok{as.integer}\NormalTok{(}\KeywordTok{str_extract}\NormalTok{(varname, }\StringTok{"(?<=[a-z])[0-9]"}\NormalTok{)),}
    \DataTypeTok{nnom     =} \KeywordTok{as.integer}\NormalTok{(}\KeywordTok{str_extract}\NormalTok{(varname, }\StringTok{"(?<=[a-z][0-9])[0-9]+"}\NormalTok{))}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

Let's take a look at this step by step:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  First, we subset the data: We want to keep \texttt{id,\ school,\ sch\_friend*.} For the later, we use the function \texttt{starts\_with} (from the \texttt{tidyselect} package). The latter allows us to select all variables that start with the word ``\texttt{sch\_friend}'', which means that \texttt{sch\_friend11,\ sch\_friend12,\ ...} will be selected.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dat }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{select}\NormalTok{(id, school, }\KeywordTok{starts_with}\NormalTok{(}\StringTok{"sch_friend"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2,164 x 78
##         id school sch_friend11 sch_friend12 sch_friend13 sch_friend14
##      <dbl>  <int>        <int>        <int>        <int>        <int>
##  1 1110001    111           NA           NA           NA           NA
##  2 1110002    111          424          423          426          289
##  3 1110007    111          629          505           NA           NA
##  4 1110013    111          232          569           NA           NA
##  5 1110014    111          582          134           41          592
##  6 1110015    111           26          488           81          138
##  7 1110020    111          528           NA          492          395
##  8 1110022    111           NA           NA           NA           NA
##  9 1110025    111          135          185          553           84
## 10 1110027    111          346          168          559            5
## # ... with 2,154 more rows, and 72 more variables: sch_friend15 <int>,
## #   sch_friend16 <int>, sch_friend17 <int>, sch_friend18 <int>,
## #   sch_friend19 <int>, sch_friend110 <int>, sch_friend111 <int>,
## #   sch_friend112 <int>, sch_friend113 <int>, sch_friend114 <int>,
## #   sch_friend115 <int>, sch_friend116 <int>, sch_friend117 <int>,
## #   sch_friend118 <int>, sch_friend119 <int>, sch_friend21 <int>,
## #   sch_friend22 <int>, sch_friend23 <int>, sch_friend24 <int>, ...
\end{verbatim}
\item
  Then, we reshape it to \emph{long} format: By transposing all the \texttt{sch\_friend*} to long format. We do this using the function \texttt{gather} (from the \texttt{tidyr} package); an alternative to the \texttt{reshape} function, which I find easier to use. Let's see how it works:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dat }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{select}\NormalTok{(id, school, }\KeywordTok{starts_with}\NormalTok{(}\StringTok{"sch_friend"}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gather}\NormalTok{(}\DataTypeTok{key =} \StringTok{"varname"}\NormalTok{, }\DataTypeTok{value =} \StringTok{"content"}\NormalTok{, }\OperatorTok{-}\NormalTok{id, }\OperatorTok{-}\NormalTok{school)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 164,464 x 4
##         id school varname      content
##      <dbl>  <int> <chr>          <int>
##  1 1110001    111 sch_friend11      NA
##  2 1110002    111 sch_friend11     424
##  3 1110007    111 sch_friend11     629
##  4 1110013    111 sch_friend11     232
##  5 1110014    111 sch_friend11     582
##  6 1110015    111 sch_friend11      26
##  7 1110020    111 sch_friend11     528
##  8 1110022    111 sch_friend11      NA
##  9 1110025    111 sch_friend11     135
## 10 1110027    111 sch_friend11     346
## # ... with 164,454 more rows
\end{verbatim}

  In this case, the \texttt{key} parameter sets the name of the variable that will contain the name of the variable that was reshaped, while \texttt{value} is the name of the variable that will hold the content of the data (that's why I named those like that). The \texttt{-id,\ -school} bit tells the function to ``drop'' those variables before reshaping. In other words, ``reshape everything but \texttt{id} and \texttt{school.}''

  Also, notice that we passed from 2164 rows to 19 (nominations) * 2164 (subjects) * 4 (waves) = 164464 rows, as expected.
\item
  As the nomination data can be empty for some cells, we need to take care of those cases, the \texttt{NA}s, so we filter the data:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dat }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{select}\NormalTok{(id, school, }\KeywordTok{starts_with}\NormalTok{(}\StringTok{"sch_friend"}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gather}\NormalTok{(}\DataTypeTok{key =} \StringTok{"varname"}\NormalTok{, }\DataTypeTok{value =} \StringTok{"content"}\NormalTok{, }\OperatorTok{-}\NormalTok{id, }\OperatorTok{-}\NormalTok{school) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(}\OperatorTok{!}\KeywordTok{is.na}\NormalTok{(content))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 39,561 x 4
##         id school varname      content
##      <dbl>  <int> <chr>          <int>
##  1 1110002    111 sch_friend11     424
##  2 1110007    111 sch_friend11     629
##  3 1110013    111 sch_friend11     232
##  4 1110014    111 sch_friend11     582
##  5 1110015    111 sch_friend11      26
##  6 1110020    111 sch_friend11     528
##  7 1110025    111 sch_friend11     135
##  8 1110027    111 sch_friend11     346
##  9 1110029    111 sch_friend11     369
## 10 1110030    111 sch_friend11     462
## # ... with 39,551 more rows
\end{verbatim}
\item
  And finally, we create three new variables from this dataset: \texttt{friendid,}, \texttt{year}, and \texttt{nom\_num} (nomination number). All using regular expressions:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dat }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{select}\NormalTok{(id, school, }\KeywordTok{starts_with}\NormalTok{(}\StringTok{"sch_friend"}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gather}\NormalTok{(}\DataTypeTok{key =} \StringTok{"varname"}\NormalTok{, }\DataTypeTok{value =} \StringTok{"content"}\NormalTok{, }\OperatorTok{-}\NormalTok{id, }\OperatorTok{-}\NormalTok{school) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(}\OperatorTok{!}\KeywordTok{is.na}\NormalTok{(content)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{friendid =}\NormalTok{ school}\OperatorTok{*}\DecValTok{10000} \OperatorTok{+}\StringTok{ }\NormalTok{content,}
    \DataTypeTok{year     =} \KeywordTok{as.integer}\NormalTok{(}\KeywordTok{str_extract}\NormalTok{(varname, }\StringTok{"(?<=[a-z])[0-9]"}\NormalTok{)),}
    \DataTypeTok{nnom     =} \KeywordTok{as.integer}\NormalTok{(}\KeywordTok{str_extract}\NormalTok{(varname, }\StringTok{"(?<=[a-z][0-9])[0-9]+"}\NormalTok{))}
\NormalTok{    )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 39,561 x 7
##         id school varname      content friendid  year  nnom
##      <dbl>  <int> <chr>          <int>    <dbl> <int> <int>
##  1 1110002    111 sch_friend11     424  1110424     1     1
##  2 1110007    111 sch_friend11     629  1110629     1     1
##  3 1110013    111 sch_friend11     232  1110232     1     1
##  4 1110014    111 sch_friend11     582  1110582     1     1
##  5 1110015    111 sch_friend11      26  1110026     1     1
##  6 1110020    111 sch_friend11     528  1110528     1     1
##  7 1110025    111 sch_friend11     135  1110135     1     1
##  8 1110027    111 sch_friend11     346  1110346     1     1
##  9 1110029    111 sch_friend11     369  1110369     1     1
## 10 1110030    111 sch_friend11     462  1110462     1     1
## # ... with 39,551 more rows
\end{verbatim}

  The regular expression \texttt{(?\textless{}={[}a-z{]})} matches a string preceded by any letter from \emph{a} to \emph{z}. In contrast, the expression \texttt{{[}0-9{]}} matches a single number. Hence, from the string \texttt{"sch\_friend12"}, the regular expression will only match the \texttt{1}, as it is the only number followed by a letter. The expression \texttt{(?\textless{}={[}a-z{]}{[}0-9{]})} matches a string preceded by a lower case letter and a one-digit number. Finally, the expression \texttt{{[}0-9{]}+} matches a string of numbers--so it could be more than one. Hence, from the string \texttt{"sch\_friend12"}, we will get \texttt{2}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{str_extract}\NormalTok{(}\StringTok{"sch_friend12"}\NormalTok{, }\StringTok{"(?<=[a-z])[0-9]"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "1"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{str_extract}\NormalTok{(}\StringTok{"sch_friend12"}\NormalTok{, }\StringTok{"(?<=[a-z][0-9])[0-9]+"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "2"
\end{verbatim}

  And finally, the \texttt{as.integer} function coerces the returning value from the \texttt{str\_extract} function from \texttt{character} to \texttt{integer}. Now that we have this edgelist, we can create an igraph object
\end{enumerate}

\hypertarget{igraph-network}{%
\subsection{igraph network}\label{igraph-network}}

For coercing the edgelist into an igraph object, we will be using the \texttt{graph\_from\_data\_frame} function in igraph (Csardi and Nepusz \protect\hyperlink{ref-R-igraph}{2006}). This function receives the following arguments: a data frame where the two first columns are ``source'' (ego) and ``target'' (alter), an indicator of whether the network is directed or not, and an optional data frame with vertices, in which's first column should contain the vertex ids.

Using the optional \texttt{vertices} argument is a good practice since, by doing so, you are telling the function what ids that you are expecting to find. Using the original dataset, we will create a data frame name vertices:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vertex_attrs <-}\StringTok{ }\NormalTok{dat }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{select}\NormalTok{(id, school, hispanic, female1, }\KeywordTok{starts_with}\NormalTok{(}\StringTok{"eversmk"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Now, let's now use the function \texttt{graph\_from\_data\_frame} to create an \texttt{igraph} object:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(igraph)}

\NormalTok{ig_year1 <-}\StringTok{ }\NormalTok{net }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(year }\OperatorTok{==}\StringTok{ "1"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{select}\NormalTok{(id, friendid, nnom) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{graph_from_data_frame}\NormalTok{(}
    \DataTypeTok{vertices =}\NormalTok{ vertex_attrs}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Error in graph_from_data_frame(., vertices = vertex_attrs): Some vertex names in edge list are not listed in vertex data frame
\end{verbatim}

Ups! It seems that individuals are making nominations to other students not included in the survey. How to solve that? Well, it all depends on what you need to do! In this case, we will go for the \emph{quietly-remove-em'-and-don't-tell} strategy:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ig_year1 <-}\StringTok{ }\NormalTok{net }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(year }\OperatorTok{==}\StringTok{ "1"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }
\StringTok{  }\CommentTok{# Extra line, all nominations must be in ego too.}
\StringTok{  }\KeywordTok{filter}\NormalTok{(friendid }\OperatorTok{%in%}\StringTok{ }\NormalTok{id) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }
\StringTok{  }\KeywordTok{select}\NormalTok{(id, friendid, nnom) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{graph_from_data_frame}\NormalTok{(}
    \DataTypeTok{vertices =}\NormalTok{ vertex_attrs}
\NormalTok{    )}

\NormalTok{ig_year1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## IGRAPH 832e763 DN-- 2164 9514 -- 
## + attr: name (v/c), school (v/n), hispanic (v/n), female1 (v/n),
## | eversmk1 (v/n), eversmk2 (v/n), eversmk3 (v/n), eversmk4 (v/n), nnom
## | (e/n)
## + edges from 832e763 (vertex names):
##  [1] 1110007->1110629 1110013->1110232 1110014->1110582 1110015->1110026
##  [5] 1110025->1110135 1110027->1110346 1110029->1110369 1110035->1110034
##  [9] 1110040->1110390 1110041->1110557 1110044->1110027 1110046->1110030
## [13] 1110050->1110086 1110057->1110263 1110069->1110544 1110071->1110167
## [17] 1110072->1110289 1110073->1110014 1110075->1110352 1110084->1110305
## [21] 1110086->1110206 1110093->1110040 1110094->1110483 1110095->1110043
## + ... omitted several edges
\end{verbatim}

So there we have our network with 2164 nodes and 9514 edges. The following steps: get some descriptive stats and visualize our network.

\hypertarget{network-descriptive-stats}{%
\section{Network descriptive stats}\label{network-descriptive-stats}}

While we could do all networks at once, in this part, we will focus on computing some network statistics for one of the schools only. We start by school 111. The first question that you should be asking yourself now is, ``how can I get that information from the igraph object?.'' Vertex and edges attributes can be accessed via the \texttt{V} and \texttt{E} functions, respectively; moreover, we can list what vertex/edge attributes are available:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{list.vertex.attributes}\NormalTok{(ig_year1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "name"     "school"   "hispanic" "female1"  "eversmk1" "eversmk2" "eversmk3"
## [8] "eversmk4"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{list.edge.attributes}\NormalTok{(ig_year1) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "nnom"
\end{verbatim}

Just like we would do with data frames, accessing vertex attributes is done via the dollar sign operator \texttt{\$}. Together with the \texttt{V} function; for example, accessing the first ten elements of the variable \texttt{hispanic} can be done as follows:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{V}\NormalTok{(ig_year1)}\OperatorTok{$}\NormalTok{hispanic[}\DecValTok{1}\OperatorTok{:}\DecValTok{10}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 1 1 0 1 1 1 1 1 0 1
\end{verbatim}

Now that you know how to access vertex attributes, we can get the network corresponding to school 111 by identifying which vertices are part of it and pass that information to the \texttt{induced\_subgraph} function:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Which ids are from school 111?}
\NormalTok{school111ids <-}\StringTok{ }\KeywordTok{which}\NormalTok{(}\KeywordTok{V}\NormalTok{(ig_year1)}\OperatorTok{$}\NormalTok{school }\OperatorTok{==}\StringTok{ }\DecValTok{111}\NormalTok{)}

\CommentTok{# Creating a subgraph}
\NormalTok{ig_year1_}\DecValTok{111}\NormalTok{ <-}\StringTok{ }\KeywordTok{induced_subgraph}\NormalTok{(}
  \DataTypeTok{graph =}\NormalTok{ ig_year1,}
  \DataTypeTok{vids  =}\NormalTok{ school111ids}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The \texttt{which} function in R returns a vector of indices indicating which elements pass the test, returning true and false, otherwise. In our case, it will result in a vector of indices of the vertices which have the attribute \texttt{school} equal to 111. With the subgraph, we can compute different centrality measures\footnote{For more information about the different centrality measurements, please take a look at the ``Centrality'' article on \href{https://en.wikipedia.org/wiki/Centrality}{Wikipedia}.} for each vertex and store them in the igraph object itself:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Computing centrality measures for each vertex}
\KeywordTok{V}\NormalTok{(ig_year1_}\DecValTok{111}\NormalTok{)}\OperatorTok{$}\NormalTok{indegree   <-}\StringTok{ }\KeywordTok{degree}\NormalTok{(ig_year1_}\DecValTok{111}\NormalTok{, }\DataTypeTok{mode =} \StringTok{"in"}\NormalTok{)}
\KeywordTok{V}\NormalTok{(ig_year1_}\DecValTok{111}\NormalTok{)}\OperatorTok{$}\NormalTok{outdegree  <-}\StringTok{ }\KeywordTok{degree}\NormalTok{(ig_year1_}\DecValTok{111}\NormalTok{, }\DataTypeTok{mode =} \StringTok{"out"}\NormalTok{)}
\KeywordTok{V}\NormalTok{(ig_year1_}\DecValTok{111}\NormalTok{)}\OperatorTok{$}\NormalTok{closeness  <-}\StringTok{ }\KeywordTok{closeness}\NormalTok{(ig_year1_}\DecValTok{111}\NormalTok{, }\DataTypeTok{mode =} \StringTok{"total"}\NormalTok{)}
\KeywordTok{V}\NormalTok{(ig_year1_}\DecValTok{111}\NormalTok{)}\OperatorTok{$}\NormalTok{betweeness <-}\StringTok{ }\KeywordTok{betweenness}\NormalTok{(ig_year1_}\DecValTok{111}\NormalTok{, }\DataTypeTok{normalized =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

From here, we can \emph{go back} to our old habits and get the set of vertex attributes as a data frame so we can compute some summary statistics on the centrality measurements that we just got

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Extracting each vectex features as a data.frame}
\NormalTok{stats <-}\StringTok{ }\KeywordTok{as_data_frame}\NormalTok{(ig_year1_}\DecValTok{111}\NormalTok{, }\DataTypeTok{what =} \StringTok{"vertices"}\NormalTok{)}

\CommentTok{# Computing quantiles for each variable}
\NormalTok{stats_degree <-}\StringTok{ }\KeywordTok{with}\NormalTok{(stats, \{}
 \KeywordTok{cbind}\NormalTok{(}
   \DataTypeTok{indegree   =} \KeywordTok{quantile}\NormalTok{(indegree, }\KeywordTok{c}\NormalTok{(.}\DecValTok{025}\NormalTok{, }\FloatTok{.5}\NormalTok{, }\FloatTok{.975}\NormalTok{), }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{),}
   \DataTypeTok{outdegree  =} \KeywordTok{quantile}\NormalTok{(outdegree, }\KeywordTok{c}\NormalTok{(.}\DecValTok{025}\NormalTok{, }\FloatTok{.5}\NormalTok{, }\FloatTok{.975}\NormalTok{), }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{),}
   \DataTypeTok{closeness  =} \KeywordTok{quantile}\NormalTok{(closeness, }\KeywordTok{c}\NormalTok{(.}\DecValTok{025}\NormalTok{, }\FloatTok{.5}\NormalTok{, }\FloatTok{.975}\NormalTok{), }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{),}
   \DataTypeTok{betweeness =} \KeywordTok{quantile}\NormalTok{(betweeness, }\KeywordTok{c}\NormalTok{(.}\DecValTok{025}\NormalTok{, }\FloatTok{.5}\NormalTok{, }\FloatTok{.975}\NormalTok{), }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{)}
\NormalTok{ )}
\NormalTok{\})}

\NormalTok{stats_degree}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       indegree outdegree    closeness  betweeness
## 2.5%         0         0 0.0005915148 0.000000000
## 50%          4         4 0.0007487833 0.001879006
## 97.5%       16        16 0.0008838413 0.016591048
\end{verbatim}

The \texttt{with} function is somewhat similar to what \texttt{dplyr} allows us to do when we want to work with the dataset but without mentioning its name everytime that we ask for a variable. Without using the \texttt{with} function, the previous could have been done as follows:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stats_degree <-}\StringTok{ }
\StringTok{ }\KeywordTok{cbind}\NormalTok{(}
   \DataTypeTok{indegree   =} \KeywordTok{quantile}\NormalTok{(stats}\OperatorTok{$}\NormalTok{indegree, }\KeywordTok{c}\NormalTok{(.}\DecValTok{025}\NormalTok{, }\FloatTok{.5}\NormalTok{, }\FloatTok{.975}\NormalTok{), }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{),}
   \DataTypeTok{outdegree  =} \KeywordTok{quantile}\NormalTok{(stats}\OperatorTok{$}\NormalTok{outdegree, }\KeywordTok{c}\NormalTok{(.}\DecValTok{025}\NormalTok{, }\FloatTok{.5}\NormalTok{, }\FloatTok{.975}\NormalTok{), }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{),}
   \DataTypeTok{closeness  =} \KeywordTok{quantile}\NormalTok{(stats}\OperatorTok{$}\NormalTok{closeness, }\KeywordTok{c}\NormalTok{(.}\DecValTok{025}\NormalTok{, }\FloatTok{.5}\NormalTok{, }\FloatTok{.975}\NormalTok{), }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{),}
   \DataTypeTok{betweeness =} \KeywordTok{quantile}\NormalTok{(stats}\OperatorTok{$}\NormalTok{betweeness, }\KeywordTok{c}\NormalTok{(.}\DecValTok{025}\NormalTok{, }\FloatTok{.5}\NormalTok{, }\FloatTok{.975}\NormalTok{), }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{)}
\NormalTok{ )}
\end{Highlighting}
\end{Shaded}

Now we will compute some statistics at the graph level:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{cbind}\NormalTok{(}
  \DataTypeTok{size    =} \KeywordTok{vcount}\NormalTok{(ig_year1_}\DecValTok{111}\NormalTok{),}
  \DataTypeTok{nedges  =} \KeywordTok{ecount}\NormalTok{(ig_year1_}\DecValTok{111}\NormalTok{),}
  \DataTypeTok{density =} \KeywordTok{edge_density}\NormalTok{(ig_year1_}\DecValTok{111}\NormalTok{),}
  \DataTypeTok{recip   =} \KeywordTok{reciprocity}\NormalTok{(ig_year1_}\DecValTok{111}\NormalTok{),}
  \DataTypeTok{centr   =} \KeywordTok{centr_betw}\NormalTok{(ig_year1_}\DecValTok{111}\NormalTok{)}\OperatorTok{$}\NormalTok{centralization,}
  \DataTypeTok{pathLen =} \KeywordTok{mean_distance}\NormalTok{(ig_year1_}\DecValTok{111}\NormalTok{)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      size nedges     density     recip      centr pathLen
## [1,]  533   2638 0.009303277 0.3731513 0.02179154 4.23678
\end{verbatim}

Triadic census

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{triadic <-}\StringTok{ }\KeywordTok{triad_census}\NormalTok{(ig_year1_}\DecValTok{111}\NormalTok{)}
\NormalTok{triadic}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 24059676   724389   290849     3619     3383     4401     3219     2997
##  [9]      407       33      836      235      163      137      277       85
\end{verbatim}

To get a nicer view of this, we can use a table that I retrieved from \texttt{?triad\_census}. Moreover, we can normalize the \texttt{triadic} object by its sum instead of looking at raw counts. That way, we get proportions instead\footnote{During our workshop, Prof.~De la Haye suggested using \({n \choose 3}\) as a normalizing constant. It turns out that \texttt{sum(triadic)\ =\ choose(n,\ 3)}! So either approach is correct.}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}\KeywordTok{cbind}\NormalTok{(}
  \DataTypeTok{Pcent =}\NormalTok{ triadic}\OperatorTok{/}\KeywordTok{sum}\NormalTok{(triadic)}\OperatorTok{*}\DecValTok{100}\NormalTok{,}
  \KeywordTok{read.csv}\NormalTok{(}\StringTok{"triadic_census.csv"}\NormalTok{)}
\NormalTok{  ), }\DataTypeTok{digits =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{r|l|l}
\hline
Pcent & code & description\\
\hline
95.88 & 003 & A,B,C, the empty graph.\\
\hline
2.89 & 012 & A->B, C, the graph with a single directed edge.\\
\hline
1.16 & 102 & A<->B, C, the graph with a mutual connection between two vertices.\\
\hline
0.01 & 021D & A<-B->C, the out-star.\\
\hline
0.01 & 021U & A->B<-C, the in-star.\\
\hline
0.02 & 021C & A->B->C, directed line.\\
\hline
0.01 & 111D & A<->B<-C.\\
\hline
0.01 & 111U & A<->B->C.\\
\hline
0.00 & 030T & A->B<-C, A->C.\\
\hline
0.00 & 030C & A<-B<-C, A->C.\\
\hline
0.00 & 201 & A<->B<->C.\\
\hline
0.00 & 120D & A<-B->C, A<->C.\\
\hline
0.00 & 120U & A->B<-C, A<->C.\\
\hline
0.00 & 120C & A->B->C, A<->C.\\
\hline
0.00 & 210 & A->B<->C, A<->C.\\
\hline
0.00 & 300 & A<->B<->C, A<->C, the complete graph.\\
\hline
\end{tabular}

\hypertarget{plotting-the-network-in-igraph}{%
\section{Plotting the network in igraph}\label{plotting-the-network-in-igraph}}

\hypertarget{single-plot}{%
\subsection{Single plot}\label{single-plot}}

Let's take a look at how does our network looks like when we use the default parameters in the plot method of the igraph object:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(ig_year1)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{03-week-1-sns-study_files/figure-latex/03-plot-raw-1} 

}

\caption{A not very nice network plot. This is what we get with the default parameters in igraph.}\label{fig:03-plot-raw}
\end{figure}

Not very nice, right? A couple of things with this plot:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  We are looking at all schools simultaneously, which does not make sense. So, instead of plotting \texttt{ig\_year1}, we will focus on \texttt{ig\_year1\_111}.
\item
  All the vertices have the same size and are overlapping. Instead of using the default size, we will size the vertices by indegree using the \texttt{degree} function and passing the vector of degrees to \texttt{vertex.size}.\footnote{Figuring out what is the optimal vertex size is a bit tricky. Without getting too technical, there's no other way of getting \emph{nice} vertex size other than just playing with different values of it. A nice solution to this is using \href{https://www.rdocumentation.org/packages/netdiffuseR/versions/1.17.0/topics/rescale_vertex_igraph}{\texttt{netdiffuseR::igraph\_vertex\_rescale}} which rescales the vertices so that these keep their aspect ratio to a predefined proportion of the screen.}
\item
  Given the number of vertices in these networks, the labels are not useful here. So we will remove them by setting \texttt{vertex.label\ =\ NA}. Moreover, we will reduce the size of the arrows' tip by setting \texttt{edge.arrow.size\ =\ 0.25}.
\item
  And finally, we will set the color of each vertex to be a function of whether the individual is Hispanic or not. For this last bit we need to go a bit more of programming:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{col_hispanic <-}\StringTok{ }\KeywordTok{V}\NormalTok{(ig_year1_}\DecValTok{111}\NormalTok{)}\OperatorTok{$}\NormalTok{hispanic }\OperatorTok{+}\StringTok{ }\DecValTok{1}
\NormalTok{col_hispanic <-}\StringTok{ }\KeywordTok{coalesce}\NormalTok{(col_hispanic, }\DecValTok{3}\NormalTok{) }
\NormalTok{col_hispanic <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"steelblue"}\NormalTok{, }\StringTok{"tomato"}\NormalTok{, }\StringTok{"white"}\NormalTok{)[col_hispanic]}
\end{Highlighting}
\end{Shaded}

Line by line, we did the following:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The first line added one to all no \texttt{NA} values so that the 0s (non-Hispanic) turned to 1s and the 1s (Hispanic) turned to 2s.
\item
  The second line replaced all \texttt{NA}s with the number three so that our vector \texttt{col\_hispanic} now ranges from one to three with no \texttt{NA}s in it.
\item
  In the last line, we created a vector of colors. Essentially, what we are doing here is telling R to create a vector of length \texttt{length(col\_hispanic)} by selecting elements by index from the vector \texttt{c("steelblue",\ "tomato",\ "white")}. This way, if, for example, the first element of the vector \texttt{col\_hispanic} was a 3, our new vector of colors would have a \texttt{"white"} in it.
\end{enumerate}

To make sure we know we are right, let's print the first 10 elements of our new vector of colors together with the original \texttt{hispanic} column:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{cbind}\NormalTok{(}
  \DataTypeTok{original =} \KeywordTok{V}\NormalTok{(ig_year1_}\DecValTok{111}\NormalTok{)}\OperatorTok{$}\NormalTok{hispanic[}\DecValTok{1}\OperatorTok{:}\DecValTok{10}\NormalTok{],}
  \DataTypeTok{colors   =}\NormalTok{ col_hispanic[}\DecValTok{1}\OperatorTok{:}\DecValTok{10}\NormalTok{]}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       original colors     
##  [1,] "1"      "tomato"   
##  [2,] "1"      "tomato"   
##  [3,] "0"      "steelblue"
##  [4,] "1"      "tomato"   
##  [5,] "1"      "tomato"   
##  [6,] "1"      "tomato"   
##  [7,] "1"      "tomato"   
##  [8,] "1"      "tomato"   
##  [9,] "0"      "steelblue"
## [10,] "1"      "tomato"
\end{verbatim}

With our nice vector of colors, now we can pass it to \texttt{plot.igraph} (which we call implicitly by just calling \texttt{plot}), via the \texttt{vertex.color} argument:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Fancy graph}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(}
\NormalTok{  ig_year1_}\DecValTok{111}\NormalTok{,}
  \DataTypeTok{vertex.size     =} \KeywordTok{degree}\NormalTok{(ig_year1_}\DecValTok{111}\NormalTok{)}\OperatorTok{/}\DecValTok{10} \OperatorTok{+}\DecValTok{1}\NormalTok{,}
  \DataTypeTok{vertex.label    =} \OtherTok{NA}\NormalTok{,}
  \DataTypeTok{edge.arrow.size =} \FloatTok{.25}\NormalTok{,}
  \DataTypeTok{vertex.color    =}\NormalTok{ col_hispanic}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{03-week-1-sns-study_files/figure-latex/03-plot-neat1-1.pdf}
\caption{\label{fig:03-plot-neat1}Friends network in time 1 for school 111.}
\end{figure}

Nice! So it does look better. The only problem is that we have a lot of isolates. Let's try again by drawing the same plot without isolates. To do so, we need to filter the graph, for which we will use the function \texttt{induced\_subgraph}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Which vertices are not isolates?}
\NormalTok{which_ids <-}\StringTok{ }\KeywordTok{which}\NormalTok{(}\KeywordTok{degree}\NormalTok{(ig_year1_}\DecValTok{111}\NormalTok{, }\DataTypeTok{mode =} \StringTok{"total"}\NormalTok{) }\OperatorTok{>}\StringTok{ }\DecValTok{0}\NormalTok{)}

\CommentTok{# Getting the subgraph}
\NormalTok{ig_year1_}\DecValTok{111}\NormalTok{_sub <-}\StringTok{ }\KeywordTok{induced_subgraph}\NormalTok{(ig_year1_}\DecValTok{111}\NormalTok{, which_ids)}

\CommentTok{# We need to get the same subset in col_hispanic}
\NormalTok{col_hispanic <-}\StringTok{ }\NormalTok{col_hispanic[which_ids]}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Fancy graph}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(}
\NormalTok{  ig_year1_}\DecValTok{111}\NormalTok{_sub,}
  \DataTypeTok{vertex.size     =} \KeywordTok{degree}\NormalTok{(ig_year1_}\DecValTok{111}\NormalTok{_sub)}\OperatorTok{/}\DecValTok{5} \OperatorTok{+}\DecValTok{1}\NormalTok{,}
  \DataTypeTok{vertex.label    =} \OtherTok{NA}\NormalTok{,}
  \DataTypeTok{edge.arrow.size =} \FloatTok{.25}\NormalTok{,}
  \DataTypeTok{vertex.color    =}\NormalTok{ col_hispanic}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{03-week-1-sns-study_files/figure-latex/03-plot-neat2-1.pdf}
\caption{\label{fig:03-plot-neat2}Friends network in time 1 for school 111. The graph excludes isolates.}
\end{figure}

Now that's better! An interesting pattern that shows up is that individuals seem to cluster by whether they are Hispanic or not.

We can write this as a function to avoid copying and pasting the code \(n\) times (supposing that we want to create a plot similar to this \(n\) times). We do the latter in the following subsection.

\hypertarget{multiple-plots}{%
\subsection{Multiple plots}\label{multiple-plots}}

When you are repeating yourself repeatedly, it is a good idea to write down a sequence of commands as a function. In this case, since we will be running the same type of plot for all schools/waves, we write a function in which the only things that change are: (a) the school id, and (b) the color of the nodes.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{myplot <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(}
\NormalTok{  net,}
\NormalTok{  schoolid,}
  \DataTypeTok{mindgr =} \DecValTok{1}\NormalTok{,}
  \DataTypeTok{vcol   =} \StringTok{"tomato"}\NormalTok{,}
\NormalTok{  ...) \{}
  
  \CommentTok{# Creating a subgraph}
\NormalTok{  subnet <-}\StringTok{ }\KeywordTok{induced_subgraph}\NormalTok{(}
\NormalTok{    net,}
    \KeywordTok{which}\NormalTok{(}\KeywordTok{degree}\NormalTok{(net, }\DataTypeTok{mode =} \StringTok{"all"}\NormalTok{) }\OperatorTok{>=}\StringTok{ }\NormalTok{mindgr }\OperatorTok{&}\StringTok{ }\KeywordTok{V}\NormalTok{(net)}\OperatorTok{$}\NormalTok{school }\OperatorTok{==}\StringTok{ }\NormalTok{schoolid)}
\NormalTok{  )}
  
  \CommentTok{# Fancy graph}
  \KeywordTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
  \KeywordTok{plot}\NormalTok{(}
\NormalTok{    subnet,}
    \DataTypeTok{vertex.size     =} \KeywordTok{degree}\NormalTok{(subnet)}\OperatorTok{/}\DecValTok{5}\NormalTok{,}
    \DataTypeTok{vertex.label    =} \OtherTok{NA}\NormalTok{,}
    \DataTypeTok{edge.arrow.size =} \FloatTok{.25}\NormalTok{,}
    \DataTypeTok{vertex.color    =}\NormalTok{ vcol,}
\NormalTok{    ...}
\NormalTok{    )}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

The function definition:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The \texttt{myplot\ \textless{}-\ function({[}arguments{]})\ \{{[}body\ of\ the\ function{]}\}} tells R that we are going to create a function called \texttt{myplot}.
\item
  We declare four specific arguments: \texttt{net}, \texttt{schoolid}, \texttt{mindgr}, and \texttt{vcol}. These are an igraph object, the school id, the minimum degree that vertices must have to be included in the figure, and the color of the vertices. Observe that, compared to other programming languages, R does not require declaring the data types.
\item
  The ellipsis object, \texttt{...}, is an especial object in R that allows us to pass other arguments without specifying which. If you take a look at the \texttt{plot} bit in the function body, you will see that we also added \texttt{...}. We use the ellipsis to pass extra arguments (different from the ones that we explicitly defined) directly to \texttt{plot}. In practice, this implies that we can, for example, set the argument \texttt{edge.arrow.size} when calling \texttt{myplot}, even though we did not include it in the function definition! (See \texttt{?dotsMethods} in R for more details).
\end{enumerate}

In the following lines of code, using our new function, we will plot each schools' network in the same plotting device (window) with the help of the \texttt{par} function, and add legend with the \texttt{legend}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Plotting all together}
\NormalTok{oldpar <-}\StringTok{ }\KeywordTok{par}\NormalTok{(}\DataTypeTok{no.readonly =} \OtherTok{TRUE}\NormalTok{)}
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow =} \KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{), }\DataTypeTok{mai =} \KeywordTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{4}\NormalTok{), }\DataTypeTok{oma=} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{))}
\KeywordTok{myplot}\NormalTok{(ig_year1, }\DecValTok{111}\NormalTok{, }\DataTypeTok{vcol =} \StringTok{"tomato"}\NormalTok{)}
\KeywordTok{myplot}\NormalTok{(ig_year1, }\DecValTok{112}\NormalTok{, }\DataTypeTok{vcol =} \StringTok{"steelblue"}\NormalTok{)}
\KeywordTok{myplot}\NormalTok{(ig_year1, }\DecValTok{113}\NormalTok{, }\DataTypeTok{vcol =} \StringTok{"black"}\NormalTok{)}
\KeywordTok{myplot}\NormalTok{(ig_year1, }\DecValTok{114}\NormalTok{, }\DataTypeTok{vcol =} \StringTok{"gold"}\NormalTok{)}
\KeywordTok{myplot}\NormalTok{(ig_year1, }\DecValTok{115}\NormalTok{, }\DataTypeTok{vcol =} \StringTok{"white"}\NormalTok{)}
\KeywordTok{par}\NormalTok{(oldpar)}

\CommentTok{# A fancy legend}
\KeywordTok{legend}\NormalTok{(}
  \StringTok{"bottomright"}\NormalTok{,}
  \DataTypeTok{legend =} \KeywordTok{c}\NormalTok{(}\DecValTok{111}\NormalTok{, }\DecValTok{112}\NormalTok{, }\DecValTok{113}\NormalTok{, }\DecValTok{114}\NormalTok{, }\DecValTok{115}\NormalTok{),}
  \DataTypeTok{pt.bg  =} \KeywordTok{c}\NormalTok{(}\StringTok{"tomato"}\NormalTok{, }\StringTok{"steelblue"}\NormalTok{, }\StringTok{"black"}\NormalTok{, }\StringTok{"gold"}\NormalTok{, }\StringTok{"white"}\NormalTok{),}
  \DataTypeTok{pch    =} \DecValTok{21}\NormalTok{,}
  \DataTypeTok{cex    =} \DecValTok{1}\NormalTok{,}
  \DataTypeTok{bty    =} \StringTok{"n"}\NormalTok{,}
  \DataTypeTok{title  =} \StringTok{"School"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{03-week-1-sns-study_files/figure-latex/03-myplot-call-1.pdf}
\caption{\label{fig:03-myplot-call}All 5 schools in time 1. Again, the graphs exclude isolates.}
\end{figure}

So what happened here?

\begin{itemize}
\item
  \texttt{oldpar\ \textless{}-\ par(no.readonly\ =\ TRUE)} This line stores the current parameters for plotting. Since we are going to be changing them, we better make sure we are able to go back!.
\item
  \texttt{par(mfrow\ =\ c(2,\ 3),\ mai\ =\ rep(0,\ 4),\ oma=rep(0,\ 4))} Here we are setting various things at the same time. \texttt{mfrow} specifies how many \emph{figures} will be drawn, and in what order. In particular, we are asking the plotting device to make room for 2*3 = 6 figures organized in two rows and three columns drawn by row.

  \texttt{mai} specifies the size of the margins in inches, setting all margins equal to zero (which is what we are doing now) gives more space to the graph. The same is true for \texttt{oma}. See \texttt{?par} for more info.
\item
  \texttt{myplot(ig\_year1,\ ...)} This is simply calling our plotting function. The neat part of this is that, since we set \texttt{mfrow\ =\ c(2,\ 3)}, R takes care of \emph{distributing} the plots in the device.
\item
  \texttt{par(oldpar)} This line allows us to restore the plotting parameters.
\end{itemize}

\hypertarget{statistical-tests}{%
\section{Statistical tests}\label{statistical-tests}}

\hypertarget{is-nomination-number-correlated-with-indegree}{%
\subsection{Is nomination number correlated with indegree?}\label{is-nomination-number-correlated-with-indegree}}

Hypothesis: Individuals that, on average, are among the first nominations of their peers are more popular

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Getting all the data in long format}
\NormalTok{edgelist <-}\StringTok{ }\KeywordTok{as_long_data_frame}\NormalTok{(ig_year1) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{as_tibble}

\CommentTok{# Computing indegree (again) and average nomination number}
\CommentTok{# Include "On a scale from one to five how close do you feel"}
\CommentTok{# Also for egocentric friends (A. Friends)}
\NormalTok{indeg_nom_cor <-}\StringTok{ }\KeywordTok{group_by}\NormalTok{(edgelist, to, to_name, to_school) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}
    \DataTypeTok{indeg   =} \KeywordTok{length}\NormalTok{(nnom),}
    \DataTypeTok{nom_avg =} \DecValTok{1}\OperatorTok{/}\KeywordTok{mean}\NormalTok{(nnom)}
\NormalTok{  ) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{rename}\NormalTok{(}
    \DataTypeTok{school =}\NormalTok{ to_school}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` has grouped output by 'to', 'to_name'. You can override using the `.groups` argument.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{indeg_nom_cor}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1,561 x 5
## # Groups:   to, to_name [1,561]
##       to to_name school indeg nom_avg
##    <dbl> <chr>    <int> <int>   <dbl>
##  1     2 1110002    111    22   0.222
##  2     3 1110007    111     7   0.175
##  3     4 1110013    111     6   0.171
##  4     5 1110014    111    19   0.134
##  5     6 1110015    111     3   0.15 
##  6     7 1110020    111     6   0.154
##  7     9 1110025    111     6   0.214
##  8    10 1110027    111    13   0.220
##  9    11 1110029    111    14   0.131
## 10    12 1110030    111     6   0.222
## # ... with 1,551 more rows
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Using pearson's correlation}
\KeywordTok{with}\NormalTok{(indeg_nom_cor, }\KeywordTok{cor.test}\NormalTok{(indeg, nom_avg))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Pearson's product-moment correlation
## 
## data:  indeg and nom_avg
## t = -12.254, df = 1559, p-value < 2.2e-16
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  -0.3409964 -0.2504653
## sample estimates:
##        cor 
## -0.2963965
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{save.image}\NormalTok{(}\StringTok{"03.rda"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{exponential-random-graph-models}{%
\chapter{Exponential Random Graph Models}\label{exponential-random-graph-models}}

I strongly suggest reading the vignette included in the \texttt{ergm} R package

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{vignette}\NormalTok{(}\StringTok{"ergm"}\NormalTok{, }\DataTypeTok{package=}\StringTok{"ergm"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{quote}
The purpose of ERGMs, in a nutshell, is to describe parsimoniously the local selection forces
that shape the global structure of a network. To this end, a network dataset, like those
depicted in Figure 1, may be considered as the response in a regression model, where the
predictors are things like ``propensity for individuals of the same sex to form partnerships'' or
``propensity for individuals to form triangles of partnerships''. In Figure 1(b), for example, it
is evident that the individual nodes appear to cluster in groups of the same numerical labels
(which turn out to be students' grades, 7 through 12); thus, an ERGM can help us quantify
the strength of this intra-group effect.

--- (David R. Hunter et al. \protect\hyperlink{ref-Hunter2008}{2008})
\end{quote}

\begin{figure}
\centering
\includegraphics{hunter2008.png}
\caption{Source: Hunter et al.~(2008)}
\end{figure}

In a nutshell, we use ERGMs as a parametric interpretation of the distribution of \(\mathbf{Y}\),
which takes the canonical form:

\[
\mbox{Pr}\left(\mathbf{Y}=\mathbf{y}|\theta, \mathcal{Y}\right) = \frac{\mbox{exp}\left\{\theta^{\mbox{T}}\mathbf{g}(\mathbf{y})\right\}}{\kappa\left(\theta, \mathcal{Y}\right)},\quad\mathbf{y}\in\mathcal{Y}
\label{eq:04-1}
\]

Where \(\theta\in\Omega\subset\mathbb{R}^q\) is the vector of model coefficients and \(\mathbf{g}(\mathbf{y})\) is a \emph{q}-vector of statistics based on the adjacency matrix \(\mathbf{y}\).

Model \eqref{eq:04-1} may be expanded by replacing \(\mathbf{g}(\mathbf{y})\) with \(\mathbf{g}(\mathbf{y}, \mathbf{X})\) to allow for additional covariate information \(\mathbf{X}\) about the network. The denominator,

\[
\kappa\left(\theta,\mathcal{Y}\right) = \sum_{\mathbf{y}\in\mathcal{Y}}\mbox{exp}\left\{\theta^{\mbox{T}}\mathbf{g}(\mathbf{y})\right\}
\]

,is the normalizing factor that ensures that equation \eqref{eq:04-1} is a legitimate probability distribution. Even after fixing \(\mathcal{Y}\) to be all the networks that have size \(n\), the size of \(\mathcal{Y}\) makes this type of statistical model hard to estimate as there are \(N = 2^{n(n-1)}\) possible networks! (David R. Hunter et al. \protect\hyperlink{ref-Hunter2008}{2008})

Recent developments include new forms of dependency structures to take into account more general neighborhood effects. These models relax the one-step Markovian dependence assumptions, allowing investigation of longer-range configurations, such as longer paths in the network or larger cycles (Pattison and Robins 2002). Models for bipartite (Faust and Skvoretz 1999) and tripartite (Mische and Robins 2000) network structures have been developed. (David R. Hunter et al. \protect\hyperlink{ref-Hunter2008}{2008}, 9)

\hypertarget{a-nauxefve-example}{%
\section{A nave example}\label{a-nauxefve-example}}

In the simplest case, ergm is equivalent to a logistic regression

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(ergm)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Loading required package: network
\end{verbatim}

\begin{verbatim}
## 
## 'network' 1.17.2 (2022-05-20), part of the Statnet Project
## * 'news(package="network")' for changes since last version
## * 'citation("network")' for citation information
## * 'https://statnet.org' for help, support, and other information
\end{verbatim}

\begin{verbatim}
## 
## 'ergm' 4.2.2 (2022-06-01), part of the Statnet Project
## * 'news(package="ergm")' for changes since last version
## * 'citation("ergm")' for citation information
## * 'https://statnet.org' for help, support, and other information
\end{verbatim}

\begin{verbatim}
## 'ergm' 4 is a major update that introduces some backwards-incompatible
## changes. Please type 'news(package="ergm")' for a list of major
## changes.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{data}\NormalTok{(}\StringTok{"sampson"}\NormalTok{)}

\NormalTok{samplike}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  Network attributes:
##   vertices = 18 
##   directed = TRUE 
##   hyper = FALSE 
##   loops = FALSE 
##   multiple = FALSE 
##   total edges= 88 
##     missing edges= 0 
##     non-missing edges= 88 
## 
##  Vertex attribute names: 
##     cloisterville group vertex.names 
## 
##  Edge attribute names: 
##     nominations
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y <-}\StringTok{ }\KeywordTok{sort}\NormalTok{(}\KeywordTok{as.vector}\NormalTok{(}\KeywordTok{as.matrix}\NormalTok{(samplike)))[}\OperatorTok{-}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{18}\NormalTok{)]}
\KeywordTok{glm}\NormalTok{(y}\OperatorTok{~}\DecValTok{1}\NormalTok{, }\DataTypeTok{family=}\KeywordTok{binomial}\NormalTok{(}\StringTok{"logit"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:  glm(formula = y ~ 1, family = binomial("logit"))
## 
## Coefficients:
## (Intercept)  
##     -0.9072  
## 
## Degrees of Freedom: 305 Total (i.e. Null);  305 Residual
## Null Deviance:       367.2 
## Residual Deviance: 367.2     AIC: 369.2
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ergm}\NormalTok{(samplike }\OperatorTok{~}\StringTok{ }\NormalTok{edges)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Starting maximum pseudolikelihood estimation (MPLE):
\end{verbatim}

\begin{verbatim}
## Evaluating the predictor and response matrix.
\end{verbatim}

\begin{verbatim}
## Maximizing the pseudolikelihood.
\end{verbatim}

\begin{verbatim}
## Finished MPLE.
\end{verbatim}

\begin{verbatim}
## Stopping at the initial estimate.
\end{verbatim}

\begin{verbatim}
## Evaluating log-likelihood at the estimate.
\end{verbatim}

\begin{verbatim}
## 
## Call:
## ergm(formula = samplike ~ edges)
## 
## Maximum Likelihood Coefficients:
##   edges  
## -0.9072
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pr <-}\StringTok{ }\KeywordTok{mean}\NormalTok{(y)}
\KeywordTok{log}\NormalTok{(pr) }\OperatorTok{-}\StringTok{ }\KeywordTok{log}\NormalTok{(}\DecValTok{1}\OperatorTok{-}\NormalTok{pr) }\CommentTok{# Logit function}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -0.9071582
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{qlogis}\NormalTok{(pr)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -0.9071582
\end{verbatim}

\hypertarget{estimation-of-ergms}{%
\section{Estimation of ERGMs}\label{estimation-of-ergms}}

The ultimate goal is to perform statistical inference on the proposed model. In a \emph{standard} setting, we would be able to use Maximum-Likelihood-Estimation (MLE), which consists of finding the model parameters \(\theta\) that, given the observed data, maximize the likelihood of the model. For the latter, we generally use \href{https://en.wikipedia.org/wiki/Newton\%27s_method_in_optimization}{Newton's method}. Newton's method requires been able to compute the log-likelihood of the model, which in ERGMs can be challenging.

For ERGMs, since part of the likelihood involves a normalizing constant that is a function of all possible networks, this is not as straightforward as in the regular setting. Because of it, most estimation methods rely on simulations.

In \texttt{statnet}, the default estimation method is based on a method proposed by (Geyer and Thompson \protect\hyperlink{ref-Geyer1992}{1992}), Markov-Chain MLE, which uses Markov-Chain Monte Carlo for simulating networks and a modified version of the Newton-Raphson algorithm to estimate the parameters.

The idea of MC-MLE for this family of statistical models is that we can approximate the expectation of normalizing constant ratios using the law of large numbers. In particular, the following:

\begin{align*}
\frac{\kappa\left(\theta,\mathcal{Y}\right)}{\kappa\left(\theta_0,\mathcal{Y}\right)} & = 
  \frac{
    \sum_{\mathbf{y}\in\mathcal{Y}}\mbox{exp}\left\{\theta^{\mbox{T}}\mathbf{g}(\mathbf{y})\right\}}{ 
    \sum_{\mathbf{y}\in\mathcal{Y}}\mbox{exp}\left\{\theta_0^{\mbox{T}}\mathbf{g}(\mathbf{y})\right\} 
  } \\
& = \sum_{\mathbf{y}\in\mathcal{Y}}\left( %
  \frac{1}{%
    \sum_{\mathbf{y}\in\mathcal{Y}\mbox{exp}\left\{\theta_0^{\mbox{T}}\mathbf{g}(\mathbf{y})\right\}}%
  } \times %
  \mbox{exp}\left\{\theta^{\mbox{T}}\mathbf{g}(\mathbf{y})\right\} %
  \right) \\
& = \sum_{\mathbf{y}\in\mathcal{Y}}\left( %
  \frac{\mbox{exp}\left\{\theta_0^{\mbox{T}}\mathbf{g}(\mathbf{y})\right\}}{%
    \sum_{\mathbf{y}\in\mathcal{Y}\mbox{exp}\left\{\theta_0^{\mbox{T}}\mathbf{g}(\mathbf{y})\right\}}%
  } \times %
  \mbox{exp}\left\{(\theta - \theta_0)^{\mbox{T}}\mathbf{g}(\mathbf{y})\right\} %
  \right) \\
& = \sum_{\mathbf{y}\in\mathcal{Y}}\left( %
  \mbox{Pr}\left(Y = y|\mathcal{Y}, \theta_0\right) \times %
  \mbox{exp}\left\{(\theta - \theta_0)^{\mbox{T}}\mathbf{g}(\mathbf{y})\right\} %
  \right) \\
& = \mbox{E}_{\theta_0}\left(\mbox{exp}\left\{(\theta - \theta_0)^{\mbox{T}}\mathbf{g}(\mathbf{y})\right\} \right)
\end{align*}

In particular, the MC-MLE algorithm uses this fact to maximize the ratio of log-likelihoods. The objective function itself can be approximated by simulating \(m\) networks from the distribution with parameter \(\theta_0\):

\[
l(\theta) - l(\theta_0) \approx (\theta - \theta_0)^{\mbox{T}}\mathbf{g}(\mathbf{y}_{obs}) - 
\mbox{log}{\left[\frac{1}{m}\sum_{i = 1}^m\mbox{exp}\left\{(\theta-\theta_0)^{\mbox{T}}\right\}\mathbf{g}(\mathbf{Y}_i)\right]}
\]

For more details, see (David R. Hunter et al. \protect\hyperlink{ref-Hunter2008}{2008}). A sketch of the algorithm follows:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Initialize the algorithm with an initial guess of \(\theta\), call it \(\theta^{(t)}\) (must be a rather OK guess)
\item
  While (no convergence) do:

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \item
    Using \(\theta^{(t)}\), simulate \(M\) networks by means of small changes in the \(\mathbf{Y}_{obs}\) (the observed network). This part is done by using an importance-sampling method which weights each proposed network by it's likelihood conditional on \(\theta^{(t)}\)
  \item
    With the networks simulated, we can do the Newton step to update the parameter \(\theta^{(t)}\) (this is the iteration part in the \texttt{ergm} package): \(\theta^{(t)}\to\theta^{(t+1)}\).
  \item
    If convergence has been reached (which usually means that \(\theta^{(t)}\) and \(\theta^{(t + 1)}\) are not very different), then stop; otherwise, go to step a.
  \end{enumerate}
\end{enumerate}

For more details see (Lusher, Koskinen, and Robins \protect\hyperlink{ref-lusher2012}{2012}; Admiraal and Handcock \protect\hyperlink{ref-admiraal2006}{2006}; Snijders \protect\hyperlink{ref-Snijders2002}{2002}; Wang et al. \protect\hyperlink{ref-Wang2009}{2009}) provides details on the algorithm used by PNet (which is the same as the one used in \texttt{RSiena}). (Lusher, Koskinen, and Robins \protect\hyperlink{ref-lusher2012}{2012}) provides a short discussion on differences between \texttt{ergm} and \texttt{PNet}.

\hypertarget{the-ergm-package}{%
\section{\texorpdfstring{The \texttt{ergm} package}{The ergm package}}\label{the-ergm-package}}

The \texttt{ergm} R package (Handcock et al. \protect\hyperlink{ref-R-ergm}{2017})

From the previous section:\footnote{You can download the 03.rda file from \href{https://github.com/gvegayon/appliedsnar}{this link}.}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(igraph)}
\KeywordTok{library}\NormalTok{(magrittr)}
\KeywordTok{library}\NormalTok{(dplyr)}

\KeywordTok{load}\NormalTok{(}\StringTok{"03.rda"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

In this section we will use the \texttt{ergm} package (from the \texttt{statnet} suit of packages (Handcock et al. \protect\hyperlink{ref-R-statnet}{2016})) suit, and the \texttt{intergraph} (Bojanowski \protect\hyperlink{ref-R-intergraph}{2015}) package. The latter provides functions to go back and forth between \texttt{igraph} and \texttt{network} objects from the \texttt{igraph} and \texttt{network} packages respectively\footnote{Yes, the classes have the same name as the packages.}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(ergm)}
\KeywordTok{library}\NormalTok{(intergraph)}
\end{Highlighting}
\end{Shaded}

As a rather important side note, the order in which R packages are loaded matters. Why is this important to mention now? Well, it turns out that at least a couple of functions in the \texttt{network} package have the same name of some functions in the \texttt{igraph} package. When the \texttt{ergm} package is loaded, since it depends on \texttt{network}, it will load the \texttt{network} package first, which will \emph{mask} some functions in \texttt{igraph}. This becomes evident once you load \texttt{ergm} after loading \texttt{igraph}:

\begin{verbatim}
The following objects are masked from package:igraph:

  add.edges, add.vertices, %c%, delete.edges, delete.vertices, get.edge.attribute, get.edges,
  get.vertex.attribute, is.bipartite, is.directed, list.edge.attributes, list.vertex.attributes, %s%,
  set.edge.attribute, set.vertex.attribute
\end{verbatim}

What are the implications of this? If you call the function \texttt{list.edge.attributes} for an object of class \texttt{igraph} R will return an error as the first function that matches that name comes from the \texttt{network} package! To avoid this you can use the double colon notation:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{igraph}\OperatorTok{::}\KeywordTok{list.edge.attributes}\NormalTok{(my_igraph_object)}
\NormalTok{network}\OperatorTok{::}\KeywordTok{list.edge.attributes}\NormalTok{(my_network_object)}
\end{Highlighting}
\end{Shaded}

Anyway\ldots{} Using the \texttt{asNetwork} function, we can coerce the igraph object into a network object so we can use it with the \texttt{ergm} function:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Creating the new network}
\NormalTok{network_}\DecValTok{111}\NormalTok{ <-}\StringTok{ }\NormalTok{intergraph}\OperatorTok{::}\KeywordTok{asNetwork}\NormalTok{(ig_year1_}\DecValTok{111}\NormalTok{)}

\CommentTok{# Running a simple ergm (only fitting edge count)}
\KeywordTok{ergm}\NormalTok{(network_}\DecValTok{111} \OperatorTok{~}\StringTok{ }\NormalTok{edges)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Warning:  This network contains loops"
\end{verbatim}

\begin{verbatim}
## Starting maximum pseudolikelihood estimation (MPLE):
\end{verbatim}

\begin{verbatim}
## Evaluating the predictor and response matrix.
\end{verbatim}

\begin{verbatim}
## Maximizing the pseudolikelihood.
\end{verbatim}

\begin{verbatim}
## Finished MPLE.
\end{verbatim}

\begin{verbatim}
## Stopping at the initial estimate.
\end{verbatim}

\begin{verbatim}
## Evaluating log-likelihood at the estimate.
\end{verbatim}

\begin{verbatim}
## 
## Call:
## ergm(formula = network_111 ~ edges)
## 
## Maximum Likelihood Coefficients:
##  edges  
## -4.734
\end{verbatim}

So what happened here! We got a warning. It turns out that our network has loops (didn't thought about it before!). Let's take a look at that with the \texttt{which\_loop} function

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{E}\NormalTok{(ig_year1_}\DecValTok{111}\NormalTok{)[}\KeywordTok{which_loop}\NormalTok{(ig_year1_}\DecValTok{111}\NormalTok{)]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## + 1/2638 edge from ec0b228 (vertex names):
## [1] 1110111->1110111
\end{verbatim}

We can get rid of these using the \texttt{igraph::-.igraph}. Let's remove the isolates using the same operator

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Creating the new network}
\NormalTok{network_}\DecValTok{111}\NormalTok{ <-}\StringTok{ }\NormalTok{ig_year1_}\DecValTok{111}

\CommentTok{# Removing loops}
\NormalTok{network_}\DecValTok{111}\NormalTok{ <-}\StringTok{ }\NormalTok{network_}\DecValTok{111} \OperatorTok{-}\StringTok{ }\KeywordTok{E}\NormalTok{(network_}\DecValTok{111}\NormalTok{)[}\KeywordTok{which}\NormalTok{(}\KeywordTok{which_loop}\NormalTok{(network_}\DecValTok{111}\NormalTok{))]}

\CommentTok{# Removing isolates}
\NormalTok{network_}\DecValTok{111}\NormalTok{ <-}\StringTok{ }\NormalTok{network_}\DecValTok{111} \OperatorTok{-}\StringTok{ }\KeywordTok{which}\NormalTok{(}\KeywordTok{degree}\NormalTok{(network_}\DecValTok{111}\NormalTok{, }\DataTypeTok{mode =} \StringTok{"all"}\NormalTok{) }\OperatorTok{==}\StringTok{ }\DecValTok{0}\NormalTok{)}

\CommentTok{# Converting the network}
\NormalTok{network_}\DecValTok{111}\NormalTok{ <-}\StringTok{ }\NormalTok{intergraph}\OperatorTok{::}\KeywordTok{asNetwork}\NormalTok{(network_}\DecValTok{111}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\texttt{asNetwork(simplify(ig\_year1\_111))}
\texttt{ig\_year1\_111\ \%\textgreater{}\%\ simplify\ \%\textgreater{}\%\ asNetwork}

A problem that we have on this data is the fact that some vertices have
missing values in the variables \texttt{hispanic}, \texttt{female1}, and \texttt{eversmk1}. For now,
we will proceed by imputing values based on the avareges:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ (v }\ControlFlowTok{in} \KeywordTok{c}\NormalTok{(}\StringTok{"hispanic"}\NormalTok{, }\StringTok{"female1"}\NormalTok{, }\StringTok{"eversmk1"}\NormalTok{)) \{}
\NormalTok{  tmpv <-}\StringTok{ }\NormalTok{network_}\DecValTok{111} \OperatorTok{%v%}\StringTok{ }\NormalTok{v}
\NormalTok{  tmpv[}\KeywordTok{is.na}\NormalTok{(tmpv)] <-}\StringTok{ }\KeywordTok{mean}\NormalTok{(tmpv, }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{) }\OperatorTok{>}\StringTok{ }\FloatTok{.5}
\NormalTok{  network_}\DecValTok{111} \OperatorTok{%v%}\StringTok{ }\NormalTok{v <-}\StringTok{ }\NormalTok{tmpv}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\hypertarget{running-ergms}{%
\section{Running ERGMs}\label{running-ergms}}

Proposed workflow:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Estimate the simplest model, adding one variable at a time.
\item
  After each estimation, run the \texttt{mcmc.diagnostics} function to see how good (or bad) behaved the chains are.
\item
  Run the \texttt{gof} function and verify how good the model matches the network's structural statistics.
\end{enumerate}

What to use:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \texttt{control.ergms}: Maximum number of iteration, seed for Pseudo-RNG, how many cores
\item
  \texttt{ergm.constraints}: Where to sample the network from. Gives stability and (in some cases) faster convergence as by constraining the model you are reducing the sample size.
\end{enumerate}

Here is an example of a couple of models that we could compare\footnote{Notice that this document may not include the usual messages that the \texttt{ergm} command generates during the estimation procedure. This is just to make it more printable-friendly.}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ans0 <-}\StringTok{ }\KeywordTok{ergm}\NormalTok{(}
\NormalTok{  network_}\DecValTok{111} \OperatorTok{~}
\StringTok{    }\NormalTok{edges }\OperatorTok{+}
\StringTok{    }\KeywordTok{nodematch}\NormalTok{(}\StringTok{"hispanic"}\NormalTok{) }\OperatorTok{+}
\StringTok{    }\KeywordTok{nodematch}\NormalTok{(}\StringTok{"female1"}\NormalTok{) }\OperatorTok{+}
\StringTok{    }\KeywordTok{nodematch}\NormalTok{(}\StringTok{"eversmk1"}\NormalTok{) }\OperatorTok{+}
\StringTok{    }\NormalTok{mutual}
\NormalTok{    ,}
  \DataTypeTok{constraints =} \OperatorTok{~}\KeywordTok{bd}\NormalTok{(}\DataTypeTok{maxout =} \DecValTok{19}\NormalTok{),}
  \DataTypeTok{control =} \KeywordTok{control.ergm}\NormalTok{(}
    \DataTypeTok{seed        =} \DecValTok{1}\NormalTok{,}
    \DataTypeTok{MCMLE.maxit =} \DecValTok{10}\NormalTok{,}
    \DataTypeTok{parallel    =} \DecValTok{4}\NormalTok{,}
    \DataTypeTok{CD.maxit    =} \DecValTok{10}
\NormalTok{    )}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

So what are we doing here:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The model is controlling for:

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \item
    \texttt{edges} Number of edges in the network (as opposed to its density)
  \item
    \texttt{nodematch("some-variable-name-here")} Includes a term that controls for homophily/heterophily
  \item
    \texttt{mutual} Number of mutual connections between \((i, j), (j, i)\). This can be related to, for example, triadic closure.
  \end{enumerate}
\end{enumerate}

For more on control parameters, see (Morris, Handcock, and Hunter \protect\hyperlink{ref-Morris2008}{2008}).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ans1 <-}\StringTok{ }\KeywordTok{ergm}\NormalTok{(}
\NormalTok{  network_}\DecValTok{111} \OperatorTok{~}
\StringTok{    }\NormalTok{edges }\OperatorTok{+}
\StringTok{    }\KeywordTok{nodematch}\NormalTok{(}\StringTok{"hispanic"}\NormalTok{) }\OperatorTok{+}
\StringTok{    }\KeywordTok{nodematch}\NormalTok{(}\StringTok{"female1"}\NormalTok{) }\OperatorTok{+}
\StringTok{    }\KeywordTok{nodematch}\NormalTok{(}\StringTok{"eversmk1"}\NormalTok{)}
\NormalTok{    ,}
  \DataTypeTok{constraints =} \OperatorTok{~}\KeywordTok{bd}\NormalTok{(}\DataTypeTok{maxout =} \DecValTok{19}\NormalTok{),}
  \DataTypeTok{control =} \KeywordTok{control.ergm}\NormalTok{(}
    \DataTypeTok{seed        =} \DecValTok{1}\NormalTok{,}
    \DataTypeTok{MCMLE.maxit =} \DecValTok{10}\NormalTok{,}
    \DataTypeTok{parallel    =} \DecValTok{4}\NormalTok{,}
    \DataTypeTok{CD.maxit    =} \DecValTok{10}
\NormalTok{    )}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

This example takes longer to compute

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ans2 <-}\StringTok{ }\KeywordTok{ergm}\NormalTok{(}
\NormalTok{  network_}\DecValTok{111} \OperatorTok{~}
\StringTok{    }\NormalTok{edges }\OperatorTok{+}
\StringTok{    }\KeywordTok{nodematch}\NormalTok{(}\StringTok{"hispanic"}\NormalTok{) }\OperatorTok{+}
\StringTok{    }\KeywordTok{nodematch}\NormalTok{(}\StringTok{"female1"}\NormalTok{) }\OperatorTok{+}
\StringTok{    }\KeywordTok{nodematch}\NormalTok{(}\StringTok{"eversmk1"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\NormalTok{mutual }\OperatorTok{+}
\StringTok{    }\NormalTok{balance}
\NormalTok{    ,}
  \DataTypeTok{constraints =} \OperatorTok{~}\KeywordTok{bd}\NormalTok{(}\DataTypeTok{maxout =} \DecValTok{19}\NormalTok{),}
  \DataTypeTok{control =} \KeywordTok{control.ergm}\NormalTok{(}
    \DataTypeTok{seed        =} \DecValTok{1}\NormalTok{,}
    \DataTypeTok{MCMLE.maxit =} \DecValTok{10}\NormalTok{,}
    \DataTypeTok{parallel    =} \DecValTok{4}\NormalTok{,}
    \DataTypeTok{CD.maxit    =} \DecValTok{10}
\NormalTok{    )}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

Now, a nice trick to see all regressions in the same table, we can use the \texttt{texreg} package (Leifeld \protect\hyperlink{ref-R-texreg}{2013}) which supports \texttt{ergm} ouputs!

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(texreg)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Version:  1.38.6
## Date:     2022-04-06
## Author:   Philip Leifeld (University of Essex)
## 
## Consider submitting praise using the praise or praise_interactive functions.
## Please cite the JSS article in your publications -- see citation("texreg").
\end{verbatim}

\begin{verbatim}
## 
## Attaching package: 'texreg'
\end{verbatim}

\begin{verbatim}
## The following object is masked from 'package:magrittr':
## 
##     extract
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{screenreg}\NormalTok{(}\KeywordTok{list}\NormalTok{(ans0, ans1, ans2))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: This object was fit with 'ergm' version 4.1.2 or earlier. Summarizing it with version 4.2 or later may return incorrect results or fail.
## This object was fit with 'ergm' version 4.1.2 or earlier. Summarizing it with version 4.2 or later may return incorrect results or fail.
## This object was fit with 'ergm' version 4.1.2 or earlier. Summarizing it with version 4.2 or later may return incorrect results or fail.
\end{verbatim}

\begin{verbatim}
## 
## ===============================================================
##                     Model 1        Model 2        Model 3      
## ---------------------------------------------------------------
## edges                   -5.63 ***      -5.49 ***      -5.60 ***
##                         (0.05)         (0.06)         (0.06)   
## nodematch.hispanic       0.22 ***       0.30 ***       0.22 ***
##                         (0.04)         (0.05)         (0.04)   
## nodematch.female1        0.87 ***       1.17 ***       0.87 ***
##                         (0.04)         (0.05)         (0.04)   
## nodematch.eversmk1       0.33 ***       0.45 ***       0.34 ***
##                         (0.04)         (0.04)         (0.04)   
## mutual                   4.10 ***                      1.75 ***
##                         (0.07)                        (0.14)   
## balance                                                0.01 ***
##                                                       (0.00)   
## ---------------------------------------------------------------
## AIC                 -40017.80      -37511.87      -39989.59    
## BIC                 -39967.46      -37471.60      -39929.18    
## Log Likelihood       20013.90       18759.94       20000.79    
## ===============================================================
## *** p < 0.001; ** p < 0.01; * p < 0.05
\end{verbatim}

Or, if you are using rmarkdown, you can export the results using LaTeX or html, let's try the latter to see how it looks like here:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(texreg)}
\KeywordTok{texreg}\NormalTok{(}\KeywordTok{list}\NormalTok{(ans0, ans1, ans2))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: This object was fit with 'ergm' version 4.1.2 or earlier. Summarizing it with version 4.2 or later may return incorrect results or fail.
## This object was fit with 'ergm' version 4.1.2 or earlier. Summarizing it with version 4.2 or later may return incorrect results or fail.
## This object was fit with 'ergm' version 4.1.2 or earlier. Summarizing it with version 4.2 or later may return incorrect results or fail.
\end{verbatim}

\begin{table}
\begin{center}
\begin{tabular}{l c c c}
\hline
 & Model 1 & Model 2 & Model 3 \\
\hline
edges              & $-5.63^{***}$ & $-5.49^{***}$ & $-5.60^{***}$ \\
                   & $(0.05)$      & $(0.06)$      & $(0.06)$      \\
nodematch.hispanic & $0.22^{***}$  & $0.30^{***}$  & $0.22^{***}$  \\
                   & $(0.04)$      & $(0.05)$      & $(0.04)$      \\
nodematch.female1  & $0.87^{***}$  & $1.17^{***}$  & $0.87^{***}$  \\
                   & $(0.04)$      & $(0.05)$      & $(0.04)$      \\
nodematch.eversmk1 & $0.33^{***}$  & $0.45^{***}$  & $0.34^{***}$  \\
                   & $(0.04)$      & $(0.04)$      & $(0.04)$      \\
mutual             & $4.10^{***}$  &               & $1.75^{***}$  \\
                   & $(0.07)$      &               & $(0.14)$      \\
balance            &               &               & $0.01^{***}$  \\
                   &               &               & $(0.00)$      \\
\hline
AIC                & $-40017.80$   & $-37511.87$   & $-39989.59$   \\
BIC                & $-39967.46$   & $-37471.60$   & $-39929.18$   \\
Log Likelihood     & $20013.90$    & $18759.94$    & $20000.79$    \\
\hline
\multicolumn{4}{l}{\scriptsize{$^{***}p<0.001$; $^{**}p<0.01$; $^{*}p<0.05$}}
\end{tabular}
\caption{Statistical models}
\label{table:coefficients}
\end{center}
\end{table}

\hypertarget{model-goodness-of-fit}{%
\section{Model Goodness-of-Fit}\label{model-goodness-of-fit}}

In raw terms, once each chain has reach stationary distribution, we can say that there are no problems with autocorrelation and that each sample point is iid. This implies that, since we are running the model with more than 1 chain, we can use all the samples (chains) as a single dataset.

\begin{quote}
Recent changes in the ergm estimation algorithm mean that these plots can no longer be used to ensure that the mean statistics from the model match the observed network statistics. For that functionality, please use the GOF command: gof(object, GOF=\textasciitilde{}model).

---?ergm::mcmc.diagnostics
\end{quote}

Since \texttt{ans0} is the one model which did best, let's take a look at it's GOF statistics. First, lets see how the MCMC did. For this we can use the \texttt{mcmc.diagnostics} function including in the package. This function is actually a wrapper of a couple of functions from the \texttt{coda} package (Plummer et al. \protect\hyperlink{ref-R-coda}{2006}) which is called upon the \texttt{\$sample} object which holds the \emph{centered} statistics from the sampled networks. This last point is important to consider since at first look it can be confusing to look at the \texttt{\$sample} object since it neither matches the observed statistics, nor the coefficients.

When calling the function \texttt{mcmc.diagnostics(ans0,\ centered\ =\ FALSE)}, you will see a lot of output including a couple of plots showing the trace and posterior distribution of the \emph{uncentered} statistics (\texttt{centered\ =\ FALSE}). In the next code chunks we will reproduce the output from the \texttt{mcmc.diagnostics} function step by step using the coda package. First we need to \emph{uncenter} the sample object:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Getting the centered sample}
\NormalTok{sample_centered <-}\StringTok{ }\NormalTok{ans0}\OperatorTok{$}\NormalTok{sample}

\CommentTok{# Getting the observed statistics and turning it into a matrix so we can add it}
\CommentTok{# to the samples}
\NormalTok{observed <-}\StringTok{ }\KeywordTok{summary}\NormalTok{(ans0}\OperatorTok{$}\NormalTok{formula)}
\NormalTok{observed <-}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}
\NormalTok{  observed,}
  \DataTypeTok{nrow  =} \KeywordTok{nrow}\NormalTok{(sample_centered[[}\DecValTok{1}\NormalTok{]]),}
  \DataTypeTok{ncol  =} \KeywordTok{length}\NormalTok{(observed),}
  \DataTypeTok{byrow =} \OtherTok{TRUE}
\NormalTok{  )}

\CommentTok{# Now we uncenter the sample}
\NormalTok{sample_uncentered <-}\StringTok{ }\KeywordTok{lapply}\NormalTok{(sample_centered, }\ControlFlowTok{function}\NormalTok{(x) \{}
\NormalTok{  x }\OperatorTok{+}\StringTok{ }\NormalTok{observed}
\NormalTok{\})}

\CommentTok{# We have to make it an mcmc.list object}
\NormalTok{sample_uncentered <-}\StringTok{ }\NormalTok{coda}\OperatorTok{::}\KeywordTok{mcmc.list}\NormalTok{(sample_uncentered)}
\end{Highlighting}
\end{Shaded}

Under the hood:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \emph{Empirical means and sd, and quantiles}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(sample_uncentered)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Iterations = 1769472:10944512
## Thinning interval = 65536 
## Number of chains = 4 
## Sample size per chain = 141 
## 
## 1. Empirical mean and standard deviation for each variable,
##    plus standard error of the mean:
## 
##                    Mean    SD Naive SE Time-series SE
## edges              2485 60.26   2.5372          3.753
## nodematch.hispanic 1838 51.25   2.1578          3.662
## nodematch.female1  1888 52.78   2.2224          3.779
## nodematch.eversmk1 1759 50.82   2.1400          3.072
## mutual              493 23.40   0.9855          1.967
## 
## 2. Quantiles for each variable:
## 
##                    2.5%  25%  50%  75% 97.5%
## edges              2373 2444 2482 2530  2612
## nodematch.hispanic 1736 1803 1839 1872  1947
## nodematch.female1  1791 1851 1885 1923  1993
## nodematch.eversmk1 1662 1725 1758 1794  1858
## mutual              449  476  493  509   537
\end{verbatim}
\item
  \emph{Cross correlation}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{coda}\OperatorTok{::}\KeywordTok{crosscorr}\NormalTok{(sample_uncentered)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                        edges nodematch.hispanic nodematch.female1
## edges              1.0000000          0.8657369         0.8851587
## nodematch.hispanic 0.8657369          1.0000000         0.7713632
## nodematch.female1  0.8851587          0.7713632         1.0000000
## nodematch.eversmk1 0.8445651          0.7122693         0.7572735
## mutual             0.7726517          0.6801783         0.7482026
##                    nodematch.eversmk1    mutual
## edges                       0.8445651 0.7726517
## nodematch.hispanic          0.7122693 0.6801783
## nodematch.female1           0.7572735 0.7482026
## nodematch.eversmk1          1.0000000 0.6873242
## mutual                      0.6873242 1.0000000
\end{verbatim}
\item
  \emph{Autocorrelation}: For now, we will only look at autocorrelation for chain one. Autocorrelation should be small (in a general MCMC setting). If autocorrelation is high, then it means that your sample is not idd (no Markov property). A way out to solve this is \emph{thinning} the sample.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{coda}\OperatorTok{::}\KeywordTok{autocorr}\NormalTok{(sample_uncentered)[[}\DecValTok{1}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## , , edges
## 
##                   edges nodematch.hispanic nodematch.female1 nodematch.eversmk1
## Lag 0       1.000000000        0.861920590        0.90235072         0.86215333
## Lag 65536   0.415060923        0.326775063        0.43751588         0.38274418
## Lag 327680  0.063993999        0.002238453        0.09094189         0.05143792
## Lag 655360  0.002497326       -0.105210070       -0.02414091         0.00143358
## Lag 3276800 0.026845190        0.068616366        0.03686125         0.03652383
##                  mutual
## Lag 0       0.785264416
## Lag 65536   0.428519050
## Lag 327680  0.074020671
## Lag 655360  0.009422505
## Lag 3276800 0.018126669
## 
## , , nodematch.hispanic
## 
##                   edges nodematch.hispanic nodematch.female1 nodematch.eversmk1
## Lag 0        0.86192059        1.000000000        0.76137201         0.74623272
## Lag 65536    0.32680263        0.336764054        0.30353156         0.32690588
## Lag 327680   0.05778076        0.004465856        0.07267341         0.03757479
## Lag 655360   0.07704457        0.024226503        0.03252125         0.08420548
## Lag 3276800 -0.02970399        0.021278122       -0.02753467        -0.03018601
##                  mutual
## Lag 0        0.70578514
## Lag 65536    0.35558587
## Lag 327680   0.05282736
## Lag 655360   0.08176601
## Lag 3276800 -0.07743174
## 
## , , nodematch.female1
## 
##                   edges nodematch.hispanic nodematch.female1 nodematch.eversmk1
## Lag 0       0.902350724         0.76137201        1.00000000         0.77769826
## Lag 65536   0.453418914         0.37756721        0.51290498         0.41954866
## Lag 327680  0.055464012        -0.01058737        0.09841770         0.04272154
## Lag 655360  0.009910833        -0.06123858       -0.03186870         0.04679847
## Lag 3276800 0.004163166         0.04057544        0.01548719        -0.01288236
##                  mutual
## Lag 0        0.76981085
## Lag 65536    0.46327442
## Lag 327680   0.03629824
## Lag 655360   0.01987496
## Lag 3276800 -0.00949882
## 
## , , nodematch.eversmk1
## 
##                  edges nodematch.hispanic nodematch.female1 nodematch.eversmk1
## Lag 0       0.86215333        0.746232721        0.77769826        1.000000000
## Lag 65536   0.37539678        0.297591397        0.41717478        0.448697559
## Lag 327680  0.02105523       -0.040132752        0.03760486        0.019124328
## Lag 655360  0.04566425        0.003387581        0.04761067       -0.006388743
## Lag 3276800 0.05048735        0.084790008        0.07108989        0.045582057
##                   mutual
## Lag 0       0.7053009595
## Lag 65536   0.4020746950
## Lag 327680  0.0183308894
## Lag 655360  0.0840948296
## Lag 3276800 0.0009713556
## 
## , , mutual
## 
##                   edges nodematch.hispanic nodematch.female1 nodematch.eversmk1
## Lag 0        0.78526442         0.70578514       0.769810849         0.70530096
## Lag 65536    0.50645801         0.44741607       0.532817503         0.47751208
## Lag 327680   0.12979152         0.06061696       0.147380566         0.10930214
## Lag 655360  -0.06393205        -0.13217821      -0.008121728        -0.03814393
## Lag 3276800 -0.01707605         0.03244214      -0.023750630         0.02781638
##                   mutual
## Lag 0        1.000000000
## Lag 65536    0.580271013
## Lag 327680   0.091309576
## Lag 655360  -0.003521212
## Lag 3276800 -0.025558756
\end{verbatim}
\item
  \emph{Geweke Diagnostic}: From the function's help file:

  \begin{quote}
  ``If the samples are drawn from the stationary distribution of the chain, the two means are equal and Geweke's statistic has an asymptotically standard normal distribution. {[}\ldots{}{]}
  The Z-score is calculated under the assumption that the two parts of the chain are asymptotically independent, which requires that the sum of frac1 and frac2 be strictly less than 1.''"

  ---?coda::geweke.diag
  \end{quote}

  Let's take a look at a single chain:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{coda}\OperatorTok{::}\KeywordTok{geweke.diag}\NormalTok{(sample_uncentered)[[}\DecValTok{1}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Fraction in 1st window = 0.1
## Fraction in 2nd window = 0.5 
## 
##              edges nodematch.hispanic  nodematch.female1 nodematch.eversmk1 
##            -0.7115            -1.7204            -0.1841             0.6952 
##             mutual 
##            -1.2891
\end{verbatim}
\item
  \emph{(not included) Gelman Diagnostic}: From the function's help file:

  \begin{quote}
  Gelman and Rubin (1992) propose a general approach to monitoring convergence of MCMC output in which m \textgreater{} 1 parallel chains are run with starting values that are overdispersed relative to the posterior distribution. Convergence is diagnosed when the chains have `forgotten' their initial values, and the output from all chains is indistinguishable. The gelman.diag diagnostic is applied to a single variable from the chain. It is based a comparison of within-chain and between-chain variances, and is similar to a classical analysis of variance.
  ---?coda::gelman.diag
  \end{quote}

  As a difference from the previous diagnostic statistic, this uses all chains simulatenously:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{coda}\OperatorTok{::}\KeywordTok{gelman.diag}\NormalTok{(sample_uncentered)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Potential scale reduction factors:
## 
##                    Point est. Upper C.I.
## edges                    1.03       1.10
## nodematch.hispanic       1.03       1.10
## nodematch.female1        1.05       1.14
## nodematch.eversmk1       1.04       1.12
## mutual                   1.05       1.14
## 
## Multivariate psrf
## 
## 1.05
\end{verbatim}

  As a rule of thumb, values that are in the \([.9,1.1]\) are good.
\end{enumerate}

One nice feature of the \texttt{mcmc.diagnostics} function is the nice trace and posterior distribution plots that it generates. If you have the R package \texttt{latticeExtra} (Sarkar and Andrews \protect\hyperlink{ref-R-latticeExtra}{2016}), the function will override the default plots used by \texttt{coda::plot.mcmc} and use lattice instead, creating a nicer looking plots. The next code chunk calls the \texttt{mcmc.diagnostic} function, but we suppress the rest of the output (see figure \ref{fig:coda-plots}).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# [2022-03-13] This line is failing for what it could be an ergm bug}
\CommentTok{# mcmc.diagnostics(ans0, center = FALSE) # Suppressing all the output}
\end{Highlighting}
\end{Shaded}

If we called the function \texttt{mcmc.diagnostics}, this message appears at the end:

\begin{quote}
MCMC diagnostics shown here are from the last round of simulation, prior to computation of final parameter estimates. Because the final estimates are refinements of those used for this simulation run, these diagnostics may understate model performance. To directly assess the performance of the final model on in-model statistics, please use the GOF command: gof(ergmFitObject, GOF=\textasciitilde{}model).

---\texttt{mcmc.diagnostics(ans0)}
\end{quote}

Not that bad (although the \texttt{mutual} term could do better)!\footnote{The statnet wiki website as a very nice example of (very) bad and good MCMC diagnostics plots \href{https://statnet.org/trac/raw-attachment/wiki/Resources/ergm.fit.diagnostics.pdf}{here}.} First, observe that in the figure we see four different lines; why is that? Since we were running in parallel using four cores, the algorithm ran four chains of the MCMC algorithm. An eyeball test is to see if all the chains moved at about the same place; in such a case, we can start thinking about model convergence from the MCMC perspective.

Once we are sure to have reach convergence on the MCMC algorithm, we can start thinking about how well does our model predicts the observed network's proterties. Besides the statistics that define our ERGM, the \texttt{gof} function's default behavior show GOF for:

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  In degree distribution,
\item
  Out degree distribution,
\item
  Edge-wise shared partners, and
\item
  Geodesics
\end{enumerate}

Let's take a look at it

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Computing and printing GOF estatistics}
\NormalTok{ans_gof <-}\StringTok{ }\KeywordTok{gof}\NormalTok{(ans0)}
\NormalTok{ans_gof}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Goodness-of-fit for in-degree 
## 
##           obs min  mean max MC p-value
## idegree0   13   0  1.43   5       0.00
## idegree1   34   2  8.47  16       0.00
## idegree2   37  13 22.53  33       0.00
## idegree3   48  29 42.25  60       0.38
## idegree4   37  45 57.78  76       0.00
## idegree5   47  44 66.51  88       0.02
## idegree6   42  44 64.18  79       0.00
## idegree7   39  40 53.58  68       0.00
## idegree8   35  23 39.58  53       0.50
## idegree9   21  18 27.43  40       0.28
## idegree10  12   9 16.38  23       0.34
## idegree11  19   1  8.82  16       0.00
## idegree12   4   0  4.63  12       1.00
## idegree13   7   0  2.12   7       0.02
## idegree14   6   0  1.26   5       0.00
## idegree15   3   0  0.44   2       0.00
## idegree16   4   0  0.37   2       0.00
## idegree17   3   0  0.14   1       0.00
## idegree18   3   0  0.06   1       0.00
## idegree19   2   0  0.02   1       0.00
## idegree20   1   0  0.00   0       0.00
## idegree21   0   0  0.02   1       1.00
## idegree22   1   0  0.00   0       0.00
## 
## Goodness-of-fit for out-degree 
## 
##           obs min  mean max MC p-value
## odegree0    4   0  1.56   5       0.10
## odegree1   28   2  8.23  17       0.00
## odegree2   45  11 22.52  33       0.00
## odegree3   50  23 40.11  56       0.10
## odegree4   54  43 59.27  76       0.52
## odegree5   62  50 67.39  93       0.48
## odegree6   40  45 63.79  79       0.00
## odegree7   28  32 54.74  73       0.00
## odegree8   13  27 39.88  50       0.00
## odegree9   16  14 26.17  43       0.04
## odegree10  20   5 16.30  25       0.36
## odegree11   8   4  8.99  17       0.76
## odegree12  11   1  4.73  10       0.00
## odegree13  13   0  2.54   8       0.00
## odegree14   6   0  1.00   3       0.00
## odegree15   6   0  0.45   3       0.00
## odegree16   7   0  0.21   2       0.00
## odegree17   4   0  0.10   2       0.00
## odegree18   3   0  0.02   1       0.00
## 
## Goodness-of-fit for edgewise shared partner 
## 
##       obs  min    mean  max MC p-value
## esp0 1032 1979 2193.78 2313          0
## esp1  755  166  235.04  423          0
## esp2  352    2   16.24   83          0
## esp3  202    0    0.88    5          0
## esp4   79    0    0.02    1          0
## esp5   36    0    0.00    0          0
## esp6   14    0    0.00    0          0
## esp7    4    0    0.00    0          0
## esp8    1    0    0.00    0          0
## 
## Goodness-of-fit for minimum geodesic distance 
## 
##       obs   min     mean   max MC p-value
## 1    2475  2329  2445.96  2573       0.52
## 2   10672 12419 13611.54 15000       0.00
## 3   31134 49756 55207.67 60888       0.00
## 4   50673 77398 79886.41 81893       0.00
## 5   42563 15561 20575.07 26629       0.00
## 6   18719   491  1265.91  2285       0.00
## 7    4808     4    38.99   178       0.00
## 8     822     0     0.77    14       0.00
## 9     100     0     0.03     1       0.00
## 10      7     0     0.00     0       0.00
## Inf 12333     0  1273.65  3321       0.00
## 
## Goodness-of-fit for model statistics 
## 
##                     obs  min    mean  max MC p-value
## edges              2475 2329 2445.96 2573       0.52
## nodematch.hispanic 1832 1740 1826.07 1978       0.86
## nodematch.female1  1879 1760 1860.64 1958       0.76
## nodematch.eversmk1 1755 1646 1733.50 1814       0.46
## mutual              486  434  472.02  498       0.42
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Plotting GOF statistics}
\KeywordTok{plot}\NormalTok{(ans_gof)}
\end{Highlighting}
\end{Shaded}

\includegraphics{04-ergms_files/figure-latex/checking-gof-1.pdf} \includegraphics{04-ergms_files/figure-latex/checking-gof-2.pdf} \includegraphics{04-ergms_files/figure-latex/checking-gof-3.pdf} \includegraphics{04-ergms_files/figure-latex/checking-gof-4.pdf} \includegraphics{04-ergms_files/figure-latex/checking-gof-5.pdf}

Try the following configuration instead

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ans0_bis <-}\StringTok{ }\KeywordTok{ergm}\NormalTok{(}
\NormalTok{  network_}\DecValTok{111} \OperatorTok{~}
\StringTok{    }\NormalTok{edges }\OperatorTok{+}
\StringTok{    }\KeywordTok{nodematch}\NormalTok{(}\StringTok{"hispanic"}\NormalTok{) }\OperatorTok{+}
\StringTok{    }\KeywordTok{nodematch}\NormalTok{(}\StringTok{"female1"}\NormalTok{) }\OperatorTok{+}
\StringTok{    }\NormalTok{mutual }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{esp}\NormalTok{(}\DecValTok{0}\OperatorTok{:}\DecValTok{3}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{idegree}\NormalTok{(}\DecValTok{0}\OperatorTok{:}\DecValTok{10}\NormalTok{)}
\NormalTok{    ,}
  \DataTypeTok{constraints =} \OperatorTok{~}\KeywordTok{bd}\NormalTok{(}\DataTypeTok{maxout =} \DecValTok{19}\NormalTok{),}
  \DataTypeTok{control =} \KeywordTok{control.ergm}\NormalTok{(}
    \DataTypeTok{seed        =} \DecValTok{1}\NormalTok{,}
    \DataTypeTok{MCMLE.maxit =} \DecValTok{15}\NormalTok{,}
    \DataTypeTok{parallel    =} \DecValTok{4}\NormalTok{,}
    \DataTypeTok{CD.maxit    =} \DecValTok{15}\NormalTok{,}
    \DataTypeTok{MCMC.samplesize =} \DecValTok{2048}\OperatorTok{*}\DecValTok{4}\NormalTok{,}
    \DataTypeTok{MCMC.burnin =} \DecValTok{30000}\NormalTok{,}
    \DataTypeTok{MCMC.interval =} \DecValTok{2048}\OperatorTok{*}\DecValTok{4}
\NormalTok{    )}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

Increase the sample size, so the curves are smoother, longer intervals (thinning), which reduces autocorrelation, and a larger burin. All this together to improve the Gelman test statistic. We also added idegree from 0 to 10, and esp from 0 to 3 to explicitly match those statistics in our model.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\OperatorTok{::}\KeywordTok{include_graphics}\NormalTok{(}\StringTok{"awful-chains.png"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!h]
\includegraphics[width=9.92in]{awful-chains} \caption{An example of a terrible ERGM (no convergence at all). Also, a good example of why running multiple chains can be useful}\label{fig:badconvergence}
\end{figure}

\hypertarget{more-on-mcmc-convergence}{%
\section{More on MCMC convergence}\label{more-on-mcmc-convergence}}

For more on this issue, I recommend reviewing \href{http://www.mcmchandbook.net/HandbookChapter1.pdf}{chapter 1} and \href{http://www.mcmchandbook.net/HandbookChapter6.pdf}{chapter 6} from the Handbook of MCMC (Brooks et al. \protect\hyperlink{ref-brooks2011}{2011}). Both chapters are free to download from the \href{http://www.mcmchandbook.net/HandbookSampleChapters.html}{book's website}.

For GOF take a look at section 6 of \href{https://statnet.csde.washington.edu/trac/raw-attachment/wiki/Sunbelt2016/ergm_tutorial.html}{ERGM 2016 Sunbelt tutorial}, and for a more technical review, you can take a look at (David R Hunter, Goodreau, and Handcock \protect\hyperlink{ref-HunterJASA2008}{2008}).

\hypertarget{mathematical-interpretation}{%
\section{Mathematical Interpretation}\label{mathematical-interpretation}}

One of the most critical parts of statistical modeling is interpreting the results,
if not the most important. In the case of ERGMs, a key aspect is based on change
statistics. Suppose that we would like to know how likely the tie \(y_{ij}\) is to
happen, given the rest of the network. We can compute such probabilities using what
literature sometimes describes as the Gibbs-sampler.

In particular, the log-odds of the \(ij\) tie ocurring conditional on the rest of
the network can be written as:

\newcommand{\sufstats}[1]{s\left(#1\right)}
\renewcommand{\exp}[1]{\mbox{exp}\left\{#1\right\}}
\renewcommand{\log}[1]{\mbox{log}\left\{#1\right\}}
\newcommand{\transpose}[1]{{#1}^\mathbf{t}}
\renewcommand{\t}[1]{\transpose{#1}}

\newcommand{\s}[1]{\sufstats{#1}}
\newcommand{\SUFF}{\mathcal{S}}
\newcommand{\Suff}{\mathbf{S}}
\newcommand{\suff}{\mathbf{s}}

\newcommand{\isone}[1]{{\boldsymbol{1}\left( #1 \right)}}
\renewcommand{\Pr}[1]{{\mathbb{P}\left(#1\right) }}
\newcommand{\f}[1]{{f\left(#1\right) }}
\newcommand{\Prcond}[2]{{\mathbb{P}\left(#1\vphantom{#2}\;\right|\left.\vphantom{#1}#2\right)}}
\newcommand{\fcond}[2]{{f\left(#1|#2\right) }}
\newcommand{\Expected}[1]{{\mathbb{E}\left\{#1\right\}}}
\newcommand{\ExpectedCond}[2]{{\mathbb{E}\left\{#1\vphantom{#2}\right|\left.\vphantom{#1}#2\right\}}}
\renewcommand{\exp}[1]{\mbox{exp}\left\{#1\right\}}

\newcommand{\Likelihood}[2]{\text{L}\left(#1 \left|\vphantom{#1}#2\right.\right)}

\newcommand{\loglik}[1]{l\left(#1\right)}
\newcommand{\logit}[1]{\mbox{logit}\left(#1\right)}
\newcommand{\chng}[1]{\delta\left(y_{#1}:0\to1\right)}

\newcommand{\pgraph}{\mathbf{x}}
\newcommand{\snamed}[2]{\s{#1}_{\mbox{#2}}}

\begin{equation}
    \mbox{logit}\left({\mathbb{P}\left(y_{ij} = 1|y_{-ij}\right) }\right) = {\theta}^\mathbf{t}\Delta\delta\left(y_{ij}:0\to 1\right),
\end{equation}

\noindent with \(\delta\left(y_{ij}:0\to 1\right)\equiv s\left(\mathbf{y}\right)_{\mbox{ij}}^+ - s\left(\mathbf{y}\right)_{\mbox{ij}}^-\) as
the vector of change statistics, in other words, the difference between the
sufficient statistics when \(y_{ij}=1\) and its value when \(y_{ij} = 0\). To show
this, we write the following:

\begin{align*}
    {\mathbb{P}\left(y_{ij} = 1|y_{-ij}\right) } & = %
        \frac{{\mathbb{P}\left(y_{ij} = 1, x_{-ij}\right) }}{%
            {\mathbb{P}\left(y_{ij} = 1, y_{-ij}\right) } + {\mathbb{P}\left(y_{ij} = 0, y_{-ij}\right) }} \\
        & = \frac{\mbox{exp}\left\{{\theta}^\mathbf{t}s\left(\mathbf{y}\right)^+_{ij}\right\}}{%
            \mbox{exp}\left\{{\theta}^\mathbf{t}s\left(\mathbf{y}\right)^+_{ij}\right\} + \mbox{exp}\left\{{\theta}^\mathbf{t}s\left(\mathbf{y}\right)^-_{ij}\right\}}
\end{align*}

Applying the logit function to the previous equation, we obtain:

\begin{align*}
& = \mbox{log}\left\{\frac{\mbox{exp}\left\{{\theta}^\mathbf{t}s\left(\mathbf{y}\right)^+_{ij}\right\}}{%
        \mbox{exp}\left\{{\theta}^\mathbf{t}s\left(\mathbf{y}\right)^+_{ij}\right\} + %
        \mbox{exp}\left\{{\theta}^\mathbf{t}s\left(\mathbf{y}\right)^-_{ij}\right\}}\right\} - %
    \mbox{log}\left\{ %
        \frac{\mbox{exp}\left\{{\theta}^\mathbf{t}s\left(\mathbf{y}\right)^-_{ij}\right\}}{%
            \mbox{exp}\left\{{\theta}^\mathbf{t}s\left(\mathbf{y}\right)^+_{ij}\right\} + \mbox{exp}\left\{{\theta}^\mathbf{t}s\left(\mathbf{y}\right)^-_{ij}\right\}}%
     \right\} \\
 & = \mbox{log}\left\{\mbox{exp}\left\{{\theta}^\mathbf{t}s\left(\mathbf{y}\right)^+_{ij}\right\}\right\} - \mbox{log}\left\{\mbox{exp}\left\{{\theta}^\mathbf{t}s\left(\mathbf{y}\right)^-_{ij}\right\}\right\} \\
 & = {\theta}^\mathbf{t}\left(s\left(\mathbf{y}\right)^+_{ij} - s\left(\mathbf{y}\right)^-_{ij}\right) \\
 & = {\theta}^\mathbf{t}\Delta\delta\left(y_{ij}:0\to 1\right)
\end{align*}
\noindent Henceforth, the conditional probability of node \(n\) gaining function \(k\) can be written as:

\begin{equation}
    {\mathbb{P}\left(y_{ij} = 1|y_{-ij}\right) } = \frac{1}{1 + \mbox{exp}\left\{-{\theta}^\mathbf{t}\Delta\delta\left(y_{ij}:0\to 1\right)\right\}}
\end{equation}

\noindent i.e., a logistic probability.

\hypertarget{markov-independence}{%
\section{Markov independence}\label{markov-independence}}

The challenge of analyzing networks is their interdependent nature. Nonetheless, in the absence of such interdependence, ERGMs are equivalent to logistic regression. Conceptually, if all the statistics included in the model do not involve two or more dyads, then the model is non-Markovian in the sense of Markov graphs.

Mathematically, to see this, it suffices to show that the ERGM probability can be written as the product of each dyads' probabilities.

\begin{equation*}
{\mathbb{P}\left(\mathbf{y} | \theta\right) } = \frac{\mbox{exp}\left\{{\theta}^\mathbf{t}s\left(\mathbf{y}\right)\right\}}{\sum_{y}\mbox{exp}\left\{{\theta}^\mathbf{t}s\left(\mathbf{y}\right)\right\}} 
= \frac{\prod_{ij}\mbox{exp}\left\{{\theta}^\mathbf{t}s\left(\mathbf{y}\right)_{ij}\right\}}{\sum_{y}\mbox{exp}\left\{{\theta}^\mathbf{t}s\left(\mathbf{y}\right)\right\}}
\end{equation*}

Where \(s\left(\right)_{ij}\) is a function such that \(s\left(\mathbf{y}\right) = \sum_{ij}{s\left(\mathbf{y}\right)_{ij}}\). We now need to deal with the normalizing constant. To see how that can be saparated, let's start from the result:

\newcommand{\thetaS}[1]{\exp{\transpose{\theta}\s{\mathbf{y}}_{#1}}}

\begin{align*}
& =\prod_{ij}\left(1 + \mbox{exp}\left\{{\theta}^\mathbf{t}s\left(\mathbf{y}\right)_{ij}\right\}\right) \\
& = \left(1 + \mbox{exp}\left\{{\theta}^\mathbf{t}s\left(\mathbf{y}\right)_{11}\right\}\right)\left(1 + \mbox{exp}\left\{{\theta}^\mathbf{t}s\left(\mathbf{y}\right)_{12}\right\}\right)\dots\left(1 + \mbox{exp}\left\{{\theta}^\mathbf{t}s\left(\mathbf{y}\right)_{nn}\right\}\right) \\
& = 1 + \mbox{exp}\left\{{\theta}^\mathbf{t}s\left(\mathbf{y}\right)_{11}\right\} + \mbox{exp}\left\{{\theta}^\mathbf{t}s\left(\mathbf{y}\right)_{11}\right\}\mbox{exp}\left\{{\theta}^\mathbf{t}s\left(\mathbf{y}\right)_{12}\right\} + \dots + \prod_{ij}\mbox{exp}\left\{{\theta}^\mathbf{t}s\left(\mathbf{y}\right)_{ij}\right\} \\
& = 1 + \mbox{exp}\left\{{\theta}^\mathbf{t}s\left(\mathbf{y}\right)_{11}\right\} + \mbox{exp}\left\{{\theta}^\mathbf{t}\left(s\left(\mathbf{y}\right)_{11} + s\left(\mathbf{y}\right)_{12}\right)\right\} + \dots + \prod_{ij}\mbox{exp}\left\{{\theta}^\mathbf{t}s\left(\mathbf{y}\right)_{ij}\right\} \\
& = \sum_{\mathbf{y}\in\mathcal{Y}}\mbox{exp}\left\{{\theta}^\mathbf{t}s\left(\mathbf{y}\right)\right\}
\end{align*}

Where the last equality follows from \(s\left(\mathbf{y}\right) = \sum_{ij}{s\left(\mathbf{y}\right)_{ij}}\). This way, we can now write:

\begin{equation}
\frac{\prod_{ij}\mbox{exp}\left\{{\theta}^\mathbf{t}s\left(\mathbf{y}\right)_{ij}\right\}}{\sum_{y}\mbox{exp}\left\{{\theta}^\mathbf{t}s\left(\mathbf{y}\right)\right\}} = 
\prod_{ij}\frac{\mbox{exp}\left\{{\theta}^\mathbf{t}s\left(\mathbf{y}\right)_{ij}\right\}}{1 + \mbox{exp}\left\{{\theta}^\mathbf{t}s\left(\mathbf{y}\right)_{ij}\right\}}
\end{equation}

Related to this, block-diagonal ERGMs can be estimated as independent models, one per block. To see more about this, read (SNIJDERS \protect\hyperlink{ref-Snijders2010margin}{2010}). Likewise, since independence depends--pun intended--on partitioning the objective function, as pointed by Snijders, non-linear functions make the model dependent, e.g., \(s\left(\mathbf{y}\right) = \sqrt{\sum_{ij}y_{ij}}\), the square root of the edgecount is no longer a bernoulli graph.

\renewcommand{\Pr}[1]{\mathbb{P}{#1}}

\hypertarget{using-constraints-in-ergms}{%
\chapter{Using constraints in ERGMs}\label{using-constraints-in-ergms}}

Exponential Random Graph Models {[}ERGMs{]} can represent a variety of
network classes. We often look at ``regular'' social networks
like students in schools, colleagues in a workplace, or families. Nonetheless,
some social networks we study have features that restrict how connections can
occur. Typical examples are \href{https://en.wikipedia.org/wiki/Bipartite_graph}{bi-partite graphs}
and \href{https://cran.r-project.org/web/packages/mlergm/vignettes/mlergm_tutorial.html}{multilevel networks}.
There are two classes of vertices in bi-partite networks, and ties can only
occur between classes. On the other hand, Multilevel networks may feature
multiple classes with inter-class ties somewhat restricted. In both cases,
structural constraints exist, meaning that some configurations may not
be plausible.

Mathematically, what we are trying to do is, instead of assuming that
all network configurations are possible:

\[
\left\{\mathbf{y} \in \mathcal{Y}: y_{ij} = 0, \forall i = j\right\}
\]

\noindent we want to go a bit further avoiding loops, namely:

\[
\left\{\mathbf{y} \in \mathcal{Y}: y_{ij} = 0, \forall i = j; \mathbf{y} \in C\right\}
\],

\noindent where \(C\) is a constraint, for example, only networks with no triangles.
The \texttt{ergm} R package has built-in capabilities to deal with some of these
cases. Nonetheless, we can specify models with arbitrary
structural constraints built into the model. The key is in using offset terms.

\hypertarget{example-1-interlocking-egos-and-disconnected-alters}{%
\section{Example 1: Interlocking egos and disconnected alters}\label{example-1-interlocking-egos-and-disconnected-alters}}

Imagine that we have two sets of vertices. The first, group \texttt{E}, are egos part of
an egocentric study. The second group, called \texttt{A}, is composed of people mentioned by egos in \texttt{E} but
were not surveyed. Assume that individuals in \texttt{A} can only connect
to individuals in \texttt{E}; moreover, individuals in \texttt{E} have no restrictions connecting to each other.
In other words, only two types of ties exist: \texttt{E-E} and \texttt{A-E}. The question is
now, how can we enforce such a constraint in an ERGM?

Using offsets, and in particular, setting coefficients to \texttt{-Inf} provides
an easy way to restrict the support set of ERGMs. For example, if we wanted
to constrain the support to include networks with no triangles, we would
add the term \texttt{offset(triangle)} and use the option \texttt{offset.coef\ =\ -Inf} to
indicate that realizations including triangles are not possible. Using R:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ergm}\NormalTok{(net }\OperatorTok{~}\StringTok{ }\NormalTok{edges }\OperatorTok{+}\StringTok{ }\KeywordTok{offset}\NormalTok{(triangle), }\DataTypeTok{offset.coef =} \OperatorTok{-}\OtherTok{Inf}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

In this model, a Bernoulli graph, we reduce the sample space to networks
with no triangles. In our example, such statistic should only take non-zero
values whenever ties within the \texttt{A} class happen. We can use
the \texttt{nodematch()} term to do that. Formally

\[
\text{NodeMatch}(x) = \sum_{i,j} y_{ij} \mathbf{1}({x_{i} = x_{j}})
\]

This statistic will sum over all ties in which source (\(i\)) and target (\(j\))'s
\(X\) attribute is equal. One way to make this happen is by creating an auxiliary
variable that equals, e.g., 0 for all vertices in \texttt{A}, and a unique value
different from zero otherwise. For example, if we had 2 \texttt{A}s and three \texttt{E}s,
the data would look something like this: \(\{0,0,1,2,3\}\). The following code
block creates an empty graph with 50 nodes, 10 of which are in group \texttt{E} (ego).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(ergm, }\DataTypeTok{quietly =}  \OtherTok{TRUE}\NormalTok{)}
\KeywordTok{library}\NormalTok{(sna, }\DataTypeTok{quietly =}  \OtherTok{TRUE}\NormalTok{)}

\NormalTok{n <-}\StringTok{ }\DecValTok{50}
\NormalTok{n_egos <-}\StringTok{ }\DecValTok{10}
\NormalTok{net <-}\StringTok{ }\KeywordTok{as.network}\NormalTok{(}\KeywordTok{matrix}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DataTypeTok{ncol =}\NormalTok{ n, }\DataTypeTok{nrow =}\NormalTok{ n), }\DataTypeTok{directed =} \OtherTok{TRUE}\NormalTok{)}

\CommentTok{# Let's assing the groups}
\NormalTok{net }\OperatorTok{%v%}\StringTok{ "is.ego"}\NormalTok{ <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\KeywordTok{rep}\NormalTok{(}\OtherTok{TRUE}\NormalTok{, n_egos), }\KeywordTok{rep}\NormalTok{(}\OtherTok{FALSE}\NormalTok{, n }\OperatorTok{-}\StringTok{ }\NormalTok{n_egos))}
\NormalTok{net }\OperatorTok{%v%}\StringTok{ "is.ego"}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE
## [13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
## [25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
## [37] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
## [49] FALSE FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{gplot}\NormalTok{(net, }\DataTypeTok{vertex.col =}\NormalTok{ net }\OperatorTok{%v%}\StringTok{ "is.ego"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{05-ergms-constrains_files/figure-latex/unnamed-chunk-1-1.pdf}

To create the auxiliary variable, we will use the following function:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Function that creates an aux variable for the ergm model}
\NormalTok{make_aux_var <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(my_net, is_ego_dummy) \{}
  
\NormalTok{  n_vertex <-}\StringTok{ }\KeywordTok{length}\NormalTok{(my_net }\OperatorTok{%v%}\StringTok{ }\NormalTok{is_ego_dummy)}
\NormalTok{  n_ego_   <-}\StringTok{ }\KeywordTok{sum}\NormalTok{(my_net }\OperatorTok{%v%}\StringTok{ }\NormalTok{is_ego_dummy)}
  
  \CommentTok{# Creating an auxiliary variable to identify the non-informant non-informant ties}
\NormalTok{  my_net }\OperatorTok{%v%}\StringTok{ "aux_var"}\NormalTok{ <-}\StringTok{ }\KeywordTok{ifelse}\NormalTok{(}
    \OperatorTok{!}\NormalTok{my_net }\OperatorTok{%v%}\StringTok{ }\NormalTok{is_ego_dummy, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\OperatorTok{:}\NormalTok{(n_vertex }\OperatorTok{-}\StringTok{ }\NormalTok{n_ego_)}
\NormalTok{    )}

\NormalTok{  my_net}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Calling the function in our data results in the following:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{net <-}\StringTok{ }\KeywordTok{make_aux_var}\NormalTok{(net, }\StringTok{"is.ego"}\NormalTok{)}

\CommentTok{# Taking a look over the first 15 rows of data}
\KeywordTok{cbind}\NormalTok{(}
  \DataTypeTok{Is_Ego =}\NormalTok{ net }\OperatorTok{%v%}\StringTok{ "is.ego"}\NormalTok{,}
  \DataTypeTok{Aux    =}\NormalTok{ net }\OperatorTok{%v%}\StringTok{ "aux_var"}  
\NormalTok{) }\OperatorTok{|}\ErrorTok{>}\StringTok{ }\KeywordTok{head}\NormalTok{(}\DataTypeTok{n =} \DecValTok{15}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       Is_Ego Aux
##  [1,]      1   1
##  [2,]      1   2
##  [3,]      1   3
##  [4,]      1   4
##  [5,]      1   5
##  [6,]      1   6
##  [7,]      1   7
##  [8,]      1   8
##  [9,]      1   9
## [10,]      1  10
## [11,]      0   0
## [12,]      0   0
## [13,]      0   0
## [14,]      0   0
## [15,]      0   0
\end{verbatim}

We can now use this data to simulate a network in which ties between
\texttt{A}-class vertices are not possible:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{2828}\NormalTok{)}
\NormalTok{net_sim <-}\StringTok{ }\KeywordTok{simulate}\NormalTok{(net }\OperatorTok{~}\StringTok{ }\NormalTok{edges }\OperatorTok{+}\StringTok{ }\KeywordTok{nodematch}\NormalTok{(}\StringTok{"aux_var"}\NormalTok{), }\DataTypeTok{coef =} \KeywordTok{c}\NormalTok{(}\OperatorTok{-}\FloatTok{3.0}\NormalTok{, }\OperatorTok{-}\OtherTok{Inf}\NormalTok{))}
\KeywordTok{gplot}\NormalTok{(net_sim, }\DataTypeTok{vertex.col =}\NormalTok{ net_sim }\OperatorTok{%v%}\StringTok{ "is.ego"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{05-ergms-constrains_files/figure-latex/unnamed-chunk-4-1.pdf}

As you can see, this network has only ties of the type \texttt{E-E} and \texttt{A-E}. We can
double-check by (i) looking at the counts and (ii) visualizing each induced-subgraph
separately:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(net_sim }\OperatorTok{~}\StringTok{ }\NormalTok{edges }\OperatorTok{+}\StringTok{ }\KeywordTok{nodematch}\NormalTok{(}\StringTok{"aux_var"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##             edges nodematch.aux_var 
##                49                 0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{net_of_alters <-}\StringTok{ }\KeywordTok{get.inducedSubgraph}\NormalTok{(}
\NormalTok{  net_sim, }\KeywordTok{which}\NormalTok{((net_sim }\OperatorTok{%v%}\StringTok{ "aux_var"}\NormalTok{) }\OperatorTok{==}\StringTok{ }\DecValTok{0}\NormalTok{)}
\NormalTok{  )}

\NormalTok{net_of_egos <-}\StringTok{ }\KeywordTok{get.inducedSubgraph}\NormalTok{(}
\NormalTok{  net_sim, }\KeywordTok{which}\NormalTok{((net_sim }\OperatorTok{%v%}\StringTok{ "aux_var"}\NormalTok{) }\OperatorTok{!=}\StringTok{ }\DecValTok{0}\NormalTok{)}
\NormalTok{  )}

\CommentTok{# Counts}
\KeywordTok{summary}\NormalTok{(net_of_alters }\OperatorTok{~}\StringTok{ }\NormalTok{edges }\OperatorTok{+}\StringTok{ }\KeywordTok{nodematch}\NormalTok{(}\StringTok{"aux_var"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##             edges nodematch.aux_var 
##                 0                 0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(net_of_egos }\OperatorTok{~}\StringTok{ }\NormalTok{edges }\OperatorTok{+}\StringTok{ }\KeywordTok{nodematch}\NormalTok{(}\StringTok{"aux_var"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##             edges nodematch.aux_var 
##                 1                 0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Figures}
\NormalTok{op <-}\StringTok{ }\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfcol =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\KeywordTok{gplot}\NormalTok{(net_of_alters, }\DataTypeTok{vertex.col =}\NormalTok{ net_of_alters }\OperatorTok{%v%}\StringTok{ "is.ego"}\NormalTok{, }\DataTypeTok{main =} \StringTok{"A"}\NormalTok{)}
\KeywordTok{gplot}\NormalTok{(net_of_egos, }\DataTypeTok{vertex.col =}\NormalTok{ net_of_egos }\OperatorTok{%v%}\StringTok{ "is.ego"}\NormalTok{, }\DataTypeTok{main =} \StringTok{"E"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{05-ergms-constrains_files/figure-latex/unnamed-chunk-5-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{par}\NormalTok{(op)}
\end{Highlighting}
\end{Shaded}

Now, to fit an ERGM with this constraint, we simply need to make use of
the offset terms. Here is an example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ans <-}\StringTok{ }\KeywordTok{ergm}\NormalTok{(}
\NormalTok{  net_sim }\OperatorTok{~}\StringTok{ }\NormalTok{edges }\OperatorTok{+}\StringTok{ }\KeywordTok{offset}\NormalTok{(}\KeywordTok{nodematch}\NormalTok{(}\StringTok{"aux_var"}\NormalTok{)), }\CommentTok{# The model (notice the offset)}
  \DataTypeTok{offset.coef =} \OperatorTok{-}\OtherTok{Inf}                              \CommentTok{# The offset coefficient}
\NormalTok{  )}
\CommentTok{## Starting maximum pseudolikelihood estimation (MPLE):}
\CommentTok{## Evaluating the predictor and response matrix.}
\CommentTok{## Maximizing the pseudolikelihood.}
\CommentTok{## Finished MPLE.}
\CommentTok{## Stopping at the initial estimate.}
\CommentTok{## Evaluating log-likelihood at the estimate.}
\KeywordTok{summary}\NormalTok{(ans)}
\CommentTok{## Call:}
\CommentTok{## ergm(formula = net_sim ~ edges + offset(nodematch("aux_var")), }
\CommentTok{##     offset.coef = -Inf)}
\CommentTok{## }
\CommentTok{## Maximum Likelihood Results:}
\CommentTok{## }
\CommentTok{##                           Estimate Std. Error MCMC % z value Pr(>|z|)    }
\CommentTok{## edges                       -2.843      0.147      0  -19.34   <1e-04 ***}
\CommentTok{## offset(nodematch.aux_var)     -Inf      0.000      0    -Inf   <1e-04 ***}
\CommentTok{## ---}
\CommentTok{## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1}
\CommentTok{## }
\CommentTok{##      Null Deviance: 1233.8  on 2450  degrees of freedom}
\CommentTok{##  Residual Deviance:  379.4  on 2448  degrees of freedom}
\CommentTok{##  }
\CommentTok{## AIC: 381.4  BIC: 386.2  (Smaller is better. MC Std. Err. = 0)}
\CommentTok{## }
\CommentTok{##  The following terms are fixed by offset and are not estimated:}
\CommentTok{##   offset(nodematch.aux_var)}
\end{Highlighting}
\end{Shaded}

This ERGM model--which by the way only featured dyadic-independent terms, and
thus can be reduced to a logistic regression--restricts the support by excluding
all networks in which ties within the class \texttt{A} exists. To finalize, let's look
at a few simulations based on this model:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{1323}\NormalTok{)}
\NormalTok{op <-}\StringTok{ }\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfcol =} \KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{mar =} \KeywordTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{4}\NormalTok{))}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\DecValTok{4}\NormalTok{) \{}
  \KeywordTok{gplot}\NormalTok{(}\KeywordTok{simulate}\NormalTok{(ans), }\DataTypeTok{vertex.col =}\NormalTok{ net }\OperatorTok{%v%}\StringTok{ "is.ego"}\NormalTok{, }\DataTypeTok{vertex.cex =} \DecValTok{2}\NormalTok{)}
  \KeywordTok{box}\NormalTok{()}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\includegraphics{05-ergms-constrains_files/figure-latex/unnamed-chunk-7-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{par}\NormalTok{(op)}
\end{Highlighting}
\end{Shaded}

All networks with no ties between \texttt{A} nodes.

\hypertarget{example-2-bi-partite-networks}{%
\section{Example 2: Bi-partite networks}\label{example-2-bi-partite-networks}}

In the case of bipartite networks (sometimes called affiliation networks,) we can
use \texttt{ergm}'s terms for bipartite graphs to corroborate what we discussed
here. For example, the two-star term. Let's start simulating a bipartite
network using the \texttt{edges} and \texttt{two-star} parameters. Since the \texttt{k-star} term
is usually complex to fit (tends to generate degenerate models,) we will
take advantage of the \texttt{Log()} transformation function in the \texttt{ergm} package
to smooth the term.\footnote{After writing this example, it became apparent the use of
  the \texttt{Log()} transformation function may not be ideal. Since many terms used
  in ERGMs can be zero, e.g., triangles, the term \texttt{Log(\textasciitilde{}\ ostar(2))} is undefined
  when \texttt{ostar(2)\ =\ 0}. In practice, the ERGM package sets a lower limit for the
  log of 0, so, instead of having \texttt{Log(0)\ \textasciitilde{}\ -Inf}, they set it to be a really
  large negative number. This causes all sorts of issues to the estimates; in
  our example, an over estimation of the population parameter and a positive
  log-likelihood. With that said, I wouldn't recommend using
  this transformation too often.}

The bipartite network that we will be simulating will have 100 actors and
50 entities. Actors, which we will map to the first level of the \texttt{ergm} terms,
this is, \texttt{b1star} \texttt{b1nodematch}, etc. will send ties to the entities,
the second level of the bipartite ERGM. To create a bipartite network, we will
create an empty matrix of size \texttt{nactors\ x\ nentitites}; thus, actors are
represented by rows and entities by columns.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Parameters for the simulation}
\NormalTok{nactors   <-}\StringTok{ }\DecValTok{100}
\NormalTok{nentities <-}\StringTok{ }\KeywordTok{floor}\NormalTok{(nactors}\OperatorTok{/}\DecValTok{2}\NormalTok{)}
\NormalTok{n         <-}\StringTok{ }\NormalTok{nactors }\OperatorTok{+}\StringTok{ }\NormalTok{nentities}

\CommentTok{# Creating an empty bipartite network (baseline)}
\NormalTok{net_b <-}\StringTok{ }\KeywordTok{network}\NormalTok{(}
  \KeywordTok{matrix}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DataTypeTok{nrow =}\NormalTok{ nactors, }\DataTypeTok{ncol =}\NormalTok{ nentities), }\DataTypeTok{bipartite =} \OtherTok{TRUE}
\NormalTok{)}

\CommentTok{# Simulating the bipartite ERGM,}
\NormalTok{net_b <-}\StringTok{ }\KeywordTok{simulate}\NormalTok{(net_b }\OperatorTok{~}\StringTok{ }\NormalTok{edges }\OperatorTok{+}\StringTok{ }\KeywordTok{Log}\NormalTok{(}\OperatorTok{~}\KeywordTok{b1star}\NormalTok{(}\DecValTok{2}\NormalTok{)), }\DataTypeTok{coef =} \KeywordTok{c}\NormalTok{(}\OperatorTok{-}\DecValTok{3}\NormalTok{, }\FloatTok{1.5}\NormalTok{), }\DataTypeTok{seed =} \DecValTok{55}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Let's see what we got here:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(net_b }\OperatorTok{~}\StringTok{ }\NormalTok{edges }\OperatorTok{+}\StringTok{ }\KeywordTok{Log}\NormalTok{(}\OperatorTok{~}\KeywordTok{b1star}\NormalTok{(}\DecValTok{2}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       edges Log~b1star2 
##  245.000000    5.746203
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{netplot}\OperatorTok{::}\KeywordTok{nplot}\NormalTok{(net_b, }\DataTypeTok{vertex.col =}\NormalTok{ (}\DecValTok{1}\OperatorTok{:}\NormalTok{n }\OperatorTok{<=}\StringTok{ }\NormalTok{nactors) }\OperatorTok{+}\StringTok{ }\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{05-ergms-constrains_files/figure-latex/05-example2-simulated-graph-1.pdf}

Notice that the first \texttt{nactors} vertices in the network are the actors, and
the remaining are the entities. Now, although the \texttt{ergm} package features
bipartite network terms, we can still fit a bipartite ERGM without explicitly
declaring the graph as such. In such case, the \texttt{b1star(2)} term of a bipartite
network is equivalent to an \texttt{ostar(2)} in a directed graph. Likewise, \texttt{b2star(2)}
in a bipartite graph matches the \texttt{istar(2)} term in a directed graph. This
information will be relevant when fitting the ERGM. Let's transform the bipartite
network into a directed graph. The following code block does so:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Identifying the edges}
\NormalTok{net_not_b <-}\StringTok{ }\KeywordTok{which}\NormalTok{(}\KeywordTok{as.matrix}\NormalTok{(net_b) }\OperatorTok{!=}\StringTok{ }\DecValTok{0}\NormalTok{, }\DataTypeTok{arr.ind =} \OtherTok{TRUE}\NormalTok{)}

\CommentTok{# We need to offset the endpoint of the ties by nactors}
\CommentTok{# so that the ids go from 1 through (nactors + nentitites)}
\NormalTok{net_not_b[,}\DecValTok{2}\NormalTok{] <-}\StringTok{ }\NormalTok{net_not_b[,}\DecValTok{2}\NormalTok{] }\OperatorTok{+}\StringTok{ }\NormalTok{nactors}

\CommentTok{# The resulting graph is a directed network}
\NormalTok{net_not_b <-}\StringTok{ }\KeywordTok{network}\NormalTok{(net_not_b, }\DataTypeTok{directed =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Now we are almost done. As before, we need to use node-level covariates
to put the constraints in our model. For this ERGM to reflect an ERGM on
a bipartite network, we need two constraints:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Only ties from actors to entities are allowed, and
\item
  entities can only receive ties.
\end{enumerate}

The corresponding offset terms for this model are: \texttt{nodematch("is.actor")\ \textasciitilde{}\ -Inf},
and \texttt{nodeocov("isnot.actor")\ \textasciitilde{}\ -Inf}. Mathematically:

\begin{align*}
\text{NodeMatch(x = "is.actor")} &= \sum_{i<j} y_{ij}\mathbb{1}\left(x_i = x_j\right) \\
\text{NodeOCov(x = "isnot.actor")} &= \sum_{i} x_i \times \sum_{j<i} y_{ij} 
\end{align*}

In other words, we are setting that ties between nodes of the same class are
forbidden, and outgoing ties are forbidden for entities. Let's create the
vertex attributes needed to use the aforementioned terms:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{net_not_b }\OperatorTok{%v%}\StringTok{ "is.actor"}\NormalTok{ <-}\StringTok{ }\KeywordTok{as.integer}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\NormalTok{n }\OperatorTok{<=}\StringTok{ }\NormalTok{nactors)}
\NormalTok{net_not_b }\OperatorTok{%v%}\StringTok{ "isnot.actor"}\NormalTok{ <-}\StringTok{ }\KeywordTok{as.integer}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\NormalTok{n }\OperatorTok{>}\StringTok{ }\NormalTok{nactors)}
\end{Highlighting}
\end{Shaded}

Finally, to make sure we have done all well, let's look how both networks--bipartite
and unimodal--look side by side:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# First, let's get the layout}
\NormalTok{fig <-}\StringTok{ }\NormalTok{netplot}\OperatorTok{::}\KeywordTok{nplot}\NormalTok{(net_b, }\DataTypeTok{vertex.col =}\NormalTok{ (}\DecValTok{1}\OperatorTok{:}\NormalTok{n }\OperatorTok{<=}\StringTok{ }\NormalTok{nactors) }\OperatorTok{+}\StringTok{ }\DecValTok{1}\NormalTok{)}
\NormalTok{gridExtra}\OperatorTok{::}\KeywordTok{grid.arrange}\NormalTok{(}
\NormalTok{  fig,}
\NormalTok{  netplot}\OperatorTok{::}\KeywordTok{nplot}\NormalTok{(}
\NormalTok{    net_not_b, }\DataTypeTok{vertex.col =}\NormalTok{ (}\DecValTok{1}\OperatorTok{:}\NormalTok{n }\OperatorTok{<=}\StringTok{ }\NormalTok{nactors) }\OperatorTok{+}\StringTok{ }\DecValTok{1}\NormalTok{,}
    \DataTypeTok{layout =}\NormalTok{ fig}\OperatorTok{$}\NormalTok{.layout}
\NormalTok{     ),}
  \DataTypeTok{ncol =} \DecValTok{2}\NormalTok{, }\DataTypeTok{nrow =} \DecValTok{1}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{05-ergms-constrains_files/figure-latex/05-example2-side-by-side-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Looking at the counts}
\KeywordTok{summary}\NormalTok{(net_b }\OperatorTok{~}\StringTok{ }\NormalTok{edges }\OperatorTok{+}\StringTok{ }\KeywordTok{b1star}\NormalTok{(}\DecValTok{2}\NormalTok{) }\OperatorTok{+}\StringTok{ }\KeywordTok{b2star}\NormalTok{(}\DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   edges b1star2 b2star2 
##     245     313     645
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(net_not_b }\OperatorTok{~}\StringTok{ }\NormalTok{edges }\OperatorTok{+}\StringTok{ }\KeywordTok{ostar}\NormalTok{(}\DecValTok{2}\NormalTok{) }\OperatorTok{+}\StringTok{ }\KeywordTok{istar}\NormalTok{(}\DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  edges ostar2 istar2 
##    245    313    645
\end{verbatim}

With the two networks matching, we can now fit the ERGMs with and without
offset terms and compare the results between the two models:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# ERGM with a bipartite graph}
\NormalTok{res_b     <-}\StringTok{ }\KeywordTok{ergm}\NormalTok{(}
  \CommentTok{# Main formula}
\NormalTok{  net_b }\OperatorTok{~}\StringTok{ }\NormalTok{edges }\OperatorTok{+}\StringTok{ }\KeywordTok{Log}\NormalTok{(}\OperatorTok{~}\KeywordTok{b1star}\NormalTok{(}\DecValTok{2}\NormalTok{)),}

  \CommentTok{# Control parameters}
  \DataTypeTok{control =} \KeywordTok{control.ergm}\NormalTok{(}\DataTypeTok{seed =} \DecValTok{1}\NormalTok{)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: 'glpk' selected as the solver, but package 'Rglpk' is not available;
## falling back to 'lpSolveAPI'. This should be fine unless the sample size and/or
## the number of parameters is very big.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# ERGM with a digraph with constraints}
\NormalTok{res_not_b <-}\StringTok{ }\KeywordTok{ergm}\NormalTok{(}
  \CommentTok{# Main formula}
\NormalTok{  net_not_b }\OperatorTok{~}\StringTok{ }\NormalTok{edges }\OperatorTok{+}\StringTok{ }\KeywordTok{Log}\NormalTok{(}\OperatorTok{~}\KeywordTok{ostar}\NormalTok{(}\DecValTok{2}\NormalTok{)) }\OperatorTok{+}

\StringTok{  }\CommentTok{# Offset terms }
\StringTok{  }\KeywordTok{offset}\NormalTok{(}\KeywordTok{nodematch}\NormalTok{(}\StringTok{"is.actor"}\NormalTok{)) }\OperatorTok{+}\StringTok{ }\KeywordTok{offset}\NormalTok{(}\KeywordTok{nodeocov}\NormalTok{(}\StringTok{"isnot.actor"}\NormalTok{)),}
  \DataTypeTok{offset.coef =} \KeywordTok{c}\NormalTok{(}\OperatorTok{-}\OtherTok{Inf}\NormalTok{, }\OperatorTok{-}\OtherTok{Inf}\NormalTok{),}

  \CommentTok{# Control parameters}
  \DataTypeTok{control =} \KeywordTok{control.ergm}\NormalTok{(}\DataTypeTok{seed =} \DecValTok{1}\NormalTok{)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

Here are the estimates (using the \texttt{texreg} R package for a prettier output):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{texreg}\OperatorTok{::}\KeywordTok{screenreg}\NormalTok{(}\KeywordTok{list}\NormalTok{(}\DataTypeTok{Bipartite =}\NormalTok{ res_b, }\DataTypeTok{Directed =}\NormalTok{ res_not_b))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## ======================================================================
##                               Bipartite    Directed                   
## ----------------------------------------------------------------------
## edges                           -3.14 ***                    -3.11 ***
##                                 (0.15)                       (0.14)   
## Log~b1star2                     21.89                                 
##                                (17.13)                                
## Log~ostar2                                                   19.66    
##                                                             (16.75)   
## offset(nodematch.is.actor)                                    -Inf    
##                                                                       
## offset(nodeocov.isnot.actor)                                  -Inf    
##                                                                       
## ----------------------------------------------------------------------
## AIC                           1958.00      -2134192392498171136.00    
## BIC                           1971.03      -2134192392498171136.00    
## Log Likelihood                -977.00       1067096196249085568.00    
## ======================================================================
## *** p < 0.001; ** p < 0.01; * p < 0.05
\end{verbatim}

As expected, both models yield the ``same'' estimate. The minor differences
observed between the models are how the \texttt{ergm} package performs
the sampling. In particular, in the bipartite case, \texttt{ergm} has special
routines for making the sampling more efficient, having a higher acceptance
rate than that of the model in which the bipartite graph was not explicitly
declared. We can tell this by inspecting rejection rates:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{data.frame}\NormalTok{(}
  \DataTypeTok{Bipartite =}\NormalTok{ coda}\OperatorTok{::}\KeywordTok{rejectionRate}\NormalTok{(res_b}\OperatorTok{$}\NormalTok{sample[[}\DecValTok{1}\NormalTok{]]) }\OperatorTok{*}\StringTok{ }\DecValTok{100}\NormalTok{,}
  \DataTypeTok{Directed  =}\NormalTok{ coda}\OperatorTok{::}\KeywordTok{rejectionRate}\NormalTok{(res_not_b}\OperatorTok{$}\NormalTok{sample[[}\DecValTok{1}\NormalTok{]][, }\OperatorTok{-}\KeywordTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{)]) }\OperatorTok{*}\StringTok{ }\DecValTok{100}
\NormalTok{) }\OperatorTok{|}\ErrorTok{>}\StringTok{ }\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}\DataTypeTok{digits =} \DecValTok{2}\NormalTok{, }\DataTypeTok{caption =} \StringTok{"Rejection rate (percent)"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:05-example2-post-dist}Rejection rate (percent)}
\centering
\begin{tabular}[t]{l|r|r}
\hline
  & Bipartite & Directed\\
\hline
edges & 2.48 & 3.67\\
\hline
Log\textasciitilde{}b1star2 & 1.24 & 2.04\\
\hline
\end{tabular}
\end{table}

The ERGM fitted with the offset terms has a much higher rejection rate
than that of the ERGM fitted with the bipartite ERGM.

Finally, the fact that we can fit ERGMs using offset does not mean that
we need to use it ALL the time. Unless there is a very good reason to
go around \texttt{ergm}'s capabilities, I wouldn't recommend fitting bipartite
ERGMs as we just did, as the authors of the package have included (MANY)
features to make our job easier.

\hypertarget{separable-temporal-exponential-family-random-graph-models}{%
\chapter{(Separable) Temporal Exponential Family Random Graph Models}\label{separable-temporal-exponential-family-random-graph-models}}

This tutorial is great! \url{https://statnet.org/trac/raw-attachment/wiki/Sunbelt2016/tergm_tutorial.pdf}

\hypertarget{simulating-and-visualizing-networks}{%
\chapter{Simulating and visualizing networks}\label{simulating-and-visualizing-networks}}

In this chapter, we will build and visualize artificial networks using Exponential
Random Graph Models {[}ERGMs.{]} Together with chapter 3, this will be an extended
example of how to read network data and visualize it using some of the available
R packages out there.

For this chapter, we will be using the following R packages:

\begin{itemize}
\tightlist
\item
  \texttt{ergm}: To simulate and estimate ERGMs.
\item
  \texttt{sna}: To visualize networks.
\item
  \texttt{igraph}: Also to visualize networks.
\item
  \texttt{intergraph}: To convert between \texttt{igraph} and \texttt{network} objects.
\item
  \texttt{netplot}: Again, for visualization.
\item
  \texttt{netdiffuseR}: For a single function we use for adjusting vertex size in igraph.
\item
  \texttt{rgexf}: For building interactive (html) figures.
\end{itemize}

You can use the following codeblock to install any missing package:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Creating the list to install}
\NormalTok{pkgs <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}
  \StringTok{"ergm"}\NormalTok{, }\StringTok{"sna"}\NormalTok{, }\StringTok{"igraph"}\NormalTok{, }\StringTok{"intergraph"}\NormalTok{, }\StringTok{"netplot"}\NormalTok{, }\StringTok{"netdiffuseR"}\NormalTok{, }\StringTok{"rgexf"}
\NormalTok{  )}

\CommentTok{# Checking if we can load them and install them if not available}
\ControlFlowTok{for}\NormalTok{ (pkg }\ControlFlowTok{in}\NormalTok{ pkgs) \{}
  \ControlFlowTok{if}\NormalTok{ (}\OperatorTok{!}\KeywordTok{require}\NormalTok{(pkg, }\DataTypeTok{character.only =} \OtherTok{TRUE}\NormalTok{)) \{}

    \CommentTok{# If not present, will install it}
    \KeywordTok{install.packages}\NormalTok{(pkg, }\DataTypeTok{character.only =} \OtherTok{TRUE}\NormalTok{)}

    \CommentTok{# And load it!}
    \KeywordTok{library}\NormalTok{(pkg, }\DataTypeTok{character.only =} \OtherTok{TRUE}\NormalTok{)}

\NormalTok{  \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\hypertarget{random-graph-models}{%
\section{Random Graph Models}\label{random-graph-models}}

While there are tons of social network data, we will use an artificial one for this chapter.
We do this as it is always helpful to have more examples simulating Random
networks. For this chapter, we will classify random graph models for sampling and
generating networks into three categories:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Exogenous}: Graphs where the structure is determined by a macro rule, e.g.,
  expected density, degree distribution, or degree-sequence. In these cases,
  ties are assigned to comply with a macro-property.
\item
  \textbf{Endogenous}: This category includes all Random Graphs generated based
  on endogenous information, e.g., small-world, scale-free, etc. Here, a tie
  creation rule gives origin to a macro property, for example, preferential attachment
  in scale-free networks.
\item
  \textbf{Exponential Random Graph Models}: Overall, since ERGMs compose a family
  of statistical models, we can always (or almost always) find a model specification
  that matches the previous categories. Whereas we are thinking about degree sequence,
  preferential attachment, or a mix of both, ERGMs can be the baseline for any of
  those models.
\end{enumerate}

The latter, ERGMs, are a generalization that covers all classes. Because of that,
we will use ERGMs to generate our artificial network.

\hypertarget{social-networks-in-schools}{%
\section{Social Networks in Schools}\label{social-networks-in-schools}}

A common type of network we analyze is friendship networks. In this case,
we will use ERGMs to simulate friendship networks within a school. In our
simulated world, these networks will be dominated by the following phenomena

\begin{itemize}
\tightlist
\item
  Low density,
\item
  Race homophily,
\item
  Structural balance,
\item
  And age homophily.
\end{itemize}

If you have been paying attention to the previous chapters, you will notice that,
out of these five properties, only one constitutes Markov graphs. Within a tie,
homophily and density only depend on ego and alter. In race homophily, only ego
and alter's race matter for the tie formation, but, in the case of Structural
balance, ego is more likely to befriend alter if a fried of ego is friends with alter,
i.e., ``the friend of my friend is my friend.''

The simulation steps are as follows:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Draw a population of \(n\) students and randomly distribute race and age across them.
\item
  Create a \texttt{network} object.
\item
  Simulate the ties in the empty network.
\end{enumerate}

Here is the code

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{712}\NormalTok{)}
\NormalTok{n <-}\StringTok{ }\DecValTok{200}

\CommentTok{# Step 1: Students}
\NormalTok{race   <-}\StringTok{ }\KeywordTok{sample}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"white"}\NormalTok{, }\StringTok{"non-white"}\NormalTok{), n, }\DataTypeTok{replace =} \OtherTok{TRUE}\NormalTok{)}
\NormalTok{age    <-}\StringTok{ }\KeywordTok{sample}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{14}\NormalTok{, }\DecValTok{17}\NormalTok{), n, }\DataTypeTok{replace =} \OtherTok{TRUE}\NormalTok{)}

\CommentTok{# Step 2: Create an empty network}
\KeywordTok{library}\NormalTok{(ergm)}
\KeywordTok{library}\NormalTok{(network)}
\NormalTok{net <-}\StringTok{ }\KeywordTok{network.initialize}\NormalTok{(n)}

\NormalTok{net }\OperatorTok{%v%}\StringTok{ "race"}\NormalTok{   <-}\StringTok{ }\NormalTok{race}
\NormalTok{net }\OperatorTok{%v%}\StringTok{ "age"}\NormalTok{    <-}\StringTok{ }\NormalTok{age}

\CommentTok{# Step 3: Simulate a graph}
\NormalTok{net_sim <-}\StringTok{ }\KeywordTok{simulate}\NormalTok{(}
\NormalTok{    net }\OperatorTok{~}\StringTok{ }\NormalTok{edges }\OperatorTok{+}
\StringTok{    }\KeywordTok{nodematch}\NormalTok{(}\StringTok{"race"}\NormalTok{) }\OperatorTok{+}
\StringTok{    }\NormalTok{ttriad }\OperatorTok{+}
\StringTok{    }\KeywordTok{absdiff}\NormalTok{(}\StringTok{"age"}\NormalTok{),}
    \DataTypeTok{coef =} \KeywordTok{c}\NormalTok{(}\OperatorTok{-}\DecValTok{4}\NormalTok{, }\FloatTok{.5}\NormalTok{, }\FloatTok{.25}\NormalTok{, }\FloatTok{-.5}\NormalTok{)}
\NormalTok{    )}
\end{Highlighting}
\end{Shaded}

What just happened? Here is a line-by-line breakout:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \texttt{set.seed(712)} Since this is a random simulation, we need to fix a seed so it is reproducible. Otherwise, results would change with every iteration.
\item
  \texttt{n\ \textless{}-\ 200} We are assigning the value \texttt{200} to the object \texttt{n}. This will make things easier as, if needed, changing the size of the networks can be done at the top of the code.
\item
  \texttt{race\ \textless{}-\ sample(c("white",\ "non-white"),\ n,\ replace\ =\ TRUE)} We are sampling 200, or actually, \texttt{n} values from the vector \texttt{c("white",\ "non-white")} with replacement.
\item
  \texttt{age\ \textless{}-\ sample(c(10,\ 14,\ 17),\ n,\ replace\ =\ TRUE)} Same as before, but with ages!
\item
  \texttt{library(ergm)} Loading the ergm R package, which we need to simulate the networks!
\item
  \texttt{library(network)} Loading the \texttt{network} R package, which we need to create the empty graph.
\item
  \texttt{net\ \textless{}-\ network.initialize(n)} Creating an empty graph of size \texttt{n}.
\item
  \texttt{net\ \%v\%\ "race"\ \textless{}-\ race} Using the \texttt{\%v\%} operator, we can access vertices features in the network object. Since race does not exist in the network yet, the operator just creates it. Notice that the number of vertices matches the length of the race vector.
\item
  \texttt{net\ \%v\%\ "age"\ \textless{}-\ age} Same as with race!
\item
  \texttt{net\_sim\ \textless{}-\ simulate(} Simulating an ERGM! A couple of observations here:

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \item
    The LHS (left-hand-side) of the equation has the network, \texttt{net}
  \item
    The RHS (you guessed it) has the terms that govern the process.
  \item
    For low density, we used the \texttt{edges} term with a corresponding
    -4.0 for the parameter.
  \item
    For race homophily, we used the \texttt{nodematch("race")} with a
    corresponding 0.5 parameter value.
  \item
    For structural balance, we use the \texttt{ttriad} term with parameter
    0.25.
  \item
    For age homophily, we use the \texttt{absdiff("age")} term with parameter
    -0.5. This is, in rigor, a term capturing heterophily. Nonetheless,
    heterophily is the opposite of homophily.
  \end{enumerate}
\end{enumerate}

Let's take a quick look at the resulting graph

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(sna)}
\KeywordTok{gplot}\NormalTok{(net_sim)}
\end{Highlighting}
\end{Shaded}

\includegraphics{06-network-simulation-and-viz_files/figure-latex/06-first-fig-1.pdf}

We can now start to see whether we got what we wanted! Before that, let's save the
network as a plain-text file so we can practice reading networks back in R!

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{write.csv}\NormalTok{(}
  \DataTypeTok{x         =} \KeywordTok{as.edgelist}\NormalTok{(net_sim),}
  \DataTypeTok{file      =} \StringTok{"06-edgelist.csv"}\NormalTok{,}
  \DataTypeTok{row.names =} \OtherTok{FALSE}
\NormalTok{  )}

\KeywordTok{write.csv}\NormalTok{(}
  \DataTypeTok{x         =} \KeywordTok{as.data.frame}\NormalTok{(net_sim, }\DataTypeTok{unit =} \StringTok{"vertices"}\NormalTok{),}
  \DataTypeTok{file      =} \StringTok{"06-nodes.csv"}\NormalTok{,}
  \DataTypeTok{row.names =} \OtherTok{FALSE}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\hypertarget{reading-a-network}{%
\section{Reading a network}\label{reading-a-network}}

The first step to analyzing network data is to read it in. Many times you'll find
data in the form of an adjacency matrix. Other times, data will come in the form
of an edgelist. Another common format is the adjacency list, which is a compressed
version of an edgelist. Let's see how the formats look like for the following
network:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{example_graph <-}\StringTok{ }\KeywordTok{matrix}\NormalTok{(0L, }\DecValTok{4}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DataTypeTok{dimnames =} \KeywordTok{list}\NormalTok{(letters[}\DecValTok{1}\OperatorTok{:}\DecValTok{4}\NormalTok{], letters[}\DecValTok{1}\OperatorTok{:}\DecValTok{4}\NormalTok{]))}
\NormalTok{example_graph[}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{7}\NormalTok{)] <-}\StringTok{ }\NormalTok{1L}
\NormalTok{example_graph[}\StringTok{"c"}\NormalTok{, }\StringTok{"d"}\NormalTok{] <-}\StringTok{ }\NormalTok{1L}
\NormalTok{example_graph[}\StringTok{"d"}\NormalTok{, }\StringTok{"c"}\NormalTok{] <-}\StringTok{ }\NormalTok{1L}
\NormalTok{example_graph <-}\StringTok{ }\KeywordTok{as.network}\NormalTok{(example_graph)}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{1231}\NormalTok{)}
\KeywordTok{gplot}\NormalTok{(example_graph, }\DataTypeTok{label =}\NormalTok{ letters[}\DecValTok{1}\OperatorTok{:}\DecValTok{4}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\includegraphics{06-network-simulation-and-viz_files/figure-latex/06-fake-graph-read-1.pdf}

\begin{itemize}
\tightlist
\item
  \textbf{Adjacency matrix} a matrix of size \(n\) by \(n\) where the \(ij\)-th entry represents
  the tie between \(i\) and \(j\). In a directed network, we say \(i\) connects to \(j\),
  so the \(i\)-th row shows the ties \(i\) sends to the rest of the network. Likewise,
  in a directed graph, the \(j\)-th column shows the ties sent to \(j\). For undirected
  graphs, the adjacency matrix is usually upper or lower diagonal. The adjacency
  matrix of an undirected graph is symmetric, so we don't need to report the same
  information twice. For example:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{as.matrix}\NormalTok{(example_graph)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   a b c d
## a 0 0 0 0
## b 1 0 0 0
## c 0 1 0 1
## d 0 0 1 0
\end{verbatim}

\begin{itemize}
\tightlist
\item
  \textbf{Edge list} a matrix of size \(|E|\) by \(2\), where \(|E|\) is the number of edges.
  Each entry represents a tie in the graph.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{as.edgelist}\NormalTok{(example_graph)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1] [,2]
## [1,]    2    1
## [2,]    3    2
## [3,]    3    4
## [4,]    4    3
## attr(,"n")
## [1] 4
## attr(,"vnames")
## [1] "a" "b" "c" "d"
## attr(,"directed")
## [1] TRUE
## attr(,"bipartite")
## [1] FALSE
## attr(,"loops")
## [1] FALSE
## attr(,"class")
## [1] "matrix_edgelist" "edgelist"        "matrix"          "array"
\end{verbatim}

The command turns the \texttt{network} object into a matrix with a set of attributes
(which are also printed.)

\begin{itemize}
\tightlist
\item
  \textbf{Adjacency list} This data format uses less space than edgelists as ties are
  grouped by ego (source.)
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{igraph}\OperatorTok{::}\KeywordTok{as_adj_list}\NormalTok{(intergraph}\OperatorTok{::}\KeywordTok{asIgraph}\NormalTok{(example_graph)) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [[1]]
## + 1/4 vertex, from c444783:
## [1] 2
## 
## [[2]]
## + 2/4 vertices, from c444783:
## [1] 1 3
## 
## [[3]]
## + 3/4 vertices, from c444783:
## [1] 2 4 4
## 
## [[4]]
## + 2/4 vertices, from c444783:
## [1] 3 3
\end{verbatim}

The function \texttt{igraph::as\_adj\_list} turns the igraph object into a list of
type adjacency list. In plain text it would look something like this:

\begin{verbatim}
2 
1 3 
2 4 4 
3 3 
\end{verbatim}

Here we will deal with an edgelist that includes node information.
In my opinion, this is one of the best ways to share network data. Let's read
the data into R using the function \texttt{read.csv}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{edges <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"06-edgelist.csv"}\NormalTok{)}
\NormalTok{nodes <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"06-nodes.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

We now have two objects of class \texttt{data.frame}, edges and nodes. Let's inspect
them using the \texttt{head} function:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{head}\NormalTok{(edges)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   V1  V2
## 1  2   7
## 2  2  41
## 3  3   5
## 4  3  16
## 5  4 138
## 6  5   9
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{head}\NormalTok{(nodes)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   vertex.names      race age
## 1            1 non-white  10
## 2            2     white  10
## 3            3     white  17
## 4            4 non-white  14
## 5            5 non-white  17
## 6            6 non-white  14
\end{verbatim}

It is always important to look at the data before creating the network. Most common
errors happen before reading the data in and could go undetected in many cases.
A few examples:

\begin{itemize}
\item
  Headers in the file could be treated as data, or the files may not
  have headers.
\item
  Ego/alter columns may show in the wrong order. Both the \texttt{igraph} and \texttt{network}
  packages take the first and second columns of edgelists as ego and alter.
\item
  Isolates, which wouldn't show in the edgelist, may be missing from the node
  information set. This is one of the most common errors.
\item
  Nodes showing in the edgelist may be missing from the nodelist.
\end{itemize}

Both \texttt{igraph} and network have functions to read edgelist with a corresponding
nodelist; the functions \texttt{graph\_from\_data\_frame} and \texttt{as.nework}, respectively. Although
, for both cases, you can avoid using a nodelist, it is highly recommended as then
you will (a) make sure that isolates are included and (b) become aware of possible
problems in the data. A frequent error in \texttt{graph\_from\_data\_frame} is nodes present
in the edgelist but not in the set of nodes.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{net_ig <-}\StringTok{ }\NormalTok{igraph}\OperatorTok{::}\KeywordTok{graph_from_data_frame}\NormalTok{(}
  \DataTypeTok{d        =}\NormalTok{ edges,}
  \DataTypeTok{directed =} \OtherTok{TRUE}\NormalTok{,}
  \DataTypeTok{vertices =}\NormalTok{ nodes}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Using \texttt{as.network} from the \texttt{network} package:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{net_net <-}\StringTok{ }\NormalTok{network}\OperatorTok{::}\KeywordTok{as.network}\NormalTok{(}
  \DataTypeTok{x        =}\NormalTok{ edges,}
  \DataTypeTok{directed =} \OtherTok{TRUE}\NormalTok{,}
  \DataTypeTok{vertices =}\NormalTok{ nodes}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

As you can see, both syntaxes are very similar. The main point here is that the
more explicit we are, the better. Nevertheless, R can be brilliant; being
\emph{shy}, i.e., not throwing warnings or errors, is not uncommon. In the next
section, we will finally start visualizing the data.

\hypertarget{visualizing-the-network}{%
\section{Visualizing the network}\label{visualizing-the-network}}

We will focus on three different attributes that we can use for this visualization:
Node size, node shape, and node color. While there are no particular rules, some
ideas you can follow are:

\begin{itemize}
\item
  \textbf{Node size} Use it to describe a continuous measurement. This feature is often
  used to highlight important nodes, e.g., using one of the many available degree measurements.
\item
  \textbf{Node shape} Shapes can be used to represent categorical values. A good figure
  will not feature too many of them; less than four would make sense.
\item
  \textbf{Node color} Like shapes, colors can be used to represent categorical values, so the
  same idea applies. Furthermore, it is not crazy to use both shape and color to
  represent the same feature.
\end{itemize}

Notice that we have not talked about layout algorithms. The R packages to build
graphs usually have internal rules to decide what algorithm to use. We will discuss that
later on. Let's start by size.

\hypertarget{vertex-size}{%
\subsection{Vertex size}\label{vertex-size}}

Finding the right scale can be somewhat difficult. We
will draw the graph four times to see what size would be the best:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Sized by indegree}
\NormalTok{net_sim }\OperatorTok{%v%}\StringTok{ "indeg"}\NormalTok{ <-}\StringTok{ }\NormalTok{sna}\OperatorTok{::}\KeywordTok{degree}\NormalTok{(net_sim, }\DataTypeTok{cmode =} \StringTok{"indegree"}\NormalTok{)}

\CommentTok{# Changing device config}
\NormalTok{op <-}\StringTok{ }\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow =} \KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{), }\DataTypeTok{mai =} \KeywordTok{c}\NormalTok{(.}\DecValTok{1}\NormalTok{, }\FloatTok{.1}\NormalTok{, }\FloatTok{.1}\NormalTok{, }\FloatTok{.1}\NormalTok{))}

\CommentTok{# Plotting}
\NormalTok{glayout <-}\StringTok{ }\KeywordTok{gplot}\NormalTok{(net_sim, }\DataTypeTok{vertex.cex =}\NormalTok{ (net_sim }\OperatorTok{%v%}\StringTok{ "indeg"}\NormalTok{) }\OperatorTok{*}\StringTok{ }\DecValTok{2}\NormalTok{)}
\KeywordTok{gplot}\NormalTok{(net_sim, }\DataTypeTok{vertex.cex =}\NormalTok{ net_sim }\OperatorTok{%v%}\StringTok{ "indeg"}\NormalTok{, }\DataTypeTok{coord =}\NormalTok{ glayout)}
\KeywordTok{gplot}\NormalTok{(net_sim, }\DataTypeTok{vertex.cex =}\NormalTok{ (net_sim }\OperatorTok{%v%}\StringTok{ "indeg"}\NormalTok{)}\OperatorTok{/}\DecValTok{2}\NormalTok{, }\DataTypeTok{coord =}\NormalTok{ glayout)}
\KeywordTok{gplot}\NormalTok{(net_sim, }\DataTypeTok{vertex.cex =}\NormalTok{ (net_sim }\OperatorTok{%v%}\StringTok{ "indeg"}\NormalTok{)}\OperatorTok{/}\DecValTok{10}\NormalTok{, }\DataTypeTok{coord =}\NormalTok{ glayout)}
\end{Highlighting}
\end{Shaded}

\includegraphics{06-network-simulation-and-viz_files/figure-latex/06-size-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Restoring device config}
\KeywordTok{par}\NormalTok{(op)}
\end{Highlighting}
\end{Shaded}

Line-by-line we did the following:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \texttt{net\_sim\ \%v\%\ "indeg"\ \textless{}-\ degree(net\_sim,\ cmode\ =\ "indegree")} Created a new
  vertex attribute called indegree and assigned it to the network object.
  The indegree is calculated using the \texttt{degree} function from the \texttt{sna}
  package. Since \texttt{igraph} also has a \texttt{degree} function, we are making sure
  that R uses \texttt{sna}'s and not \texttt{igraph}'s. The \texttt{package::function} notation
  is useful for these cases.
\item
  \texttt{op\ \textless{}-\ par(mfrow\ =\ c(2,\ 2),\ mai\ =\ c(.1,\ .1,\ .1,\ .1))} This changes the
  graphical device information to (a) \texttt{mfrow\ =\ c(2,2)} have a 2x2 grid by row,
  meaning that new figures will be added left to right and then top to bottom,
  and (b) set the margins in the figure to be 0.1 inches in all four sizes.
\item
  \texttt{glayout\ \textless{}-\ gplot(net\_sim,\ vertex.cex\ =\ (net\_sim\ \%v\%\ "indeg")\ *\ 2)} generating
  the plot \textbf{and} recording the layout. The \texttt{gplot} function returns a matrix of
  size \texttt{\#\ vertices} by 2 with the positions of the vertices. We are also passing the
  \texttt{vertex.cex} argument, which we use to specify the size of each vertex. In our
  case, we decided to size the vertices proportional to their indegree \emph{times two}.
\item
  \texttt{gplot(net\_sim,\ vertex.cex\ =\ net\_sim\ \%v\%\ "indeg",\ coord\ =\ glayout)}, again,
  we are drawing the graph using the coordinates of the previous draw, but now
  the vertices are half the size of the original figure.
\end{enumerate}

The other two calls are similar to four. If we used igraph, setting the
size can be more accessible thanks to the netdiffuseR R package. Let's start by converting
our network to an igraph object with the R package \texttt{intergraph}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(intergraph)}
\KeywordTok{library}\NormalTok{(igraph)}

\CommentTok{# Converting the network object to an igraph object}
\NormalTok{net_sim_i <-}\StringTok{ }\KeywordTok{asIgraph}\NormalTok{(net_sim)}

\CommentTok{# Plotting with igraph}
\KeywordTok{plot}\NormalTok{(}
\NormalTok{  net_sim_i,}
  \DataTypeTok{vertex.size =}\NormalTok{ netdiffuseR}\OperatorTok{::}\KeywordTok{rescale_vertex_igraph}\NormalTok{(}
    \DataTypeTok{vertex.size =} \KeywordTok{V}\NormalTok{(net_sim_i)}\OperatorTok{$}\NormalTok{indeg,}
    \DataTypeTok{minmax.relative.size =} \KeywordTok{c}\NormalTok{(.}\DecValTok{01}\NormalTok{, }\FloatTok{.1}\NormalTok{)}
\NormalTok{  ), }
  \DataTypeTok{layout       =}\NormalTok{ glayout,}
  \DataTypeTok{vertex.label =} \OtherTok{NA}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{06-network-simulation-and-viz_files/figure-latex/06-size-netdiffuseR-1.pdf}

We could also have tried netplot, which should make things easier and make a better use of the space:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(netplot)}
\KeywordTok{nplot}\NormalTok{(}
\NormalTok{  net_sim, }\DataTypeTok{layout =}\NormalTok{ glayout,}
  \DataTypeTok{vertex.color =} \StringTok{"tomato"}\NormalTok{,}
  \DataTypeTok{vertex.frame.color =} \StringTok{"darkred"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\includegraphics{06-network-simulation-and-viz_files/figure-latex/06-netplot1-1.pdf}

With a good idea for size, we can now start looking into vertex color.

\hypertarget{vertex-color}{%
\subsection{Vertex color}\label{vertex-color}}

For the color, we will use vertex age. Although age is, by definition, continuous,
we only have three values for age. Because of this, we can treat age as categorical.
Instead of using \texttt{nplot} we will go ahead with \texttt{nplot\_base}. As of this version of
the book, the \texttt{netplot} package does not have an easy way to add legends with the
core function, \texttt{nplot}; therefore, we use \texttt{nplot\_base} which is compatible with
the R function \texttt{legend}, as we will now see:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Specifying colors for each vertex}
\NormalTok{vcolors_palette <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"10"}\NormalTok{ =}\StringTok{ "gray"}\NormalTok{, }\StringTok{"14"}\NormalTok{ =}\StringTok{ "tomato"}\NormalTok{, }\StringTok{"17"}\NormalTok{ =}\StringTok{ "steelblue"}\NormalTok{)}
\NormalTok{vcolors <-}\StringTok{ }\NormalTok{vcolors_palette[}\KeywordTok{as.character}\NormalTok{(net_sim }\OperatorTok{%v%}\StringTok{ "age"}\NormalTok{)]}
\NormalTok{net_sim }\OperatorTok{%v%}\StringTok{ "color"}\NormalTok{ <-}\StringTok{ }\NormalTok{vcolors}

\CommentTok{# Plotting}
\KeywordTok{nplot_base}\NormalTok{(}
\NormalTok{  net_ig,}
  \DataTypeTok{layout =}\NormalTok{ glayout,}
  \DataTypeTok{vertex.color =}\NormalTok{ net_sim }\OperatorTok{%v%}\StringTok{ "color"}\NormalTok{,}
\NormalTok{  )}

\CommentTok{# Color legend}
\KeywordTok{legend}\NormalTok{(}
  \StringTok{"bottomright"}\NormalTok{,}
  \DataTypeTok{legend =} \KeywordTok{names}\NormalTok{(vcolors_palette),}
  \DataTypeTok{fill   =}\NormalTok{ vcolors_palette, }
  \DataTypeTok{bty    =} \StringTok{"n"}\NormalTok{,}
  \DataTypeTok{title  =} \StringTok{"Age"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\includegraphics{06-network-simulation-and-viz_files/figure-latex/06-network-color-1.pdf}

Line by line, this is what we just did:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \texttt{vcolors\ \textless{}-\ c("10"\ =\ "gray",\ "14"\ =\ "tomato",\ "17"\ =\ "steelblue")} we created
  a character vector with three elements, \texttt{"gray"}, \texttt{"tomato"}, and \texttt{"blue"}.
  Furthermore, the vector has names assigned to it, \texttt{"10"}, \texttt{"14"}, and \texttt{"17"}--
  the ages we have in the network--so that we can access its
  elements by indexing by name, e.g., if we type \texttt{vcolors{[}"10"{]}} R returns
  the value \texttt{"gray"}.
\item
  \texttt{vcolors\ \textless{}-\ vcolors{[}as.character(net\_sim\ \%v\%\ "age"){]}} there are several things
  going on in this line. First, we extract the attribute ``age'' from the network
  using the \texttt{\%v\%} operator. We then transform the resulting vector from integer type
  to a character type with the function \texttt{as.character}. Finally, using the resulting
  \textbf{character vector} with values \texttt{"10",\ "14",\ "17",\ ...}, we retrieve values
  from \texttt{vcolors} name-indexing. The resulting vector is of length equal to
  the vertex count in the network.
\item
  \texttt{net\_sim\ \%v\%\ "color"\ \textless{}-\ vcolors} creates a
  new vertex attribute, \texttt{color}. The assigned value is the result from subsetting
  \texttt{vcolors} by the ages of each vertex.
\item
  \texttt{nplot\_base(...} finally draws the network. We pass the previously computed
  vertex coordinates and vertex colors with the new attribute \texttt{color}.
\item
  \texttt{legend(...)} Let's see one parameter at a time:

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \item
    \texttt{"bottomright"} tells the overall position of the legend
  \item
    \texttt{legend\ =\ names(vcolors)} passes the actual legend (text); in our case
    the ages of individuals.
  \item
    \texttt{fill\ \ \ =\ vcolors} passes the colors associated with the text.
  \item
    \texttt{bty\ \ \ \ =\ "n"} suppresses wrapping the legend within a box.
  \item
    \texttt{title\ \ =\ "Age"} sets the title to be ``Age''.
  \end{enumerate}
\end{enumerate}

\hypertarget{vertex-shape}{%
\subsection{Vertex shape}\label{vertex-shape}}

For the color, we will use vertex age. Although age is, by definition, continuous,
we only have three values for age. Because of this, we can treat age as categorical.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Specifying the shapes for each vertex}
\NormalTok{vshape_list <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"white"}\NormalTok{ =}\StringTok{ }\DecValTok{15}\NormalTok{, }\StringTok{"non-white"}\NormalTok{ =}\StringTok{ }\DecValTok{3}\NormalTok{)}
\NormalTok{vshape      <-}\StringTok{ }\NormalTok{vshape_list[}\KeywordTok{as.character}\NormalTok{(net_sim }\OperatorTok{%v%}\StringTok{ "race"}\NormalTok{)]}
\NormalTok{net_sim }\OperatorTok{%v%}\StringTok{ "shape"}\NormalTok{ <-}\StringTok{ }\NormalTok{vshape}

\CommentTok{# Plotting}
\KeywordTok{nplot_base}\NormalTok{(}
\NormalTok{  net_ig,}
  \DataTypeTok{layout =}\NormalTok{ glayout,}
  \DataTypeTok{vertex.color =}\NormalTok{ net_sim }\OperatorTok{%v%}\StringTok{ "color"}\NormalTok{,}
  \DataTypeTok{vertex.nsides =}\NormalTok{ net_sim }\OperatorTok{%v%}\StringTok{ "shape"}
\NormalTok{  )}

\CommentTok{# Color legend}
\KeywordTok{legend}\NormalTok{(}
  \StringTok{"bottomright"}\NormalTok{,}
  \DataTypeTok{legend =} \KeywordTok{names}\NormalTok{(vcolors_palette),}
  \DataTypeTok{fill   =}\NormalTok{ vcolors_palette, }
  \DataTypeTok{bty    =} \StringTok{"n"}\NormalTok{,}
  \DataTypeTok{title  =} \StringTok{"Age"}
\NormalTok{  )}

\CommentTok{# Shape legend}
\KeywordTok{legend}\NormalTok{(}
  \StringTok{"bottomleft"}\NormalTok{,}
  \DataTypeTok{legend =} \KeywordTok{names}\NormalTok{(vshape_list),}
  \DataTypeTok{pch    =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{), }
  \DataTypeTok{bty    =} \StringTok{"n"}\NormalTok{,}
  \DataTypeTok{title  =} \StringTok{"Race"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\includegraphics{06-network-simulation-and-viz_files/figure-latex/06-network-shape-1.pdf}

Let's now compare the figure to our original ERGM:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Low density (\texttt{edges})} Without low density, the figure would be
  a hairball.
\item
  \textbf{Race homophily (\texttt{nodematch("race")})} Although not surprisingly evident,
  nodes tend to form small clusters by shape, which, in our model, represents
  race.
\item
  \textbf{Structural balance (\texttt{ttriad})} A force, in this case, opposite to low
  density, higher prevalence of transitive triads makes individuals cluster.
\item
  \textbf{Age homophily (\texttt{absdiff("age")})} This is the most prominent feature of
  the graph. In it, nodes are clustered by age.
\end{enumerate}

Of the four features, \textbf{age homophily} is the one that stands out. Why is this
tha case? If we look again at the parameters used in the ERGM and how these
interact with vertices' attributes, we will find the answer:

\begin{itemize}
\item
  The log-odds of a new race-homophilic tie are \(1\times\theta_{\mbox{race-homophily}} = 0.5\).
\item
  But, the log-odd of an age heterophilic tie between, say, 14 and 17 year
  olds is \(|17-14|\theta_{\mbox{age-homophily}} = 3\times -0.5 = -1.5\).
\item
  Therefore, the effect of heterophily (which is just the opposite of homophily)
  is significantly larger, actually three times in this case, than the race-homophily
  effect.
\end{itemize}

This observation becomes clear if we run another simulation with the same seed, but
adjusting for the maximum size the effect of age-homophily can take. A
quick-n-dirty way to achieve this is to re-run the simulation with the \texttt{nodematch}
term instead of the \texttt{absdiff} term. This way, we (a) explicitly operationalize
the term as homophily (before it was heterophily,) and (b) have both homophily
effects have the same influence in the model:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{net_sim2 <-}\StringTok{ }\KeywordTok{simulate}\NormalTok{(}
\NormalTok{    net }\OperatorTok{~}\StringTok{ }\NormalTok{edges }\OperatorTok{+}
\StringTok{    }\KeywordTok{nodematch}\NormalTok{(}\StringTok{"race"}\NormalTok{) }\OperatorTok{+}
\StringTok{    }\NormalTok{ttriad }\OperatorTok{+}
\StringTok{    }\KeywordTok{nodematch}\NormalTok{(}\StringTok{"age"}\NormalTok{),}
    \DataTypeTok{coef =} \KeywordTok{c}\NormalTok{(}\OperatorTok{-}\DecValTok{5}\NormalTok{, }\FloatTok{.5}\NormalTok{, }\FloatTok{.25}\NormalTok{, }\FloatTok{.5}\NormalTok{) }\CommentTok{# This line changed}
\NormalTok{    )}
\end{Highlighting}
\end{Shaded}

Re-doing the plot. From the previous graph-drawing, only the graph structure
changed. The vertex attributes are the same so we can go ahead and re-use them.
Like I mentioned earlier, the \texttt{nplot\_base} function currently supports \texttt{igraph}
objects, so we will use \texttt{intergraph::asIgraph} to make it work:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Plotting}
\KeywordTok{nplot_base}\NormalTok{(}
  \KeywordTok{asIgraph}\NormalTok{(net_sim2),}
  \CommentTok{# We comment this out to allow for a new layout}
  \CommentTok{# layout = glayout, }
  \DataTypeTok{vertex.color =}\NormalTok{ net_sim }\OperatorTok{%v%}\StringTok{ "color"}\NormalTok{,}
  \DataTypeTok{vertex.nsides =}\NormalTok{ net_sim }\OperatorTok{%v%}\StringTok{ "shape"}
\NormalTok{  )}

\CommentTok{# Color legend}
\KeywordTok{legend}\NormalTok{(}
  \StringTok{"bottomright"}\NormalTok{,}
  \DataTypeTok{legend =} \KeywordTok{names}\NormalTok{(vcolors_palette),}
  \DataTypeTok{fill   =}\NormalTok{ vcolors_palette, }
  \DataTypeTok{bty    =} \StringTok{"n"}\NormalTok{,}
  \DataTypeTok{title  =} \StringTok{"Age"}
\NormalTok{  )}

\CommentTok{# Shape legend}
\KeywordTok{legend}\NormalTok{(}
  \StringTok{"bottomleft"}\NormalTok{,}
  \DataTypeTok{legend =} \KeywordTok{names}\NormalTok{(vshape_list),}
  \DataTypeTok{pch    =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{), }
  \DataTypeTok{bty    =} \StringTok{"n"}\NormalTok{,}
  \DataTypeTok{title  =} \StringTok{"Race"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\includegraphics{06-network-simulation-and-viz_files/figure-latex/06-adjust-homophily-plot-1.pdf}

As expected, there is no longer a dominant effect in homophily. One important
thing we can learn from this final example is that phenomena will not always
show themselves in graph visualization. Careful analysis in complex networks
is a must.

\hypertarget{hypothesis-testing-in-networks}{%
\chapter{Hypothesis testing in networks}\label{hypothesis-testing-in-networks}}

Overall, there are many ways in which we can see hypothesis testing within
the networks context:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Comparing two or more networks}, e.g., we want to see if the density of
  two networks are \emph{equal}.
\item
  \textbf{Prevalence of a motif/pattern}, e.g., check whether the observed number
  of transitive triads is different from that expected as of by chance.
\item
  \textbf{Multivariate using ERGMs}, e.g., jointly test whether homophily and
  two stars are the motifs that drive network structure.
\end{enumerate}

The latter we already review in the ERGM chapter. In this part, we will look
at types one and two; both using non-parametric methods.

\hypertarget{comparing-networks}{%
\section{Comparing networks}\label{comparing-networks}}

Imagine that we have two graphs, \((G_1,G_2) \in \mathcal{G}\), and we would like
to assess whether a given statistic \(s(\cdot)\), e.g., density, is equal in both of them.
Formally, we would like to asses whether \(H_0: s(G_1) - s(G_2) = k\) vs
\(H_a: s(G_1) - s(G_2) \neq k\).

As usual, the true distribution of \(s(\cdot)\) is unknown, thus, one approach that
we could use is a non-parametric bootstrap test.

\hypertarget{network-bootstrap}{%
\subsection{Network bootstrap}\label{network-bootstrap}}

The non parametric bootstrap and jackknife methods for social networks were
introduced by (Snijders and Borgatti \protect\hyperlink{ref-Snijders1999}{1999}). The method itself is used to generate standard
errors for network level statistics. Both methods are implemented in the R
package \href{https://cran.r-project.org/package=netdiffuseR}{\texttt{netdiffuseR}}.

\hypertarget{when-the-statistic-is-normal}{%
\subsection{When the statistic is normal}\label{when-the-statistic-is-normal}}

When the we deal with things that are normally distributed, e.g., sample means
like density\footnote{Density is indeed a sample mean as we are, in principle
  computing the average of a sequence of Bernoulli variables. Formally:
  \(\mbox{density}(G) = \frac{1}{n(n-1)}\sum_{ij}A_{ij}\).},
we can make use of the Student's distribution for making inference. In particular,
we can use Bootstrap/Jackknife to approximate the standard errors of the statistic
for each network:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Since \(s(G_i)\sim \mbox{N}(\mu_i,\sigma_i^2/m_i)\) for \(i\in\{1,2\}\), in the case
  of the density, \(m_i = n_i * (n_i - 1)\). The statistic is then:

  \[
  s(G_1) - s(G_0)\sim \mbox{N}(\mu_1-\mu_0, \sigma_1^2/m_1 + \sigma_1^2/m_2)
  \]

  Thus

  \[
  \frac{s(G_1) - s(G_0) - \mu_1 + \mu_2}{\sqrt{\sigma_1^2/{m_1} + \sigma_1^2/{m_2}}} \sim t_{m_1 + m_2 - 2}
  \]
  But, if we are testing \(H_0: \mu_1 - \mu_2 = k\), then, under the null

  \[
  \frac{s(G_1) - s(G_0) - k}{\sqrt{\sigma_1^2/{m_1} + \sigma_1^2/{m_2}}} \sim t_{m_1 + m_2 - 2}
  \]
  Where We now proceede to approximate the variances.
\item
  Using the \emph{plugin principle} (Efron and Tibshirani \protect\hyperlink{ref-Efron1994}{1994}), we can approximate the variances
  using Bootstrap/Jackknife, i.e., compute \(\hat\sigma_1^2\approx\sigma_1^2/m_1\) and
  \(\hat\sigma_2^2\approx\sigma_2^2/m_2\). Using netdiffuseR

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(netdiffuseR)}

\CommentTok{# Obtain a 100 replicates}
\NormalTok{sg1 <-}\StringTok{ }\KeywordTok{bootnet}\NormalTok{(g1, }\ControlFlowTok{function}\NormalTok{(i, ...) }\KeywordTok{sum}\NormalTok{(i)}\OperatorTok{/}\NormalTok{(}\KeywordTok{nnodes}\NormalTok{(i) }\OperatorTok{*}\StringTok{ }\NormalTok{(}\KeywordTok{nnodes}\NormalTok{(i) }\OperatorTok{-}\StringTok{ }\DecValTok{1}\NormalTok{)), }\DataTypeTok{R =} \DecValTok{100}\NormalTok{)}
\NormalTok{sg2 <-}\StringTok{ }\KeywordTok{bootnet}\NormalTok{(g2, }\ControlFlowTok{function}\NormalTok{(i, ...) }\KeywordTok{sum}\NormalTok{(i)}\OperatorTok{/}\NormalTok{(}\KeywordTok{nnodes}\NormalTok{(i) }\OperatorTok{*}\StringTok{ }\NormalTok{(}\KeywordTok{nnodes}\NormalTok{(i) }\OperatorTok{-}\StringTok{ }\DecValTok{1}\NormalTok{)), }\DataTypeTok{R =} \DecValTok{100}\NormalTok{)}

\CommentTok{# Retrieving the variances}
\NormalTok{hat_sigma1 <-}\StringTok{ }\NormalTok{sg1}\OperatorTok{$}\NormalTok{var_t}
\NormalTok{hat_sigma2 <-}\StringTok{ }\NormalTok{sg2}\OperatorTok{$}\NormalTok{var_t}

\CommentTok{# And the actual values}
\NormalTok{sg1 <-}\StringTok{ }\NormalTok{sg1}\OperatorTok{$}\NormalTok{t0}
\NormalTok{sg2 <-}\StringTok{ }\NormalTok{sg2}\OperatorTok{$}\NormalTok{t0}
\end{Highlighting}
\end{Shaded}
\item
  With the approximates in hand, we can then use the the ``t-test table'' to
  retrieve the corresponding value, in R:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Building the statistic}
\NormalTok{k <-}\StringTok{ }\DecValTok{0} \CommentTok{# For equal variances}
\NormalTok{tstat <-}\StringTok{ }\NormalTok{(sg1 }\OperatorTok{-}\StringTok{ }\NormalTok{sg2 }\OperatorTok{-}\StringTok{ }\NormalTok{k)}\OperatorTok{/}\NormalTok{(}\KeywordTok{sqrt}\NormalTok{(hat_sigma1 }\OperatorTok{+}\StringTok{ }\NormalTok{hat_sigma2))}

\CommentTok{# Computing the pvalue}
\NormalTok{m1 <-}\StringTok{ }\KeywordTok{nnodes}\NormalTok{(g1)}\OperatorTok{*}\NormalTok{(}\KeywordTok{nnodes}\NormalTok{(g1) }\OperatorTok{-}\StringTok{ }\DecValTok{1}\NormalTok{)}
\NormalTok{m2 <-}\StringTok{ }\KeywordTok{nnodes}\NormalTok{(g2)}\OperatorTok{*}\NormalTok{(}\KeywordTok{nnodes}\NormalTok{(g2) }\OperatorTok{-}\StringTok{ }\DecValTok{1}\NormalTok{)}
\KeywordTok{pt}\NormalTok{(tstat, }\DataTypeTok{df =}\NormalTok{ m1 }\OperatorTok{+}\StringTok{ }\NormalTok{m2 }\OperatorTok{-}\StringTok{ }\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}
\end{enumerate}

\hypertarget{when-the-statistic-is-not-normal}{%
\subsection{When the statistic is NOT normal}\label{when-the-statistic-is-not-normal}}

In the case that the statistic is not normally distributed, we cannot use the
t-statistic any longer. Nevertheless, the Bootstrap can come to help. While
in general it is better to use distributions of pivot statistics (see (Efron and Tibshirani \protect\hyperlink{ref-Efron1994}{1994})),
we can still leverage the power of this method to make inferences. For this
example, \(s(\cdot)\) will be the range of the threshold in a diffusion graph.

As before, imagine that we are dealing with an statistic \(s(\cdot)\) for two
different networks, and we would like to asses whether we can reject \(H_0\)
or \href{https://www.thoughtco.com/fail-to-reject-in-a-hypothesis-test-3126424}{fail to reject} it.
The procedure is very similar:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  One approach that we can test is whether \(k \in \mbox{ConfInt}(s(G_1) - s(G_2))\).
  Building confidence intervals with bootstrap could be more intuitive.
\item
  Like before, we use bootstrap to generate a distribution of \(s(G_1)\) and
  \(s(G_2)\), in R:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Obtain a 1000 replicates}
\NormalTok{sg1 <-}\StringTok{ }\KeywordTok{bootnet}\NormalTok{(g1, }\ControlFlowTok{function}\NormalTok{(i, ...) }\KeywordTok{range}\NormalTok{(}\KeywordTok{threshold}\NormalTok{(i)), }\DataTypeTok{R =} \DecValTok{1000}\NormalTok{)}
\NormalTok{sg2 <-}\StringTok{ }\KeywordTok{bootnet}\NormalTok{(g2, }\ControlFlowTok{function}\NormalTok{(i, ...) }\KeywordTok{range}\NormalTok{(}\KeywordTok{threshold}\NormalTok{(i)), }\DataTypeTok{R =} \DecValTok{1000}\NormalTok{)}

\CommentTok{# Retrieving the distributions}
\NormalTok{sg1 <-}\StringTok{ }\NormalTok{sg1}\OperatorTok{$}\NormalTok{boot}\OperatorTok{$}\NormalTok{t}
\NormalTok{sg2 <-}\StringTok{ }\NormalTok{sg2}\OperatorTok{$}\NormalTok{boot}\OperatorTok{$}\NormalTok{t}

\CommentTok{# Define the statistic}
\NormalTok{sdiff <-}\StringTok{ }\NormalTok{sg1 }\OperatorTok{-}\StringTok{ }\NormalTok{sg2}
\end{Highlighting}
\end{Shaded}
\item
  Once we have \texttt{sdiff}, we can proceed and compute the, for example, 95\%
  confidence interval, and evaluate whether \(k\) falls within. In R:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{diff_ci <-}\StringTok{ }\KeywordTok{quantile}\NormalTok{(sdiff, }\DataTypeTok{probs =} \KeywordTok{c}\NormalTok{(}\FloatTok{0.025}\NormalTok{, }\FloatTok{.975}\NormalTok{))}
\end{Highlighting}
\end{Shaded}
\end{enumerate}

This corresponds to what Efron and Tibshirani call ``percentile interval.''
This is easy to compute, but a better approach is using the ``BCa'' method,
``Bias Corrected and Accelerated.'' (TBD)

\hypertarget{examples}{%
\section{Examples}\label{examples}}

\hypertarget{average-of-node-level-stats}{%
\subsection{Average of node-level stats}\label{average-of-node-level-stats}}

Supposed that we would like to compare something like average indegree.
In particular, for both networks, \(G_1\) and \(G_2\), we compute the average
indegree per node:

\[
s(G_1) = \mbox{AvgIndeg}(G_1) = \frac{1}{n}\sum_{i}\sum_{j\neq i}A^1_{ji}
\]

\noindent where \(A^1_{ji}\) equals one if vertex \(j\) sends a tie to \(i\). In this
case, since we are looking at an average, we have that
\(\mbox{AvgIndeg}(G_1) \sim N(\mu_1, \sigma^2_1/n)\). Thus, taking advantage of
the normality of the statistic, we can build a test statistic as follows:

\[
\frac{s(G_1) - s(G_2) - k}{\sqrt{\hat\sigma_{1}^2 + \hat\sigma_{2}^2}} \sim t_{n_1 + n_2 - 2}
\]
Where \(\hat\sigma_i\) is the bootstrap standard error, and \(k = 0\) when we are testing
equality. This distributes \(t\) with
\(n_1+n_2-2\) degrees of freedom. As a difference from the previous example using
density, the degrees of freedom for this test are less as, instead of having an
average across all entries of the adjacency matrix, we have an average across all
vertices.

\hypertarget{network-diffussion-with-netdiffuser}{%
\chapter{\texorpdfstring{Network diffussion with \texttt{netdiffuseR}}{Network diffussion with netdiffuseR}}\label{network-diffussion-with-netdiffuser}}

This chapter mainly was based on the 2018 and 2019 tutorials of netdiffuseR
at the Sunbelt conference. The source code of the tutorials, taught by \href{https://keck.usc.edu/faculty-search/thomas-william-valente/}{Thomas W. Valente}
and \href{https://ggvy.cl}{George G. Vega Yon} (author of this book), is available \href{https://github.com/USCCANA/netdiffuser-sunbelt2018/tree/sunbelt2019}{here}.

\hypertarget{network-diffusion-of-innovation}{%
\section{Network diffusion of innovation}\label{network-diffusion-of-innovation}}

\hypertarget{diffusion-networks}{%
\subsection{Diffusion networks}\label{diffusion-networks}}

\begin{itemize}
\item
  Explains how new ideas and practices (innovations) spread within and between
  communities.
\item
  While a lot of factors have been shown to influence diffusion (Spatial,
  Economic, Cultural, Biological, etc.), Social Networks is a prominent one.
\item
  There are many components in the diffusion network model including network exposures, thresholds, infectiousness, susceptibility, hazard rates, diffusion rates (bass model), clustering (Moran's I), and so on.
\end{itemize}

\hypertarget{thresholds}{%
\subsection{Thresholds}\label{thresholds}}

\begin{itemize}
\item
  One of the canonical concepts is the network threshold. Network thresholds (Valente, 1995; 1996), \(\tau\), are defined as the required proportion or number of neighbors that lead you to adopt a particular behavior (innovation), \(a=1\). In (very) general terms

  \[
  a_i = \left\{\begin{array}{ll}
  1 &\mbox{if } \tau_i\leq E_i \\
  0 & \mbox{Otherwise}
  \end{array}\right. \qquad
  E_i \equiv \frac{\sum_{j\neq i}\mathbf{X}_{ij}a_j}{\sum_{j\neq i}\mathbf{X}_{ij}}
  \]

  Where \(E_i\) is i's exposure to the innovation and \(\mathbf{X}\) is the adjacency matrix (the network).
\item
  This can be generalized and extended to include covariates and other network weighting schemes (that's what \textbf{netdiffuseR} is all about).
\end{itemize}

\hypertarget{the-netdiffuser-r-package}{%
\section{The netdiffuseR R package}\label{the-netdiffuser-r-package}}

\hypertarget{overview}{%
\subsection{Overview}\label{overview}}

\textbf{netdiffuseR} is an R package that:

\begin{itemize}
\item
  Is designed for Visualizing, Analyzing, and Simulating network diffusion data (in general).
\item
  Depends on some pretty popular packages:

  \begin{itemize}
  \tightlist
  \item
    \emph{RcppArmadillo}: So it's fast,
  \item
    \emph{Matrix}: So it's big,
  \item
    \emph{statnet} and \emph{igraph}: So it's not from scratch
  \end{itemize}
\item
  Can handle big graphs, e.g., an adjacency matrix with more than 4 billion elements (PR for RcppArmadillo)
\item
  Already on CRAN with \textasciitilde{}6,000 downloads since its first version, Feb 2016,
\item
  A lot of features to make it easy to read network (dynamic) data, making it a companion of other net packages.
\end{itemize}

\hypertarget{datasets}{%
\subsection{Datasets}\label{datasets}}

\begin{itemize}
\item
  \textbf{netdiffuseR} has the three classic Diffusion Network Datasets:

  \begin{itemize}
  \tightlist
  \item
    \texttt{medInnovationsDiffNet} Doctors and the innovation of Tetracycline (1955).
  \item
    \texttt{brfarmersDiffNet} Brazilian farmers and the innovation of Hybrid Corn Seed (1966).
  \item
    \texttt{kfamilyDiffNet} Korean women and Family Planning methods (1973).
  \end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{brfarmersDiffNet}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Dynamic network of class -diffnet-
##  Name               : Brazilian Farmers
##  Behavior           : Adoption of Hybrid Corn Seeds
##  # of nodes         : 692 (1001, 1002, 1004, 1005, 1007, 1009, 1010, 1020, ...)
##  # of time periods  : 21 (1946 - 1966)
##  Type               : directed
##  Final prevalence   : 1.00
##  Static attributes  : village, idold, age, liveout, visits, contact, coo... (146)
##  Dynamic attributes : -
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{medInnovationsDiffNet}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Dynamic network of class -diffnet-
##  Name               : Medical Innovation
##  Behavior           : Adoption of Tetracycline
##  # of nodes         : 125 (1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, ...)
##  # of time periods  : 18 (1 - 18)
##  Type               : directed
##  Final prevalence   : 1.00
##  Static attributes  : city, detail, meet, coll, attend, proage, length, ... (58)
##  Dynamic attributes : -
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{kfamilyDiffNet}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Dynamic network of class -diffnet-
##  Name               : Korean Family Planning
##  Behavior           : Family Planning Methods
##  # of nodes         : 1047 (10002, 10003, 10005, 10007, 10010, 10011, 10012, 10014, ...)
##  # of time periods  : 11 (1 - 11)
##  Type               : directed
##  Final prevalence   : 1.00
##  Static attributes  : village, recno1, studno1, area1, id1, nmage1, nmag... (430)
##  Dynamic attributes : -
\end{verbatim}
\end{itemize}

\hypertarget{visualization-methods}{%
\subsection{Visualization methods}\label{visualization-methods}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{12315}\NormalTok{)}
\NormalTok{x <-}\StringTok{ }\KeywordTok{rdiffnet}\NormalTok{(}
  \DecValTok{400}\NormalTok{, }\DataTypeTok{t =} \DecValTok{6}\NormalTok{, }\DataTypeTok{rgraph.args =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{k=}\DecValTok{6}\NormalTok{, }\DataTypeTok{p=}\NormalTok{.}\DecValTok{3}\NormalTok{),}
  \DataTypeTok{seed.graph =} \StringTok{"small-world"}\NormalTok{,}
  \DataTypeTok{seed.nodes =} \StringTok{"central"}\NormalTok{, }\DataTypeTok{rewire =} \OtherTok{FALSE}\NormalTok{, }\DataTypeTok{threshold.dist =} \DecValTok{1}\OperatorTok{/}\DecValTok{4}
\NormalTok{  )}
\KeywordTok{plot}\NormalTok{(x)}
\end{Highlighting}
\end{Shaded}

\includegraphics{08-netdiffuser_files/figure-latex/viz-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot_diffnet}\NormalTok{(x)}
\end{Highlighting}
\end{Shaded}

\includegraphics{08-netdiffuser_files/figure-latex/viz-2.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot_diffnet2}\NormalTok{(x)}
\end{Highlighting}
\end{Shaded}

\includegraphics{08-netdiffuser_files/figure-latex/viz-3.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot_adopters}\NormalTok{(x)}
\end{Highlighting}
\end{Shaded}

\includegraphics{08-netdiffuser_files/figure-latex/viz-4.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot_threshold}\NormalTok{(x)}
\end{Highlighting}
\end{Shaded}

\includegraphics{08-netdiffuser_files/figure-latex/viz-5.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot_infectsuscep}\NormalTok{(x, }\DataTypeTok{K=}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning in plot_infectsuscep.list(graph$graph, graph$toa, t0, normalize, : When
## applying logscale some observations are missing.
\end{verbatim}

\includegraphics{08-netdiffuser_files/figure-latex/viz-6.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot_hazard}\NormalTok{(x)}
\end{Highlighting}
\end{Shaded}

\includegraphics{08-netdiffuser_files/figure-latex/viz-7.pdf}

\hypertarget{problems}{%
\subsection{Problems}\label{problems}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Using the diffnet object in \href{intro.rda}{\texttt{intro.rda}}, use the function \texttt{plot\_threshold} specifying
  shapes and colors according to the variables ItrustMyFriends and Age. Do you see any pattern?
\end{enumerate}

\hypertarget{simulation-of-diffusion-processes}{%
\section{Simulation of diffusion processes}\label{simulation-of-diffusion-processes}}

Before we start, a review of the concepts we will be using here

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Exposure: Proportion/number of neighbors that have adopted an innovation at each point in time.
\item
  Threshold: The proportion/number of your neighbors who had adopted at or one time period before ego (the focal individual) adopted.
\item
  Infectiousness: How much \(i\)'s adoption affects her alters.
\item
  Susceptibility: How much \(i\)'s alters' adoption affects her.
\item
  Structural equivalence: How similar is \(i\) to \(j\) in terms of position in the network.
\end{enumerate}

\hypertarget{simulating-diffusion-networks}{%
\subsection{Simulating diffusion networks}\label{simulating-diffusion-networks}}

We will simulate a diffusion network with the following parameters:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Will have 1,000 vertices,
\item
  Will span 20 time periods,
\item
  The initial adopters (seeds) will be selected at random,
\item
  Seeds will be a 10\% of the network,
\item
  The graph (network) will be small-world,
\item
  Will use the WS algorithm with \(p=.2\) (probability of rewiring).
\item
  Threshold levels will be uniformly distributed between {[}0.3, 0.7{]}
\end{enumerate}

To generate this diffusion network, we can use the \texttt{rdiffnet} function included in the package:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Setting the seed for the RNG}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{1213}\NormalTok{)}

\CommentTok{# Generating a random diffusion network}
\NormalTok{net <-}\StringTok{ }\KeywordTok{rdiffnet}\NormalTok{(}
  \DataTypeTok{n              =} \FloatTok{1e3}\NormalTok{,                         }\CommentTok{# 1.}
  \DataTypeTok{t              =} \DecValTok{20}\NormalTok{,                          }\CommentTok{# 2.}
  \DataTypeTok{seed.nodes     =} \StringTok{"random"}\NormalTok{,                    }\CommentTok{# 3.}
  \DataTypeTok{seed.p.adopt   =} \FloatTok{.1}\NormalTok{,                          }\CommentTok{# 4.}
  \DataTypeTok{seed.graph     =} \StringTok{"small-world"}\NormalTok{,               }\CommentTok{# 5.}
  \DataTypeTok{rgraph.args    =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{p=}\NormalTok{.}\DecValTok{2}\NormalTok{),                  }\CommentTok{# 6.}
  \DataTypeTok{threshold.dist =} \ControlFlowTok{function}\NormalTok{(x) }\KeywordTok{runif}\NormalTok{(}\DecValTok{1}\NormalTok{, }\FloatTok{.3}\NormalTok{, }\FloatTok{.7}\NormalTok{) }\CommentTok{# 7.}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\item
  The function \texttt{rdiffnet} generates random diffusion networks. Main features:

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \item
    Simulating random graph or using your own,
  \item
    Setting threshold levels per node,
  \item
    Network rewiring throughout the simulation, and
  \item
    Setting the seed nodes.
  \end{enumerate}
\item
  The simulation algorithm is as follows:

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \item
    If required, a baseline graph is created,
  \item
    Set of initial adopters and threshold distribution are established,
  \item
    The set of t networks is created (if required), and
  \item
    Simulation starts at t=2, assigning adopters based on exposures and thresholds:

    \begin{enumerate}
    \def\labelenumii{\alph{enumii}.}
    \item
      For each \(i \in N\), if its exposure at \(t-1\) is greater than its threshold, then
      adopts, otherwise, continue without change.
    \item
      next \(i\)
    \end{enumerate}
  \end{enumerate}
\end{itemize}

\hypertarget{rumor-spreading}{%
\subsection{Rumor spreading}\label{rumor-spreading}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(netdiffuseR)}

\KeywordTok{set.seed}\NormalTok{(}\DecValTok{09}\NormalTok{)}
\NormalTok{diffnet_rumor <-}\StringTok{ }\KeywordTok{rdiffnet}\NormalTok{(}
  \DataTypeTok{n =} \FloatTok{5e2}\NormalTok{,}
  \DataTypeTok{t =} \DecValTok{5}\NormalTok{, }
  \DataTypeTok{seed.graph =} \StringTok{"small-world"}\NormalTok{,}
  \DataTypeTok{rgraph.args =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{k =} \DecValTok{4}\NormalTok{, }\DataTypeTok{p =} \FloatTok{.3}\NormalTok{),}
  \DataTypeTok{seed.nodes =} \StringTok{"random"}\NormalTok{,}
  \DataTypeTok{seed.p.adopt =} \FloatTok{.05}\NormalTok{,}
  \DataTypeTok{rewire =} \OtherTok{TRUE}\NormalTok{,}
  \DataTypeTok{threshold.dist =} \ControlFlowTok{function}\NormalTok{(i) 1L,}
  \DataTypeTok{exposure.args =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{normalized =} \OtherTok{FALSE}\NormalTok{)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(diffnet_rumor)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Diffusion network summary statistics
## Name     : A diffusion network
## Behavior : Random contagion
## -----------------------------------------------------------------------------
##  Period   Adopters   Cum Adopt. (%)   Hazard Rate   Density   Moran's I (sd)  
## -------- ---------- ---------------- ------------- --------- ---------------- 
##        1         25        25 (0.05)             -      0.01 -0.00 (0.00)     
##        2         78       103 (0.21)          0.16      0.01  0.01 (0.00) *** 
##        3        187       290 (0.58)          0.47      0.01  0.01 (0.00) *** 
##        4        183       473 (0.95)          0.87      0.01  0.01 (0.00) *** 
##        5         27       500 (1.00)          1.00      0.01               -  
## -----------------------------------------------------------------------------
##  Left censoring  : 0.05 (25)
##  Right centoring : 0.00 (0)
##  # of nodes      : 500
## 
##  Moran's I was computed on contemporaneous autocorrelation using 1/geodesic
##  values. Significane levels  *** <= .01, ** <= .05, * <= .1.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot_diffnet}\NormalTok{(diffnet_rumor, }\DataTypeTok{slices =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{08-netdiffuser_files/figure-latex/plot-rumor-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# We want to use igraph to compute layout}
\NormalTok{igdf <-}\StringTok{ }\KeywordTok{diffnet_to_igraph}\NormalTok{(diffnet_rumor, }\DataTypeTok{slices=}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{))[[}\DecValTok{1}\NormalTok{]]}
\NormalTok{pos <-}\StringTok{ }\NormalTok{igraph}\OperatorTok{::}\KeywordTok{layout_with_drl}\NormalTok{(igdf)}

\KeywordTok{plot_diffnet2}\NormalTok{(diffnet_rumor, }\DataTypeTok{vertex.size =} \KeywordTok{dgr}\NormalTok{(diffnet_rumor)[,}\DecValTok{1}\NormalTok{], }\DataTypeTok{layout=}\NormalTok{pos)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{08-netdiffuser_files/figure-latex/plot-rumor-2} \end{center}

\hypertarget{difussion}{%
\subsection{Difussion}\label{difussion}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{09}\NormalTok{)}
\NormalTok{diffnet_complex <-}\StringTok{ }\KeywordTok{rdiffnet}\NormalTok{(}
  \DataTypeTok{seed.graph =}\NormalTok{ diffnet_rumor}\OperatorTok{$}\NormalTok{graph,}
  \DataTypeTok{seed.nodes =} \KeywordTok{which}\NormalTok{(diffnet_rumor}\OperatorTok{$}\NormalTok{toa }\OperatorTok{==}\StringTok{ }\DecValTok{1}\NormalTok{),}
  \DataTypeTok{rewire =} \OtherTok{FALSE}\NormalTok{,}
  \DataTypeTok{threshold.dist =} \ControlFlowTok{function}\NormalTok{(i) }\KeywordTok{rbeta}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{10}\NormalTok{),}
  \DataTypeTok{name =} \StringTok{"Diffusion"}\NormalTok{,}
  \DataTypeTok{behavior =} \StringTok{"Some social behavior"}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot_adopters}\NormalTok{(diffnet_rumor, }\DataTypeTok{what =} \StringTok{"cumadopt"}\NormalTok{, }\DataTypeTok{include.legend =} \OtherTok{FALSE}\NormalTok{)}
\KeywordTok{plot_adopters}\NormalTok{(diffnet_complex, }\DataTypeTok{bg=}\StringTok{"tomato"}\NormalTok{, }\DataTypeTok{add=}\OtherTok{TRUE}\NormalTok{, }\DataTypeTok{what =} \StringTok{"cumadopt"}\NormalTok{)}
\KeywordTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\DataTypeTok{legend =} \KeywordTok{c}\NormalTok{(}\StringTok{"Disease"}\NormalTok{, }\StringTok{"Complex"}\NormalTok{), }\DataTypeTok{col =} \KeywordTok{c}\NormalTok{(}\StringTok{"lightblue"}\NormalTok{, }\StringTok{"tomato"}\NormalTok{),}
       \DataTypeTok{bty =} \StringTok{"n"}\NormalTok{, }\DataTypeTok{pch=}\DecValTok{19}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{08-netdiffuser_files/figure-latex/plot-complex-and-disease-1.pdf}

\hypertarget{mentor-matching}{%
\subsection{Mentor Matching}\label{mentor-matching}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Finding mentors}
\NormalTok{mentors <-}\StringTok{ }\KeywordTok{mentor_matching}\NormalTok{(diffnet_rumor, }\DecValTok{25}\NormalTok{, }\DataTypeTok{lead.ties.method =} \StringTok{"random"}\NormalTok{)}

\CommentTok{# Simulating diffusion with these mentors}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{09}\NormalTok{)}
\NormalTok{diffnet_mentored <-}\StringTok{ }\KeywordTok{rdiffnet}\NormalTok{(}
  \DataTypeTok{seed.graph =}\NormalTok{ diffnet_complex,}
  \DataTypeTok{seed.nodes =} \KeywordTok{which}\NormalTok{(mentors}\OperatorTok{$}\StringTok{`}\DataTypeTok{1}\StringTok{`}\OperatorTok{$}\NormalTok{isleader),}
  \DataTypeTok{rewire =} \OtherTok{FALSE}\NormalTok{,}
  \DataTypeTok{threshold.dist =}\NormalTok{ diffnet_complex[[}\StringTok{"real_threshold"}\NormalTok{]],}
  \DataTypeTok{name =} \StringTok{"Diffusion using Mentors"}
\NormalTok{)}

\KeywordTok{summary}\NormalTok{(diffnet_mentored)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Diffusion network summary statistics
## Name     : Diffusion using Mentors
## Behavior : Random contagion
## -----------------------------------------------------------------------------
##  Period   Adopters   Cum Adopt. (%)   Hazard Rate   Density   Moran's I (sd)  
## -------- ---------- ---------------- ------------- --------- ---------------- 
##        1         25        25 (0.05)             -      0.01 -0.00 (0.00)     
##        2         92       117 (0.23)          0.19      0.01  0.01 (0.00) *** 
##        3        152       269 (0.54)          0.40      0.01  0.01 (0.00) *** 
##        4        150       419 (0.84)          0.65      0.01  0.01 (0.00) *** 
##        5         73       492 (0.98)          0.90      0.01 -0.00 (0.00) **  
## -----------------------------------------------------------------------------
##  Left censoring  : 0.05 (25)
##  Right centoring : 0.02 (8)
##  # of nodes      : 500
## 
##  Moran's I was computed on contemporaneous autocorrelation using 1/geodesic
##  values. Significane levels  *** <= .01, ** <= .05, * <= .1.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{cumulative_adopt_count}\NormalTok{(diffnet_complex)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          1     2        3           4           5
## num  25.00 80.00 183.0000 338.0000000 470.0000000
## prop  0.05  0.16   0.3660   0.6760000   0.9400000
## rate  0.00  2.20   1.2875   0.8469945   0.3905325
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{cumulative_adopt_count}\NormalTok{(diffnet_mentored)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          1       2          3           4           5
## num  25.00 117.000 269.000000 419.0000000 492.0000000
## prop  0.05   0.234   0.538000   0.8380000   0.9840000
## rate  0.00   3.680   1.299145   0.5576208   0.1742243
\end{verbatim}

\hypertarget{example-by-changing-threshold}{%
\subsection{Example by changing threshold}\label{example-by-changing-threshold}}

\begin{Shaded}
\begin{Highlighting}[]

\CommentTok{# Simulating a scale-free homophilic network}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{1231}\NormalTok{)}
\NormalTok{X <-}\StringTok{ }\KeywordTok{rep}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{), }\DecValTok{50}\NormalTok{)}
\NormalTok{net <-}\StringTok{ }\KeywordTok{rgraph_ba}\NormalTok{(}\DataTypeTok{t =} \DecValTok{499}\NormalTok{, }\DataTypeTok{m=}\DecValTok{4}\NormalTok{, }\DataTypeTok{eta =}\NormalTok{ X)}

\CommentTok{# Taking a look in igraph}
\NormalTok{ig  <-}\StringTok{ }\NormalTok{igraph}\OperatorTok{::}\KeywordTok{graph_from_adjacency_matrix}\NormalTok{(net)}
\KeywordTok{plot}\NormalTok{(ig, }\DataTypeTok{vertex.color =} \KeywordTok{c}\NormalTok{(}\StringTok{"azure"}\NormalTok{, }\StringTok{"tomato"}\NormalTok{)[X}\OperatorTok{+}\DecValTok{1}\NormalTok{], }\DataTypeTok{vertex.label =} \OtherTok{NA}\NormalTok{,}
     \DataTypeTok{vertex.size =} \KeywordTok{sqrt}\NormalTok{(}\KeywordTok{dgr}\NormalTok{(net)))}
\end{Highlighting}
\end{Shaded}

\includegraphics{08-netdiffuser_files/figure-latex/sim-sim-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]

\CommentTok{# Now, simulating a bunch of diffusion processes}
\NormalTok{nsim <-}\StringTok{ }\NormalTok{500L}
\NormalTok{ans_1and2 <-}\StringTok{ }\KeywordTok{vector}\NormalTok{(}\StringTok{"list"}\NormalTok{, nsim)}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{223}\NormalTok{)}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{nsim) \{}
  \CommentTok{# We just want the cum adopt count}
\NormalTok{  ans_1and2[[i]] <-}\StringTok{ }
\StringTok{    }\KeywordTok{cumulative_adopt_count}\NormalTok{(}
      \KeywordTok{rdiffnet}\NormalTok{(}
        \DataTypeTok{seed.graph =}\NormalTok{ net,}
        \DataTypeTok{t =} \DecValTok{10}\NormalTok{,}
        \DataTypeTok{threshold.dist =} \KeywordTok{sample}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{2}\NormalTok{, 500L, }\OtherTok{TRUE}\NormalTok{),}
        \DataTypeTok{seed.nodes =} \StringTok{"random"}\NormalTok{,}
        \DataTypeTok{seed.p.adopt =} \FloatTok{.10}\NormalTok{,}
        \DataTypeTok{exposure.args =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{outgoing =} \OtherTok{FALSE}\NormalTok{, }\DataTypeTok{normalized =} \OtherTok{FALSE}\NormalTok{),}
        \DataTypeTok{rewire =} \OtherTok{FALSE}
\NormalTok{        )}
\NormalTok{      )}
  
  \CommentTok{# Are we there yet?}
  \ControlFlowTok{if}\NormalTok{ (}\OperatorTok{!}\NormalTok{(i }\OperatorTok{%%}\StringTok{ }\DecValTok{50}\NormalTok{))}
    \KeywordTok{message}\NormalTok{(}\StringTok{"Simulation "}\NormalTok{, i,}\StringTok{" of "}\NormalTok{, nsim, }\StringTok{" done."}\NormalTok{)}
\NormalTok{\}}
\CommentTok{## Simulation 50 of 500 done.}
\CommentTok{## Simulation 100 of 500 done.}
\CommentTok{## Simulation 150 of 500 done.}
\CommentTok{## Simulation 200 of 500 done.}
\CommentTok{## Simulation 250 of 500 done.}
\CommentTok{## Simulation 300 of 500 done.}
\CommentTok{## Simulation 350 of 500 done.}
\CommentTok{## Simulation 400 of 500 done.}
\CommentTok{## Simulation 450 of 500 done.}
\CommentTok{## Simulation 500 of 500 done.}

\CommentTok{# Extracting prop}
\NormalTok{ans_1and2 <-}\StringTok{ }\KeywordTok{do.call}\NormalTok{(rbind, }\KeywordTok{lapply}\NormalTok{(ans_1and2, }\StringTok{"["}\NormalTok{, }\DataTypeTok{i=}\StringTok{"prop"}\NormalTok{, }\DataTypeTok{j=}\NormalTok{))}

\NormalTok{ans_2and3 <-}\StringTok{ }\KeywordTok{vector}\NormalTok{(}\StringTok{"list"}\NormalTok{, nsim)}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{223}\NormalTok{)}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{nsim) \{}
  \CommentTok{# We just want the cum adopt count}
\NormalTok{  ans_2and3[[i]] <-}\StringTok{ }
\StringTok{    }\KeywordTok{cumulative_adopt_count}\NormalTok{(}
      \KeywordTok{rdiffnet}\NormalTok{(}
        \DataTypeTok{seed.graph =}\NormalTok{ net,}
        \DataTypeTok{t =} \DecValTok{10}\NormalTok{,}
        \DataTypeTok{threshold.dist =} \KeywordTok{sample}\NormalTok{(}\DecValTok{2}\OperatorTok{:}\DecValTok{3}\NormalTok{, 500L, }\OtherTok{TRUE}\NormalTok{),}
        \DataTypeTok{seed.nodes =} \StringTok{"random"}\NormalTok{,}
        \DataTypeTok{seed.p.adopt =} \FloatTok{.10}\NormalTok{,}
        \DataTypeTok{exposure.args =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{outgoing =} \OtherTok{FALSE}\NormalTok{, }\DataTypeTok{normalized =} \OtherTok{FALSE}\NormalTok{),}
        \DataTypeTok{rewire =} \OtherTok{FALSE}
\NormalTok{        )}
\NormalTok{      )}
  
  \CommentTok{# Are we there yet?}
  \ControlFlowTok{if}\NormalTok{ (}\OperatorTok{!}\NormalTok{(i }\OperatorTok{%%}\StringTok{ }\DecValTok{50}\NormalTok{))}
    \KeywordTok{message}\NormalTok{(}\StringTok{"Simulation "}\NormalTok{, i,}\StringTok{" of "}\NormalTok{, nsim, }\StringTok{" done."}\NormalTok{)}
\NormalTok{\}}
\CommentTok{## Simulation 50 of 500 done.}
\CommentTok{## Simulation 100 of 500 done.}
\CommentTok{## Simulation 150 of 500 done.}
\CommentTok{## Simulation 200 of 500 done.}
\CommentTok{## Simulation 250 of 500 done.}
\CommentTok{## Simulation 300 of 500 done.}
\CommentTok{## Simulation 350 of 500 done.}
\CommentTok{## Simulation 400 of 500 done.}
\CommentTok{## Simulation 450 of 500 done.}
\CommentTok{## Simulation 500 of 500 done.}

\NormalTok{ans_2and3 <-}\StringTok{ }\KeywordTok{do.call}\NormalTok{(rbind, }\KeywordTok{lapply}\NormalTok{(ans_2and3, }\StringTok{"["}\NormalTok{, }\DataTypeTok{i=}\StringTok{"prop"}\NormalTok{, }\DataTypeTok{j=}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

We can simplify by using the function \texttt{rdiffnet\_multiple}. The following lines of code accomplish the same as the previous code avoiding the for-loop (from the user's perspective). Besides of the usual parameters passed to \texttt{rdiffnet}, the \texttt{rdiffnet\_multiple} function requires \texttt{R} (number of repetitions/simulations), and \texttt{statistic} (a function that returns the statistic of interest). Optionally, the user may choose to specify the number of clusters to run it in parallel (multiple CPUs):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ans_1and3 <-}\StringTok{ }\KeywordTok{rdiffnet_multiple}\NormalTok{(}
  \CommentTok{# Num of sim}
  \DataTypeTok{R              =}\NormalTok{ nsim,}
  \CommentTok{# Statistic}
  \DataTypeTok{statistic      =} \ControlFlowTok{function}\NormalTok{(d) }\KeywordTok{cumulative_adopt_count}\NormalTok{(d)[}\StringTok{"prop"}\NormalTok{,], }
  \DataTypeTok{seed.graph     =}\NormalTok{ net,}
  \DataTypeTok{t              =} \DecValTok{10}\NormalTok{,}
  \DataTypeTok{threshold.dist =} \KeywordTok{sample}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{3}\NormalTok{, }\DecValTok{500}\NormalTok{, }\OtherTok{TRUE}\NormalTok{),}
  \DataTypeTok{seed.nodes     =} \StringTok{"random"}\NormalTok{,}
  \DataTypeTok{seed.p.adopt   =} \FloatTok{.1}\NormalTok{,}
  \DataTypeTok{rewire         =} \OtherTok{FALSE}\NormalTok{,}
  \DataTypeTok{exposure.args  =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{outgoing=}\OtherTok{FALSE}\NormalTok{, }\DataTypeTok{normalized=}\OtherTok{FALSE}\NormalTok{),}
  \CommentTok{# Running on 4 cores}
  \DataTypeTok{ncpus          =}\NormalTok{ 4L}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{boxplot}\NormalTok{(ans_1and2, }\DataTypeTok{col=}\StringTok{"ivory"}\NormalTok{, }\DataTypeTok{xlab =} \StringTok{"Time"}\NormalTok{, }\DataTypeTok{ylab =} \StringTok{"Threshold"}\NormalTok{)}
\KeywordTok{boxplot}\NormalTok{(ans_2and3, }\DataTypeTok{col=}\StringTok{"tomato"}\NormalTok{, }\DataTypeTok{add=}\OtherTok{TRUE}\NormalTok{)}
\KeywordTok{boxplot}\NormalTok{(}\KeywordTok{t}\NormalTok{(ans_1and3), }\DataTypeTok{col =} \StringTok{"steelblue"}\NormalTok{, }\DataTypeTok{add=}\OtherTok{TRUE}\NormalTok{)}
\KeywordTok{legend}\NormalTok{(}
  \StringTok{"topleft"}\NormalTok{,}
  \DataTypeTok{fill =} \KeywordTok{c}\NormalTok{(}\StringTok{"ivory"}\NormalTok{, }\StringTok{"tomato"}\NormalTok{, }\StringTok{"steelblue"}\NormalTok{),}
  \DataTypeTok{legend =} \KeywordTok{c}\NormalTok{(}\StringTok{"1/2"}\NormalTok{, }\StringTok{"2/3"}\NormalTok{, }\StringTok{"1/3"}\NormalTok{),}
  \DataTypeTok{title =} \StringTok{"Threshold range"}\NormalTok{,}
  \DataTypeTok{bty =}\StringTok{"n"}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{08-netdiffuser_files/figure-latex/sim-sim-results-1.pdf}

\hypertarget{problems-1}{%
\subsection{Problems}\label{problems-1}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Given the following types of networks: Small-world, Scale-free, Bernoulli,
  what set of \(n\) initiators maximizes diffusion?
\end{enumerate}

\hypertarget{statistical-inference}{%
\section{Statistical inference}\label{statistical-inference}}

\hypertarget{morans-i}{%
\subsection{Moran's I}\label{morans-i}}

\begin{itemize}
\item
  Moran's I tests for spatial autocorrelation.
\item
  \textbf{netdiffuseR} implements the test in \texttt{moran}, which is suited for sparse matrices.
\item
  We can use Moran's I as a first look to whether there is something happening:
  let that be influence or homophily.
\end{itemize}

\hypertarget{using-geodesics}{%
\subsection{Using geodesics}\label{using-geodesics}}

\begin{itemize}
\item
  One approach is to use the geodesic (shortest path length) matrix to account for indirect
  influence.
\item
  In the case of sparse matrices, and furthermore, in the presence of structural holes
  it is more convenient to calculate the distance matrix taking this into account.
\item
  \textbf{netdiffuseR} has a function to do so, the \texttt{approx\_geodesic} function, which,
  using graph powers, computes the shortest path up to \texttt{n} steps. This could be
  faster (if you only care up to \texttt{n} steps) than \texttt{igraph} or \texttt{sns}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Extracting the large adjacency matrix (stacked)}
\NormalTok{dgc <-}\StringTok{ }\KeywordTok{diag_expand}\NormalTok{(medInnovationsDiffNet}\OperatorTok{$}\NormalTok{graph)}
\NormalTok{ig  <-}\StringTok{ }\NormalTok{igraph}\OperatorTok{::}\KeywordTok{graph_from_adjacency_matrix}\NormalTok{(dgc)}
\NormalTok{mat <-}\StringTok{ }\NormalTok{network}\OperatorTok{::}\KeywordTok{as.network}\NormalTok{(}\KeywordTok{as.matrix}\NormalTok{(dgc))}

\CommentTok{# Measuring times}
\NormalTok{times <-}\StringTok{ }\NormalTok{microbenchmark}\OperatorTok{::}\KeywordTok{microbenchmark}\NormalTok{(}
  \DataTypeTok{netdiffuseR =}\NormalTok{ netdiffuseR}\OperatorTok{::}\KeywordTok{approx_geodesic}\NormalTok{(dgc),}
  \DataTypeTok{igraph =}\NormalTok{ igraph}\OperatorTok{::}\KeywordTok{distances}\NormalTok{(ig),}
  \DataTypeTok{sna =}\NormalTok{ sna}\OperatorTok{::}\KeywordTok{geodist}\NormalTok{(mat),}
  \DataTypeTok{times =} \DecValTok{50}\NormalTok{, }\DataTypeTok{unit=}\StringTok{"ms"}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

  \includegraphics{08-netdiffuser_files/figure-latex/geodesic_speed-box-1.pdf}
\item
  The \texttt{summary.diffnet} method already runs Moran's for you. What happens under the hood is:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# For each time point we compute the geodesic distances matrix}
\NormalTok{W <-}\StringTok{ }\KeywordTok{approx_geodesic}\NormalTok{(medInnovationsDiffNet}\OperatorTok{$}\NormalTok{graph[[}\DecValTok{1}\NormalTok{]])}

\CommentTok{# We get the element-wise inverse}
\NormalTok{W}\OperatorTok{@}\NormalTok{x <-}\StringTok{ }\DecValTok{1}\OperatorTok{/}\NormalTok{W}\OperatorTok{@}\NormalTok{x}

\CommentTok{# And then compute moran}
\KeywordTok{moran}\NormalTok{(medInnovationsDiffNet}\OperatorTok{$}\NormalTok{cumadopt[,}\DecValTok{1}\NormalTok{], W)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $observed
## [1] 0.06624028
## 
## $expected
## [1] -0.008064516
## 
## $sd
## [1] 0.03265066
## 
## $p.value
## [1] 0.02286087
## 
## attr(,"class")
## [1] "diffnet_moran"
\end{verbatim}
\end{itemize}

\hypertarget{structural-dependence-and-permutation-tests}{%
\subsection{Structural dependence and permutation tests}\label{structural-dependence-and-permutation-tests}}

\begin{itemize}
\tightlist
\item
  A novel statistical method (work-in-progress) that allows conducting inference.
\item
  Included in the package, tests whether a particular network statistic depends on network structure
\item
  Suitable to be applied to network thresholds (you can't use thresholds in regression-like models!)
\end{itemize}

\hypertarget{idea}{%
\subsection{Idea}\label{idea}}

\begin{itemize}
\item
  Let \(\mathcal{G} = (V,E)\) be a graph, \(\gamma\) a vertex attribute, and \(\beta = f(\gamma,\mathcal{G})\), then

  \[\gamma \perp \mathcal{G} \implies \mathbb{E}\left[\beta(\gamma,\mathcal{G})|\mathcal{G}\right] = \mathbb{E}\left[\beta(\gamma,\mathcal{G})\right]\]
\item
  This is, if for example time of adoption is independent on the structure of the network, then the average threshold level will be independent from the network structure as well.
\item
  Another way of looking at this is that the test will allow us to see how probable is to have this combination of network structure and network threshold (if it is uncommon then we say that the diffusion model is highly likely)
\end{itemize}

\hypertarget{example-not-random-toa}{%
\subsubsection{Example Not random TOA}\label{example-not-random-toa}}

\begin{itemize}
\item
\begin{verbatim}
To use this test, __netdiffuseR__ has the `struct_test` function.
\end{verbatim}
\item
\begin{verbatim}
It simulates networks with the same density, and computes a particular statistic every time, generating an EDF (Empirical Distribution Function) under the Null hypothesis (p-values).
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Simulating network}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{1123}\NormalTok{)}
\NormalTok{net <-}\StringTok{ }\KeywordTok{rdiffnet}\NormalTok{(}\DataTypeTok{n=}\DecValTok{500}\NormalTok{, }\DataTypeTok{t=}\DecValTok{10}\NormalTok{, }\DataTypeTok{seed.graph =} \StringTok{"small-world"}\NormalTok{)}

\CommentTok{# Running the test}
\NormalTok{test <-}\StringTok{ }\KeywordTok{struct_test}\NormalTok{(}
  \DataTypeTok{graph     =}\NormalTok{ net, }
  \DataTypeTok{statistic =} \ControlFlowTok{function}\NormalTok{(x) }\KeywordTok{mean}\NormalTok{(}\KeywordTok{threshold}\NormalTok{(x), }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{),}
  \DataTypeTok{R         =} \FloatTok{1e3}\NormalTok{,}
  \DataTypeTok{ncpus=}\DecValTok{4}\NormalTok{, }\DataTypeTok{parallel=}\StringTok{"multicore"}
\NormalTok{  )}

\CommentTok{# See the output}
\NormalTok{test}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Structure dependence test
## # Simulations     : 1,000
## # nodes           : 500
## # of time periods : 10
## --------------------------------------------------------------------------------
##  H0: E[beta(Y,G)|G] - E[beta(Y,G)] = 0 (no structure dependency)
##     observed    expected       p.val
##       0.5513      0.2511      0.0000
\end{verbatim}
\end{itemize}

\includegraphics{08-netdiffuser_files/figure-latex/unnamed-chunk-2-1.pdf}

\begin{itemize}
\item
  Now we shuffle times of adoption, so that is random

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Resetting TOAs (now will be completely random)}
\KeywordTok{diffnet.toa}\NormalTok{(net) <-}\StringTok{ }\KeywordTok{sample}\NormalTok{(}\KeywordTok{diffnet.toa}\NormalTok{(net), }\KeywordTok{nnodes}\NormalTok{(net), }\OtherTok{TRUE}\NormalTok{)}

\CommentTok{# Running the test}
\NormalTok{test <-}\StringTok{ }\KeywordTok{struct_test}\NormalTok{(}
  \DataTypeTok{graph     =}\NormalTok{ net, }
  \DataTypeTok{statistic =} \ControlFlowTok{function}\NormalTok{(x) }\KeywordTok{mean}\NormalTok{(}\KeywordTok{threshold}\NormalTok{(x), }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{),}
  \DataTypeTok{R         =} \FloatTok{1e3}\NormalTok{,}
  \DataTypeTok{ncpus=}\DecValTok{4}\NormalTok{, }\DataTypeTok{parallel=}\StringTok{"multicore"}
\NormalTok{  )}

\CommentTok{# See the output}
\NormalTok{test}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Structure dependence test
## # Simulations     : 1,000
## # nodes           : 500
## # of time periods : 10
## --------------------------------------------------------------------------------
##  H0: E[beta(Y,G)|G] - E[beta(Y,G)] = 0 (no structure dependency)
##     observed    expected       p.val
##       0.2714      0.2579      0.3720
\end{verbatim}

  \includegraphics{08-netdiffuser_files/figure-latex/unnamed-chunk-3-1.pdf}
\end{itemize}

\hypertarget{regression-analysis}{%
\subsection{Regression analysis}\label{regression-analysis}}

\begin{itemize}
\item
  In regression analysis, we want to see if exposure, once we control for other
  covariates had any effect on the adoption of a behavior.
\item
  In general, the big problem here is when we have a latent variable that
  co-determines both network and behavior.
\item
  Unless we can control for such variable, regression analysis will be
  generically biased.
\item
  On the other hand, if you can claim that either such variable doesn't exist
  or you actually can control for it, then we have two options: lagged exposure
  models or contemporaneous exposure models. We will focus on the former.
\end{itemize}

\hypertarget{lagged-exposure-models}{%
\subsubsection{Lagged exposure models}\label{lagged-exposure-models}}

\begin{itemize}
\item
  In this type of model, we usually have the following

  \[
  y_t = f(W_{t-1}, y_{t-1}, X_i) + \varepsilon
  \]

  Furthermore, in the case of adoption, we have

  \[
  y_{it} = \left\{
  \begin{array}{ll}
  1 & \mbox{if}\quad \rho\sum_{j\neq i}\frac{W_{ijt-1}y_{it-1}}{\sum_{j\neq i}W_{ijt-1}} + X_{it}\beta > 0\\
  0 & \mbox{otherwise}
  \end{array}
  \right.
  \]
\item
  In netdiffuseR is as easy as doing the following:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# fakedata}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{121}\NormalTok{)}

\NormalTok{W   <-}\StringTok{ }\KeywordTok{rgraph_ws}\NormalTok{(}\FloatTok{1e3}\NormalTok{, }\DecValTok{8}\NormalTok{, }\FloatTok{.2}\NormalTok{)}
\NormalTok{X   <-}\StringTok{ }\KeywordTok{cbind}\NormalTok{(}\DataTypeTok{var1 =} \KeywordTok{rnorm}\NormalTok{(}\FloatTok{1e3}\NormalTok{))}
\NormalTok{toa <-}\StringTok{ }\KeywordTok{sample}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\OtherTok{NA}\NormalTok{,}\DecValTok{1}\OperatorTok{:}\DecValTok{5}\NormalTok{), }\FloatTok{1e3}\NormalTok{, }\OtherTok{TRUE}\NormalTok{)}

\NormalTok{dn  <-}\StringTok{ }\KeywordTok{new_diffnet}\NormalTok{(W, }\DataTypeTok{toa=}\NormalTok{toa, }\DataTypeTok{vertex.static.attrs =}\NormalTok{ X)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning in new_diffnet(W, toa = toa, vertex.static.attrs = X): -graph- is static
## and will be recycled (see ?new_diffnet).
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Computing exposure and adoption for regression}
\NormalTok{dn[[}\StringTok{"cohesive_expo"}\NormalTok{]] <-}\StringTok{ }\KeywordTok{cbind}\NormalTok{(}\OtherTok{NA}\NormalTok{, }\KeywordTok{exposure}\NormalTok{(dn)[,}\OperatorTok{-}\KeywordTok{nslices}\NormalTok{(dn)])}
\NormalTok{dn[[}\StringTok{"adopt"}\NormalTok{]]         <-}\StringTok{ }\NormalTok{dn}\OperatorTok{$}\NormalTok{cumadopt}

\CommentTok{# Generating the data and running the model}
\NormalTok{dat <-}\StringTok{ }\KeywordTok{as.data.frame}\NormalTok{(dn)}
\NormalTok{ans <-}\StringTok{ }\KeywordTok{glm}\NormalTok{(adopt }\OperatorTok{~}\StringTok{ }\NormalTok{cohesive_expo }\OperatorTok{+}\StringTok{ }\NormalTok{var1 }\OperatorTok{+}\StringTok{ }\KeywordTok{factor}\NormalTok{(per),}
           \DataTypeTok{data =}\NormalTok{ dat,}
           \DataTypeTok{family =} \KeywordTok{binomial}\NormalTok{(}\DataTypeTok{link=}\StringTok{"probit"}\NormalTok{),}
           \DataTypeTok{subset =} \KeywordTok{is.na}\NormalTok{(toa) }\OperatorTok{|}\StringTok{ }\NormalTok{(per }\OperatorTok{<=}\StringTok{ }\NormalTok{toa))}
\KeywordTok{summary}\NormalTok{(ans)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## glm(formula = adopt ~ cohesive_expo + var1 + factor(per), family = binomial(link = "probit"), 
##     data = dat, subset = is.na(toa) | (per <= toa))
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.1754  -0.8462  -0.6645   1.2878   1.9523  
## 
## Coefficients:
##               Estimate Std. Error z value Pr(>|z|)    
## (Intercept)   -0.92777    0.05840 -15.888  < 2e-16 ***
## cohesive_expo  0.23839    0.17514   1.361 0.173452    
## var1          -0.04623    0.02704  -1.710 0.087334 .  
## factor(per)3   0.29313    0.07715   3.799 0.000145 ***
## factor(per)4   0.33902    0.09897   3.425 0.000614 ***
## factor(per)5   0.59851    0.12193   4.909 9.18e-07 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 2745.1  on 2317  degrees of freedom
## Residual deviance: 2663.5  on 2312  degrees of freedom
##   (1000 observations deleted due to missingness)
## AIC: 2675.5
## 
## Number of Fisher Scoring iterations: 4
\end{verbatim}

  Alternatively, we could have used the new function \texttt{diffreg}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ans <-}\StringTok{ }\KeywordTok{diffreg}\NormalTok{(dn }\OperatorTok{~}\StringTok{ }\NormalTok{exposure }\OperatorTok{+}\StringTok{ }\NormalTok{var1 }\OperatorTok{+}\StringTok{ }\KeywordTok{factor}\NormalTok{(per), }\DataTypeTok{type =} \StringTok{"probit"}\NormalTok{)}
\KeywordTok{summary}\NormalTok{(ans)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## glm(formula = Adopt ~ exposure + var1 + factor(per), family = binomial(link = "probit"), 
##     data = dat, subset = ifelse(is.na(toa), TRUE, toa >= per))
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.1754  -0.8462  -0.6645   1.2878   1.9523  
## 
## Coefficients:
##              Estimate Std. Error z value Pr(>|z|)    
## (Intercept)  -0.92777    0.05840 -15.888  < 2e-16 ***
## exposure      0.23839    0.17514   1.361 0.173452    
## var1         -0.04623    0.02704  -1.710 0.087334 .  
## factor(per)3  0.29313    0.07715   3.799 0.000145 ***
## factor(per)4  0.33902    0.09897   3.425 0.000614 ***
## factor(per)5  0.59851    0.12193   4.909 9.18e-07 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 2745.1  on 2317  degrees of freedom
## Residual deviance: 2663.5  on 2312  degrees of freedom
##   (1000 observations deleted due to missingness)
## AIC: 2675.5
## 
## Number of Fisher Scoring iterations: 4
\end{verbatim}
\end{itemize}

\hypertarget{contemporaneous-exposure-models}{%
\subsubsection{Contemporaneous exposure models}\label{contemporaneous-exposure-models}}

\begin{itemize}
\item
  Similar to the lagged exposure models, we usually have the following

  \[
  y_t = f(W_t, y_t, X_t) + \varepsilon
  \]

  Furthermore, in the case of adoption, we have

  \[
  y_{it} = \left\{
  \begin{array}{ll}
  1 & \mbox{if}\quad \rho\sum_{j\neq i}\frac{W_{ijt}y_{it}}{\sum_{j\neq i}W_{ijt}} + X_{it}\beta > 0\\
  0 & \mbox{otherwise}
  \end{array}
  \right.
  \]
\item
  Unfortunately, since \(y_t\) is in both sides of the equation, this models cannot
  be fitted using a standard probit or logit regression.
\item
  Two alternatives to solve this:

  \begin{enumerate}
  \def\labelenumi{\alph{enumi}.}
  \item
    Using Instrumental Variables Probit (ivprobit in both R and Stata)
  \item
    Use a Spatial Autoregressive (SAR) Probit (SpatialProbit and ProbitSpatial in R).
  \end{enumerate}
\item
  We won't cover these here.
\end{itemize}

\hypertarget{problems-2}{%
\subsection{Problems}\label{problems-2}}

Using the dataset \url{stats.rda}:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Compute Moran's I as the function \texttt{summary.diffnet} does. For this you'll need
  to use the function \texttt{toa\_mat} (which calculates the cumulative adoption matrix),
  and \texttt{approx\_geodesic} (which computes the geodesic matrix). (see \texttt{?summary.diffnet}
  for more details).
\item
  Read the data as diffnet object, and fit the following logit model \(adopt = Exposure*\gamma + Measure*\beta + \varepsilon\).
  What happens if you exclude the time-fixed effects?
\end{enumerate}

\hypertarget{stochastic-actor-oriented-models}{%
\chapter{Stochastic Actor Oriented Models}\label{stochastic-actor-oriented-models}}

Stochastic Actor Oriented Models (SOAM), also known as Siena models were introduced by CITATION NEEDED.

As a difference from ERGMs, Siena models look at the data generating process from the individuals' point of view. Based on McFadden's ideas of probabilistic choice, the model is founded in the following equation

\[
U_i(x) - U_i(x') \sim \mbox{Extreame Value Distribution}
\]

In other words, individuals choose between states \(x\) and \(x'\) in a probabilistic way (with some noise),

\[
\frac{\mbox{exp}\left\{f_i^Z(\beta^z,x, z)\right\}}{\sum_{Z'\in\mathcal{C}}\mbox{exp}\left\{f_i^{Z}(\beta, x, z')\right\}}
\]

snijders\_(sociological methodology 2001)

(Snijders, Bunt, and Steglich \protect\hyperlink{ref-Snijders2010}{2010}, @lazega2015, @Ripley2011)

\hypertarget{part-statistical-foundations}{%
\part{Statistical Foundations}\label{part-statistical-foundations}}

\hypertarget{bayes-rule}{%
\chapter{Bayes' Rule}\label{bayes-rule}}

Bayes' Rule is a fundamental equation in Bayesian statistics. With it, we can reformulate inferential problems by writing probabilities in terms of known quantities. Bayes' rule can be stated as follows:

\begin{equation}
\mathbb{P}{\left(X=x|Y=y\right)} = \frac{\mathbb{P}{\left(Y=y|X=y\right)}\mathbb{P}{\left(X=x\right)}}{\mathbb{P}{\left(Y=y\right)}}
\end{equation}

Here we say that the conditional probability of \(X\) given \(Y\) can be expressed in terms of the conditional probability of \(Y\) given \(X\). For example, let \(X\) be an unknown vector of parameters \(\theta\in\Theta\) and \(Y\) a dataset \(D \sim f(\theta)\) whose data generating process depends on the unobserved \(\theta\). As the posterior distribution of model parameters is in general elusive, instead, we use Bayes' rule to rephrase the problem:

\begin{equation*}
\mathbb{P}{\left(\theta|D\right)} = \frac{\mathbb{P}{\left(\theta|D\right)}\mathbb{P}{\left(\theta\right)}}{\mathbb{P}{\left(D\right)}}
\end{equation*}

Since the denominator of the equation does not depend on \(\theta\), we can, instead, write

\begin{equation*}
\mathbb{P}{\left(\theta|D\right)} \propto \mathbb{P}{\left(\theta|D\right)}\mathbb{P}{\left(\theta\right)}
\end{equation*}

In the Bayesian world, the unconditional distribution of the model parameters is assumed to come from a particular distribution, whereas in the frequentist world, no distributional assumptions are made about the model parameters. The latter is then equivalent to saying that \(\theta\sim \mbox{Uniform}(-\infty, +\infty)\); therefore, even frequentists assume something about the model parameters!\footnote{The discussion about differences and similarities between frequentists and Bayesians has a long tradition. Bottom line, no one can say 100\% that they are either-or. In rigor, frequentists say model parameters are not random but deterministic.}

Bayes' rule can be derived using conditional probabilities. In particular, \(\mathbb{P}{\left(x=x|Y=y\right)}\) is defined as \(\mathbb{P}{\left(x=x, Y=y\right)}/Pr{\left(Y=y\right)}\). Likewise, \(\mathbb{P}{\left(y=y|X=x\right)}\) is defined as \(\mathbb{P}{\left(y=y, X=x\right)}/Pr{\left(X=x\right)}\), which can be re-written as \(\mathbb{P}{\left(x=x, Y=y\right)} = \mathbb{P}{\left(y=y|X=x\right)}Pr{\left(X=x\right)}\). Replacing the last equality in the first equation we get

\begin{align*}
\mathbb{P}{\left(x=x|Y=y\right)} & = \frac{\mathbb{P}{\left(x=x, Y=y\right)}}{Pr{\left(Y=y\right)}} \\
& \frac{\mathbb{P}{\left(y=y|X=x\right)}Pr{\left(X=x\right)}}{Pr{\left(Y=y\right)}}
\end{align*}

\hypertarget{markov-chain}{%
\chapter{Markov Chain}\label{markov-chain}}

A Markov Chain is a sequence of random variables in which the conditional distribution of the \(n\)-th element only depends on \(n-1\).

\hypertarget{metropolis-algorithm}{%
\section{Metropolis Algorithm}\label{metropolis-algorithm}}

In the Metropolis Algorithm, or Metropolis MCMC, builds a Markov Chain that
under certain conditions converges to the target distribution. The key of the
Algorithm is in accepting a proposed move from \(\theta\) to \(\theta'\) with
probability equal to:

\begin{equation}
r = \min\left(1, \frac{\mathbb{P}{\left(\theta'|D\right)}}{\mathbb{P}{\left(\theta|D\right)}}\right)
\end{equation}

The resulting sequence converges to the target distribution. We can prove
convergence by showing that (a) the sequence is ergodic, and (b) the posterior
distribution matches the target distribution. Ergodicity describes three
propoerties of a chain:

\begin{itemize}
\item
  Irreducibility: There is no zero probability of transitioning between any pair of states.
\item
  Aperiodicity: As the term suggests, the chain has no repetitive periods/sequences.
\item
  Non-transient: Transient refers to a chain having non-zero probability of
  never returning to a starting state.
\end{itemize}

The three properties are reached by any random walk based on a well-defined
probability distribution, so we will focus on showing that the posterior matches
the target distribution.

\hypertarget{metropolis-hastings}{%
\section{Metropolis-Hastings}\label{metropolis-hastings}}

\[
\min\left(1, \frac{\mathbb{P}{\left(d|\theta'\right)}\mathbb{P}{\left(\theta'\right)}\mathbb{P}{\left(\theta'|\theta\right)}}{\mathbb{P}{\left(d|\theta\right)}\mathbb{P}{\left(\theta\right)}\mathbb{P}{\left(\theta|\theta'\right)}}\right)
\]

If the transittion probability is symmetric, then the previous equation reduces
to the Metropolis probability.

\hypertarget{likelihood-free-mcmc}{%
\section{Likelihood-free MCMC}\label{likelihood-free-mcmc}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Initialize the algorithm with \(\theta_0\), \(\theta^* =\theta_0\)--the current accepted
  state,--and observed summary statistic \(s_0 = S(D_{observed})\):
\item
  For \(t = 1\) to \(T\) do:

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \item
    Draw \(\theta_t\) from the proposal distribution \(J(\theta_t|\theta^*)\)
  \item
    Draw a simulated data \(D_t\) from model \(M(\theta_t)\)
  \item
    Calculate the summary statistics \(s_t = S(D_t)\)
  \item
    Accept the proposed state with probability
  \end{enumerate}

  If accepted, set \(\theta^* = \theta_t\).

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \setcounter{enumii}{4}
  \tightlist
  \item
    Next \(t\)
  \end{enumerate}
\end{enumerate}

\hypertarget{power-calculation-in-network-studies}{%
\chapter{Power calculation in network studies}\label{power-calculation-in-network-studies}}

Computing power and sample size are common tasks in study design. This chapter will walk you
through power analysis for network studies. First, we will start with some preliminaries
regarding error types and statistical power.

\hypertarget{error-types}{%
\section{Error types}\label{error-types}}

One of the most important tables we'll see around is the contingency table of accept/reject the null hypothesis conditional on the true state:

\begin{tabular}{l|l|l}
\hline
  & Accept H0 & Reject H0\\
\hline
H0 is true & True positive & False negative\\
\hline
H1 is true & False positive & True negative\\
\hline
\end{tabular}

A better way, more statistically accurate version of this table would be

\begin{tabular}{l|l|l}
\hline
  & Accept H0 & Reject H0\\
\hline
H0 is true & Correct inference & Type I error\\
\hline
H1 is true & Type II error & Correct Inference\\
\hline
\end{tabular}

With \(\mathbb{P}{(\mbox{Type I error})} = \alpha\) and \(\mathbb{P}{(\mbox{Type II error})} = \beta\). This way, power can be defined as the
probability of rejecting the null given the alternative is true, \(\mathbb{P}{(\mbox{Reject H0}|\mbox{H1 is true})} = 1-\beta\).

\hypertarget{examples-1}{%
\section{Examples}\label{examples-1}}

\hypertarget{sample-size-for-a-proportion}{%
\subsection{Sample size for a proportion}\label{sample-size-for-a-proportion}}

Let's imagine we are preparing a study in which we would like to estimate the proportion of individuals with a given status. Formally, we then say that the variable \(Y\sim\mbox{Bernoulli}(p)\). To do so, we will need to survey \(n\) individuals and estimate such a number by taking the sample average. Furthermore, we hypothesize that under the null the proportion is \(H_0: p = p_0\).

The key here is to think about a simple rejection rule. Again, power is the probability of \textbf{rejecting the null} given that \textbf{the alternative is true}. So, to write down the equation, we need to think about acceptance and rejection regions. Let \(\hat p\) be our estimate for the population parameter, furthermore, \(\hat p = n^{-1}\sum_i y_i\). Our test statistic can be--and will be, most of the cases--standardized to leverage the law of large numbers; under the null, we write the following:

\begin{align*}
\mathbb{E}(\hat p) & = p_0 \\
\mathbf{Var}(\hat p) & = \sqrt{p_0(1-p_0)/n}
\end{align*}

Therefore, the statistic:

\begin{equation*}
\frac{\hat p - p_0}{\sqrt{p_0(1-p_0)/n}} = \frac{\sqrt{n}(\hat p - p_0)}{\sqrt{p_0(1-p_0)}} \sim \mbox{N}(0, 1)
\end{equation*}

Since the statistic is normally distributed, we can then say when we will reject the null. For this case, that depends on the critical value, which most of the time is defined in terms of the type I error rate. Formally, we reject the null if

\begin{equation*}
\frac{\sqrt{n}(\hat p - p_0)}{\sqrt{p_0(1-p_0)}} > Z_{1-\alpha/2}
\end{equation*}

This is equivalent to saying that the \textbf{test statistic fell into the rejection region}. With this in hand, we can now write out the equation that we will be using for calculating the sample size. Going back to the definition of power:

\begin{align*}
\mathbb{P}{(\mbox{Reject H0}|\mbox{H1 is true})} & = 1-\beta \\
\mathbb{P}{\left(\frac{\sqrt{n}(\hat p - p_0)}{\sqrt{p_0(1-p_0)}} > Z_{1-\alpha/2}\right.\left|\vphantom{\frac{1}{2}}p = p_1\right)} & = 1 - \beta
\end{align*}

Observe that we cannot compute the power for all \(p\neq p_0\); instead, we look at a given parameter value. A good idea is to start from one previously known or identified in other studies. The key idea here is to be able to manipulate the argument of the probability to turn it into a known distribution, for example, the normal distribution:

For a given Type I of 0.05 and power of 0.8, the required sample size can be computed as follows:

\begin{align*}
1 - \beta & = \mathbb{P}{\left(\frac{\sqrt{n}(\hat p - p_0)}{\sqrt{p_0(1-p_0)}} > Z_{1-\alpha/2}\right.\left|\vphantom{\frac{1}{2}}p = p_1\right)} \\
& = \mathbb{P}{\left(\frac{\sqrt{n}(\hat p - p_0)}{\sqrt{p_0(1-p_0)}} < Z_{\alpha/2}\right.\left|\vphantom{\frac{1}{2}}p = p_1\right)} \\
& = \mathbb{P}{\left(\frac{\sqrt{n}(\hat p - p_0)}{\sqrt{p_1(1-p_1)}} < \frac{Z_{\alpha/2}\sqrt{p_0(1-p_0)}}{\sqrt{p_1(1-p_1)}}\right.\left|\vphantom{\frac{1}{2}}p = p_1\right)} \\
& = \mathbb{P}{\left(\frac{\sqrt{n}(\hat p - p_0 + p_0 - p_1)}{\sqrt{p_1(1-p_1)}} < \frac{Z_{\alpha/2}\sqrt{p_0(1-p_0)} + \sqrt{n}(p_0 - p_1)}{\sqrt{p_1(1-p_1)}}\right.\left|\vphantom{\frac{1}{2}}p = p_1\right)} \\
& = \mathbb{P}{\left(\frac{\sqrt{n}(\hat p - p_1)}{\sqrt{p_1(1-p_1)}} < \frac{Z_{\alpha/2}\sqrt{p_0(1-p_0)} + \sqrt{n}(p_0 - p_1)}{\sqrt{p_1(1-p_1)}}\right.\left|\vphantom{\frac{1}{2}}p = p_1\right)} \\
& = \Phi\left(\frac{Z_{\alpha/2}\sqrt{p_0(1-p_0)} + \sqrt{n}(p_0 - p_1)}{\sqrt{p_1(1-p_1)}}\right.\left|\vphantom{\frac{1}{2}}p = p_1\right) \\
\end{align*}

The last equality follows from the quantity \(\frac{\sqrt{n}(\hat p - p_1)}{\sqrt{p_1(1-p_1)}}\) distributing standard normal. We can now take the inverse of the cumulative distribution function (cdf) to isolate the sample size \(n\):

\begin{align*}
\Phi^{-1}(1 - \beta)& = \frac{Z_{\alpha/2}\sqrt{p_0(1-p_0)} + \sqrt{n}(p_0 - p_1)}{\sqrt{p_1(1-p_1)}} \\
Z_{1-\beta}\sqrt{p_1(1-p_1)}& = Z_{\alpha/2}\sqrt{p_0(1-p_0)} + \sqrt{n}(p_0 - p_1) \\
\frac{\left(Z_{1-\beta}\sqrt{p_1(1-p_1)} - Z_{\alpha/2}\sqrt{p_0(1-p_0)}\right)^2}{(p_0 - p_1)^2}& = n \\
\end{align*}

Therefore, for the parameters \((1-\beta, \alpha, p_0, p_1) = (0.8, 0.05, 0.5, 0.6)\), the required sample size is 193.8473 \(\sim\) 194.

\hypertarget{sample-size-for-a-proportion-vis}{%
\subsection{Sample size for a proportion (vis)}\label{sample-size-for-a-proportion-vis}}

Now, what happens if the model we are planning to estimate does not have a close form? If analytical solutions are not available, simulations can be an excellent alternative to save the day. Let's re-do the sample size calculation using simulations.

The procedure to compute sample size based on simulations is computationally intensive. The concept is straightforward, pick a set of best guesses for sample size, and for each one of them, simulate the system to estimate power. Now, for a given value of \(n\), we:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Simulate a sample of size \(n\) under the alternative.
\item
  Compute the test statistic corresponding to the null.
\item
  Accept or reject accordingly to the selected \(\alpha\), and store the result.
\item
  Repeat steps 1-3 many times. The obtained average is the corresponding power.
\end{enumerate}

When running simulations, it is convenient to write a function for the data generating process. In our case, the function will be called \texttt{sim\_fun}. The following lines of code achieve our goal: approximate power by simulating 10,000 experiments for each sample size candidate:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Model parameters}
\NormalTok{p0        <-}\StringTok{ }\FloatTok{.5}
\NormalTok{p1        <-}\StringTok{ }\FloatTok{.6}
\NormalTok{betapower <-}\StringTok{ }\DecValTok{1} \OperatorTok{-}\StringTok{ }\FloatTok{0.8}
\NormalTok{alpha     <-}\StringTok{ }\FloatTok{0.05}
\NormalTok{nsims     <-}\StringTok{ }\DecValTok{10000}

\CommentTok{# Step 1: Simulate the data under H1}
\NormalTok{z_one_minus_alpha_half <-}\StringTok{ }\KeywordTok{qnorm}\NormalTok{(}\DecValTok{1} \OperatorTok{-}\StringTok{ }\NormalTok{alpha }\OperatorTok{/}\StringTok{ }\DecValTok{2}\NormalTok{)}
\NormalTok{sim_fun <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(n) \{}

    \CommentTok{# Generating the data}
\NormalTok{    y <-}\StringTok{ }\KeywordTok{as.integer}\NormalTok{(}\KeywordTok{runif}\NormalTok{(n) }\OperatorTok{<}\StringTok{ }\NormalTok{p1)}
\NormalTok{    phat <-}\StringTok{ }\KeywordTok{mean}\NormalTok{(y)}

    \CommentTok{# Accept or reject?}
    \KeywordTok{sqrt}\NormalTok{(n) }\OperatorTok{*}\StringTok{ }\NormalTok{(phat }\OperatorTok{-}\StringTok{ }\NormalTok{p0) }\OperatorTok{/}\StringTok{ }\KeywordTok{sqrt}\NormalTok{(p0 }\OperatorTok{*}\StringTok{ }\NormalTok{(}\DecValTok{1} \OperatorTok{-}\StringTok{ }\NormalTok{p0)) }\OperatorTok{>}
\StringTok{        }\NormalTok{z_one_minus_alpha_half}

\NormalTok{\}}

\CommentTok{# Step 2: For an array of n, simulate multiple experiments}
\NormalTok{n_seq <-}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\DataTypeTok{from =} \DecValTok{150}\NormalTok{, }\DataTypeTok{to =} \DecValTok{250}\NormalTok{, }\DataTypeTok{by =} \DecValTok{10}\NormalTok{)}

\NormalTok{simulations <-}\StringTok{ }\OtherTok{NULL}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{12312}\NormalTok{)}
\ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in}\NormalTok{ n_seq) \{}

    \CommentTok{# Run the nsims experiments}
\NormalTok{    res <-}\StringTok{ }\KeywordTok{replicate}\NormalTok{(nsims, }\KeywordTok{sim_fun}\NormalTok{(n))}

    \CommentTok{# Compute power and store the value}
\NormalTok{    simulations <-}\StringTok{ }\KeywordTok{rbind}\NormalTok{(}
\NormalTok{        simulations,}
        \KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{size =}\NormalTok{ n, }\DataTypeTok{power =} \KeywordTok{mean}\NormalTok{(res))}
\NormalTok{    )}
\NormalTok{\}}

\CommentTok{# Finding out what is the closets value}
\NormalTok{best <-}\StringTok{ }\KeywordTok{which.min}\NormalTok{(}
    \KeywordTok{abs}\NormalTok{((}\DecValTok{1} \OperatorTok{-}\StringTok{ }\NormalTok{betapower) }\OperatorTok{-}\StringTok{ }\NormalTok{simulations}\OperatorTok{$}\NormalTok{power)}
\NormalTok{    )}

\NormalTok{simulations[best,,drop=}\OtherTok{FALSE}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   size  power
## 5  190 0.7952
\end{verbatim}

Let's visualize the power curve we generate from this simulation:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(ggplot2)}
\KeywordTok{ggplot}\NormalTok{(simulations, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ size, }\DataTypeTok{y =}\NormalTok{ power)) }\OperatorTok{+}
\StringTok{    }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}
\StringTok{    }\KeywordTok{geom_smooth}\NormalTok{() }\OperatorTok{+}
\StringTok{    }\KeywordTok{geom_hline}\NormalTok{(}\DataTypeTok{yintercept =} \DecValTok{1} \OperatorTok{-}\StringTok{ }\NormalTok{betapower)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `geom_smooth()` using method = 'loess' and formula 'y ~ x'
\end{verbatim}

\includegraphics{11-power_files/figure-latex/11-power-plot-1.pdf}

According to our simulation study, the closest to our 80\% power is using a sample size equal to 190, which is very close to the analytical solution of 194.

As a final comment for this example, remember that the more simulations the better.

\cleardoublepage

\hypertarget{appendix-appendix}{%
\appendix}


\hypertarget{datasets-1}{%
\chapter{Datasets}\label{datasets-1}}

\hypertarget{sns-data}{%
\section{SNS data}\label{sns-data}}

\hypertarget{about-the-data}{%
\subsection{About the data}\label{about-the-data}}

\begin{itemize}
\item
  This data is part of the NIH Challenge grant \# RC 1RC1AA019239 ``Social
  Networks and Networking That Puts Adolescents at High Risk''.
\item
  In general terms, the SNS's goal was(is) ``Understand the network effects on
  risk behaviors such as smoking initiation and substance use''.
\end{itemize}

\hypertarget{variables}{%
\subsection{Variables}\label{variables}}

The data has a \emph{wide} structure, which means that there is one row per individual,
and that dynamic attributes are represented as one column per time.

\begin{itemize}
\item
  \texttt{photoid} Photo id at the school level (can be repeated across schools).
\item
  \texttt{school} School id.
\item
  \texttt{hispanic} Indicator variable that equals 1 if the indivual ever reported
  himself as hispanic.
\item
  \texttt{female1}, \ldots{}, \texttt{female4} Indicator variable that equals 1 if the individual
  reported to be female at the particular wave.
\item
  \texttt{grades1},\ldots{}, \texttt{grades4} Academic grades by wave. Values from 1 to 5, with 5
  been the best.
\item
  \texttt{eversmk1}, \ldots{}, \texttt{eversmk4} Indicator variable of ever smoking by wave. A one
  indicated that the individual had smoked at the time of the survey.
\item
  \texttt{everdrk1}, \ldots{}, \texttt{everdrk4} Indicator variable of ever drinking by wave.
  A one indicated that the individual had drink at the time of the survey.
\item
  \texttt{home1}, \ldots{}, \texttt{home4} Factor variable for home status by wave. A one
  indicates home ownership, a 2 rent, and a 3 a ``I don't know''.
\end{itemize}

During the survey, participants were asked to name up to 19 of their school
friends:

\begin{itemize}
\item
  \texttt{sch\_friend11}, \ldots{}, \texttt{sch\_friend119} School friends nominations (19 in total)
  for wave 1. The codes are mapped to the variable \texttt{photoid}.
\item
  \texttt{sch\_friend21}, \ldots{}, \texttt{sch\_friend219} School friends nominations (19 in total)
  for wave 2. The codes are mapped to the variable \texttt{photoid}.
\item
  \texttt{sch\_friend31}, \ldots{}, \texttt{sch\_friend319} School friends nominations (19 in total)
  for wave 3. The codes are mapped to the variable \texttt{photoid}.
\item
  \texttt{sch\_friend41}, \ldots{}, \texttt{sch\_friend419} School friends nominations (19 in total)
  for wave 4. The codes are mapped to the variable \texttt{photoid}.
\end{itemize}

\bibliographystyle{apacite}

\hypertarget{references}{%
\chapter*{References}\label{references}}
\addcontentsline{toc}{chapter}{References}

\hypertarget{refs}{}
\leavevmode\hypertarget{ref-admiraal2006}{}%
Admiraal, Ryan, and Mark S Handcock. 2006. ``Sequential Importance Sampling for Bipartite Graphs with Applications to Likelihood-Based Inference.'' Department of Statistics, University of Washington.

\leavevmode\hypertarget{ref-R-magrittr}{}%
Bache, Stefan Milton, and Hadley Wickham. 2014. \emph{Magrittr: A Forward-Pipe Operator for R}. \url{https://CRAN.R-project.org/package=magrittr}.

\leavevmode\hypertarget{ref-R-intergraph}{}%
Bojanowski, Michal. 2015. \emph{Intergraph: Coercion Routines for Network Data Objects}. \url{http://mbojan.github.io/intergraph}.

\leavevmode\hypertarget{ref-brooks2011}{}%
Brooks, Steve, Andrew Gelman, Galin Jones, and Xiao-Li Meng. 2011. \emph{Handbook of Markov Chain Monte Carlo}. CRC press.

\leavevmode\hypertarget{ref-R-igraph}{}%
Csardi, Gabor, and Tamas Nepusz. 2006. ``The Igraph Software Package for Complex Network Research.'' \emph{InterJournal} Complex Systems: 1695. \url{http://igraph.org}.

\leavevmode\hypertarget{ref-Efron1994}{}%
Efron, Bradley, and Robert J Tibshirani. 1994. \emph{An Introduction to the Bootstrap}. CRC press.

\leavevmode\hypertarget{ref-Geyer1992}{}%
Geyer, Charles J., and Elizabeth A. Thompson. 1992. ``Constrained Monte Carlo Maximum Likelihood for Dependent Data.'' \emph{Journal of the Royal Statistical Society. Series B (Methodological)} 54 (3): 657--99. \url{http://www.jstor.org/stable/2345852}.

\leavevmode\hypertarget{ref-R-statnet}{}%
Handcock, Mark S., David R. Hunter, Carter T. Butts, Steven M. Goodreau, Pavel N. Krivitsky, Skye Bender-deMoll, and Martina Morris. 2016. \emph{Statnet: Software Tools for the Statistical Analysis of Network Data}. The Statnet Project (\url{http://www.statnet.org}). \url{CRAN.R-project.org/package=statnet}.

\leavevmode\hypertarget{ref-R-ergm}{}%
Handcock, Mark S., David R. Hunter, Carter T. Butts, Steven M. Goodreau, Pavel N. Krivitsky, and Martina Morris. 2017. \emph{Ergm: Fit, Simulate and Diagnose Exponential-Family Models for Networks}. The Statnet Project (\url{http://www.statnet.org}). \url{https://CRAN.R-project.org/package=ergm}.

\leavevmode\hypertarget{ref-HunterJASA2008}{}%
Hunter, David R, Steven M Goodreau, and Mark S Handcock. 2008. ``Goodness of Fit of Social Network Models.'' \emph{Journal of the American Statistical Association} 103 (481): 248--58. \url{https://doi.org/10.1198/016214507000000446}.

\leavevmode\hypertarget{ref-Hunter2008}{}%
Hunter, David R., Mark S. Handcock, Carter T. Butts, Steven M. Goodreau, and Martina Morris. 2008. ``ergm : A Package to Fit, Simulate and Diagnose Exponential-Family Models for Networks.'' \emph{Journal of Statistical Software} 24 (3). \url{https://doi.org/10.18637/jss.v024.i03}.

\leavevmode\hypertarget{ref-lazega2015}{}%
Lazega, Emmanuel, and Tom AB Snijders. 2015. \emph{Multilevel Network Analysis for the Social Sciences: Theory, Methods and Applications}. Vol. 12. Springer.

\leavevmode\hypertarget{ref-R-texreg}{}%
Leifeld, Philip. 2013. ``texreg: Conversion of Statistical Model Output in R to LaTeX and HTML Tables.'' \emph{Journal of Statistical Software} 55 (8): 1--24. \url{http://www.jstatsoft.org/v55/i08/}.

\leavevmode\hypertarget{ref-lusher2012}{}%
Lusher, Dean, Johan Koskinen, and Garry Robins. 2012. \emph{Exponential Random Graph Models for Social Networks: Theory, Methods, and Applications}. Cambridge University Press.

\leavevmode\hypertarget{ref-Matloff2011}{}%
Matloff, Norman. 2011. \emph{The Art of R Programming: A Tour of Statistical Software Design}. No Starch Press.

\leavevmode\hypertarget{ref-Morris2008}{}%
Morris, Martina, Mark Handcock, and David Hunter. 2008. ``Specification of Exponential-Family Random Graph Models: Terms and Computational Aspects.'' \emph{Journal of Statistical Software, Articles} 24 (4): 1--24. \url{https://doi.org/10.18637/jss.v024.i04}.

\leavevmode\hypertarget{ref-R-coda}{}%
Plummer, Martyn, Nicky Best, Kate Cowles, and Karen Vines. 2006. ``CODA: Convergence Diagnosis and Output Analysis for Mcmc.'' \emph{R News} 6 (1): 7--11. \url{https://journal.r-project.org/archive/}.

\leavevmode\hypertarget{ref-R-foreign}{}%
R Core Team. 2017a. \emph{Foreign: Read Data Stored by 'Minitab', 'S', 'Sas', 'Spss', 'Stata', 'Systat', 'Weka', 'dBase', ...} \url{https://CRAN.R-project.org/package=foreign}.

\leavevmode\hypertarget{ref-R}{}%
---------. 2017b. \emph{R: A Language and Environment for Statistical Computing}. Vienna, Austria: R Foundation for Statistical Computing. \url{https://www.R-project.org/}.

\leavevmode\hypertarget{ref-Ripley2011}{}%
Ripley, Ruth M., Tom AB Snijders, Paulina Preciado, and Others. 2011. ``Manual for RSIENA.'' \emph{University of Oxford: Department of Statistics, Nuffield College}, no. 2007. \href{https://www.uni-due.de/hummell/sna/R/RSiena\%7B/_\%7DManual.pdf}{https://www.uni-due.de/hummell/sna/R/RSiena\{\textbackslash{}\_\}Manual.pdf}.

\leavevmode\hypertarget{ref-R-latticeExtra}{}%
Sarkar, Deepayan, and Felix Andrews. 2016. \emph{LatticeExtra: Extra Graphical Utilities Based on Lattice}. \url{https://CRAN.R-project.org/package=latticeExtra}.

\leavevmode\hypertarget{ref-Snijders2002}{}%
Snijders, Tom AB. 2002. ``Markov Chain Monte Carlo Estimation of Exponential Random Graph Models.'' \emph{Journal of Social Structure} 3.

\leavevmode\hypertarget{ref-Snijders2010margin}{}%
SNIJDERS, TOM A. B. 2010. ``Conditional Marginalization for Exponential Random Graph Models.'' \emph{The Journal of Mathematical Sociology} 34 (4): 239--52. \url{https://doi.org/10.1080/0022250X.2010.485707}.

\leavevmode\hypertarget{ref-Snijders1999}{}%
Snijders, Tom A B, and Stephen P Borgatti. 1999. ``Non-Parametric Standard Errors and Tests for Network Statistics.'' \emph{Connections} 22 (2): 1--10. \url{https://insna.org/PDF/Connections/v22/1999_I-2_61-70.pdf}.

\leavevmode\hypertarget{ref-Snijders2010}{}%
Snijders, Tom A B, Gerhard G. van de Bunt, and Christian E G Steglich. 2010. ``Introduction to stochastic actor-based models for network dynamics.'' \emph{Social Networks} 32 (1): 44--60. \url{https://doi.org/10.1016/j.socnet.2009.02.004}.

\leavevmode\hypertarget{ref-R-rex}{}%
Ushey, Kevin, Jim Hester, and Robert Krzyzanowski. 2017. \emph{Rex: Friendly Regular Expressions}. \url{https://CRAN.R-project.org/package=rex}.

\leavevmode\hypertarget{ref-Wang2009}{}%
Wang, Peng, Ken Sharpe, Garry L. Robins, and Philippa E. Pattison. 2009. ``Exponential Random Graph (P*) Models for Affiliation Networks.'' \emph{Social Networks} 31 (1): 12--25. \url{https://doi.org/https://doi.org/10.1016/j.socnet.2008.08.002}.

\leavevmode\hypertarget{ref-R-stringr}{}%
Wickham, Hadley. 2017. \emph{Stringr: Simple, Consistent Wrappers for Common String Operations}. \url{https://CRAN.R-project.org/package=stringr}.

\leavevmode\hypertarget{ref-R-readxl}{}%
Wickham, Hadley, and Jennifer Bryan. 2017. \emph{Readxl: Read Excel Files}. \url{https://CRAN.R-project.org/package=readxl}.

\leavevmode\hypertarget{ref-R-dplyr}{}%
Wickham, Hadley, Romain Francois, Lionel Henry, and Kirill Mller. 2017. \emph{Dplyr: A Grammar of Data Manipulation}. \url{https://CRAN.R-project.org/package=dplyr}.

\leavevmode\hypertarget{ref-R-tidyr}{}%
Wickham, Hadley, and Lionel Henry. 2017. \emph{Tidyr: Easily Tidy Data with 'Spread()' and 'Gather()' Functions}. \url{https://CRAN.R-project.org/package=tidyr}.

\leavevmode\hypertarget{ref-R-readr}{}%
Wickham, Hadley, Jim Hester, and Romain Francois. 2017. \emph{Readr: Read Rectangular Text Data}. \url{https://CRAN.R-project.org/package=readr}.

\end{document}
