# Power calculation in network studies

In survey and study design, calculating the required sample size is key. Nowadays, tools and methods for calculating the required sample size abound; nonetheless, sample size calculation for studies involving social networks is still underdeveloped. In this chapter, we will illustrate how can we use computer simulations to estimate the required sample size. Chapter \@ref(part2-power) provides a general overview of power analysis.

## Example 1: Spillover effects in egocentric studies[^credit-ego-power]

Suppose that we want to run an intervention over a particular population and we are interested in the effects such intervention will have over the egos' alters. In economics, this problem, which they call the "spillover effect," is actively studied.

For the power calculation, we will assume that alters only get exposed if egos acquire the behavior. Furthermore, for this first run, we will assume that there is no social reinforcement or influence between alters. We will later relax this assumption. To calculate power we will do the following:

1. Simulate egos' behavior following a logit distribution.

2. Randomly drop some egos as a result of attrition.

3. Simulate alters' behavior using their egos as the treatment.

4. Fit a logistic regression based on the previous model.

5. Accept/reject the null and store the result.

The previous steps will be repeated 500 for each value of $n$ we analyze. We will finalize by plotting power against sample sizes. Let's first start by writing down the simulation parameters:

```{r part-01-power-params1}
# Design
n_sims    <- 1000 # Number of simulations
n_a       <- 5   # Number of alters
sizes     <-     # Sizes to try
  seq(from = 100, to = 350, by = 25)

# Assumptions
odds_h_1  <- 1.5 # Odds of Increase/
attrition <- .3
baseline  <- .2  # Low prevalence in 1s

# Parameters
alpha    <- .05
beta_pow <- 0.2
```

As we discuss in \@ref(part2-power), it is always a good idea to encapsule the simulation into a function:

```{r part-01-power-simfun}
# The odds turned to a prob
theta_h_1 <- plogis(log(odds_h_1))

# Simulation function
sim_data <- function(n) {

  # Treatment assignment
  tr  <- c(rep(1, n/2), rep(0, n/2))

  # Step 1: Sampling population of egos
  y_ego <- runif(n) < c(
    rep(theta_h_1, n/2),
    rep(0.5, n/2)
  )

  # Step 2: Simulating attrition
  todrop <- order(runif(n))[1:(n * attrition)]
  y_ego  <- y_ego[-todrop]
  tr     <- tr[-todrop]
  n      <- n - length(todrop)

  # Step 3: Simulating alter's effect. We assume the same as in
  # ego
  tr_alter <- rep(y_ego * tr, n_a)
  y_alter  <- runif(n * n_a) < ifelse(tr_alter, theta_h_1, 0.5)

  # Step 4: Computing test statistic
  res_ego   <- tryCatch(glm(y_ego ~ tr, family = binomial("logit")), error = function(e) e)
  res_alter <- tryCatch(glm(y_alter ~ tr_alter, family = binomial("logit")), error = function(e) e)

  if (inherits(res_ego, "error") | inherits(res_alter, "error"))
    return(c(ego =  NA, alter = NA))
  
  # Step 5: Reject?
  c(
    ego   = summary(res_ego)$coefficients["tr", "Pr(>|z|)"] < alpha,
    alter = summary(res_alter)$coefficients["tr_alter", "Pr(>|z|)"] < alpha
  )
  

}
```

Now that we have the data generating function, we can run the simulations to approximate statistical power given the sample size. Since we are simulating data, it is important to set the seed so that we can reproduce the results. The results will be stored in the matrix `spower`.

```{r part-01-powersim1, warning=FALSE}
# We always set the seed
set.seed(88) 

# Making space, and running!
spower <- NULL
for (s in sizes) {

  # Run the simulation for size s
  simres <- rowMeans(replicate(n_sims, sim_data(s)), na.rm = TRUE)

  # And store the results
  spower <- rbind(spower, simres)

}
```

The following figure shows the approximate power for finding effects at both levels, ego and alter:

```{r part-01-power-plot1, warning=FALSE}
library(ggplot2)

spower <- rbind(
  data.frame(size = sizes, power = spower[,"ego"], type =  "ego"),
  data.frame(size = sizes, power = spower[,"alter"], type =  "alter")
)

spower |>
  ggplot(aes(x = size, y = power, colour = type)) +
  geom_point() +
  geom_smooth(method = "loess", formula = y ~ x) +
  labs(x = "Number of Egos", y = "Approx. Power", colour = "Node type") +
  geom_hline(yintercept = 1 - beta_pow)
```

As shown in Chapter \@ref(part2-power), we can use a linear regression model to predict sample size as a function of statistical power:

```{r part-01-power-ols-example1}
# Fitting the model
power_model <- glm(
  size ~ power + I(power^2),
  data = spower, family = gaussian(), subset = type == "alter"
)

summary(power_model)

# Predict
predict(power_model, newdata = data.frame(power = .8), type = "response") |>
  ceiling()
```

From the figure, it becomes apparent that, although there is not enough power to identify effects at the ego level, because each ego brings in five alters, the alter sample size is high enough that we can reach above 0.8 statistical power with relatively small sample size.

[^credit-ego-power]: The original problem was posed by [Dr. Shinduk Lee](https://faculty.utah.edu/u6037777-SHINDUK_LEE/hm/index.hml) from the School of Nursing at the University of Utah.


## Example 2: Spillover effects pre-post effect

Now the dynamics are different. Instead of having a treated and control group, we have a single group over which we will measure behavioral change. We will simulate individuals in their initial state, still 0/1, and then simulate that the intervention will make them more likely to have $y = 1.$ We will also assume that subjects generally don't change their behavior and that the baseline prevalence of zeros is higher. The simulation steps are as follows:

1. For each individual in the population, draw the underlaying probability that $y = 1$. With that probability assign the value of $y$. This applies to both ego and alter.

2. Randomly drop some egos and their corresponding alters as a result of attrition.

3. Simulate alters' behavior using their egos as the treatment. Both ego and alter's underlying probability are increased by the chosen odds.

4. In the case of ego, perform a paired t-test comparing first vs second observation. In the case of alters, since we can treat ego's behavior as treatment, fit a linear regression using alters' state at time 0 and ego's state at time 1

5. Accept/reject the null and store the result.

```{r part-01-params2}
beta_pars <- c(2, 8)
odds_h_1  <- 1.5
```

```{r part-01-sim2}
# Simulation function
sim_data_prepost <- function(n) {


  # Step 1: Sampling population of egos
  y_ego_star <- rbeta(n, beta_pars[1], beta_pars[2])
  y_ego_0    <- runif(n) < y_ego_star

  # Step 2: Simulating attrition
  todrop     <- order(runif(n))[1:(n * attrition)]
  y_ego_0    <- y_ego_0[-todrop]
  n          <- n - length(todrop)
  y_ego_star <- y_ego_star[-todrop]

  # Step 3: Simulating alter's effect. We assume the same as in
  # ego
  y_alter_star <- rbeta(n * n_a, beta_pars[1], beta_pars[2])
  y_alter_0    <- runif(n * n_a) < y_alter_star

  # Simulating post
  y_ego_1   <- runif(n) < (y_ego_star * odds_h_1)
  tr_alter  <- as.integer(rep(y_ego_1, n_a))
  y_alter_1 <- runif(n * n_a) < (y_alter_star * odds_h_1^(tr_alter)) # So only if ego did something

  # Step 4: Computing test statistic
  y_ego_0 <- as.integer(y_ego_0)
  y_ego_1 <- as.integer(y_ego_1)
  y_alter_0 <- as.integer(y_alter_0)
  y_alter_1 <- as.integer(y_alter_1)

  res_ego   <- tryCatch(
    t.test(y_ego_0, y_ego_1, paired = TRUE, alternative="two.sided"),
    error = function(e) e
    )

  res_alter <- tryCatch(
    glm(y_alter_1 ~ y_alter_0 + tr_alter, family = binomial("logit")),
    error = function(e) e
    )

  if (inherits(res_ego, "error") | inherits(res_alter, "error"))
    return(c(ego =  NA, alter = NA))
  
  # Step 5: Reject?
  c(
    ego   = res_ego$p.value < alpha,
    alter = summary(res_alter)$coefficients["tr_alter", "Pr(>|z|)"] < alpha,
    mean_ego = mean(y_ego_0 < y_ego_1) ,
    mean_alter = coef(res_alter)[2]
  )
  

}
```

```{r part-01-powersim2, warning=FALSE, cache = TRUE}
# We always set the seed
set.seed(88)

# Making space and running!
spower <- NULL
for (s in sizes) {

  # Run the simulation for size s
  simres <- rowMeans(replicate(n_sims, sim_data_prepost(s)), na.rm = TRUE)

  # And store the results
  spower <- rbind(spower, simres)

}
```


```{r part-01-power-plot2, warning=FALSE}
library(ggplot2)

spower <- rbind(
  data.frame(size = sizes, power = spower[,"ego"], type =  "ego"),
  data.frame(size = sizes, power = spower[,"alter"], type =  "alter")
)

spower |>
  ggplot(aes(x = size, y = power, colour = type)) +
  geom_point() +
  geom_smooth(method = "loess", formula = y ~ x) +
  labs(x = "Number of Egos", y = "Approx. Power", colour = "Node type") +
  geom_hline(yintercept = 1 - beta_pow)
```

As shown in Chapter \@ref(part2-power), we can use a linear regression model to predict sample size as a function of statistical power:

```{r part-01-power-ols-example2}
# Fitting the model
power_model <- glm(
  size ~ power + I(power^2),
  data = spower, family = gaussian(), subset = type == "alter"
)

summary(power_model)

# Predict
predict(power_model, newdata = data.frame(power = .8), type = "response") |>
  ceiling()
```

